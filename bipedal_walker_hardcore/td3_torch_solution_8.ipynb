{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "ACTOR=Sequential(\n",
      "  (0): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (6): Dropout(p=0.2)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n",
      "ACTOR=Sequential(\n",
      "  (0): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (6): Dropout(p=0.2)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "action_space=Box(4,)\n",
      "obs_space=Box(24,)\n",
      "threshold=300 \n",
      "\n",
      "Random Seed: 123\n",
      "DIR=./preTrained/td3_torch/BipedalWalkerHardcore-v2 NAME=TD3_torch_BipedalWalkerHardcore-v2_123\n",
      "No models to load\n",
      "Ep:10   Rew:-119.15  Avg Rew:-117.01  LR:0.00009340   Polyak:0.99990  Bf: 0  EN:0.2802  Loss: -0.127 44.173 45.754\n",
      "Ep:20   Rew:-206.59  Avg Rew:-133.01  LR:0.00009660   Polyak:0.99990  Bf: 0  EN:0.2898  Loss: -0.920 0.804 1.073\n",
      "Ep:30   Rew:-123.22  Avg Rew:-126.70  LR:0.00009534   Polyak:0.99990  Bf: 1  EN:0.2860  Loss: 0.793 0.652 0.680\n",
      "Ep:40   Rew:-114.95  Avg Rew:-124.74  LR:0.00009495   Polyak:0.99990  Bf: 1  EN:0.2848  Loss: 1.282 8.644 11.825\n",
      "Ep:50   Rew:-116.65  Avg Rew:-122.90  LR:0.00009458   Polyak:0.99990  Bf: 1  EN:0.2837  Loss: 1.205 1.177 1.433\n",
      "Ep:60   Rew:-108.43  Avg Rew:-120.67  LR:0.00009413   Polyak:0.99990  Bf: 1  EN:0.2824  Loss: 1.085 1.433 1.675\n",
      "Ep:70   Rew:-109.39  Avg Rew:-119.03  LR:0.00009381   Polyak:0.99990  Bf: 1  EN:0.2814  Loss: 1.558 16.075 14.826\n",
      "Ep:80   Rew:-115.30  Avg Rew:-118.25  LR:0.00009365   Polyak:0.99990  Bf: 1  EN:0.2810  Loss: 0.861 10.252 12.185\n",
      "Ep:90   Rew:-106.76  Avg Rew:-117.04  LR:0.00009341   Polyak:0.99990  Bf: 1  EN:0.2802  Loss: 0.880 25.504 23.857\n",
      "Ep:100   Rew:-105.94  Avg Rew:-116.23  LR:0.00009325   Polyak:0.99990  Bf: 1  EN:0.2797  Loss: 0.696 4.270 8.077\n",
      "Ep:110   Rew:-138.74  Avg Rew:-116.43  LR:0.00009329   Polyak:0.99990  Bf: 1  EN:0.2799  Loss: 0.960 19.838 17.356\n",
      "Ep:120   Rew:-167.62  Avg Rew:-114.34  LR:0.00009287   Polyak:0.99990  Bf: 1  EN:0.2786  Loss: 0.534 2.312 4.225\n",
      "Ep:130   Rew:-167.32  Avg Rew:-117.46  LR:0.00009349   Polyak:0.99990  Bf: 2  EN:0.2805  Loss: 0.147 0.996 1.325\n",
      "Ep:140   Rew:-110.63  Avg Rew:-120.23  LR:0.00009405   Polyak:0.99990  Bf: 2  EN:0.2821  Loss: 0.131 1.373 1.437\n",
      "Ep:150   Rew:-116.34  Avg Rew:-119.48  LR:0.00009390   Polyak:0.99990  Bf: 2  EN:0.2817  Loss: -0.171 3.291 4.761\n",
      "Ep:160   Rew:-103.47  Avg Rew:-119.33  LR:0.00009387   Polyak:0.99990  Bf: 2  EN:0.2816  Loss: -0.231 8.777 1.935\n",
      "Ep:170   Rew:-112.01  Avg Rew:-119.39  LR:0.00009388   Polyak:0.99990  Bf: 2  EN:0.2816  Loss: -0.489 3.010 2.854\n",
      "Ep:180   Rew:-111.59  Avg Rew:-119.21  LR:0.00009384   Polyak:0.99990  Bf: 2  EN:0.2815  Loss: 0.029 1.400 1.449\n",
      "Ep:190   Rew:-105.54  Avg Rew:-119.43  LR:0.00009389   Polyak:0.99990  Bf: 2  EN:0.2817  Loss: -0.600 6.512 3.963\n",
      "Ep:200   Rew:-123.37  Avg Rew:-119.53  LR:0.00009391   Polyak:0.99990  Bf: 2  EN:0.2817  Loss: -0.708 7.801 12.022\n",
      "Ep:210   Rew:-106.30  Avg Rew:-118.46  LR:0.00009369   Polyak:0.99990  Bf: 2  EN:0.2811  Loss: -0.656 11.771 14.697\n",
      "Ep:220   Rew:-103.21  Avg Rew:-116.45  LR:0.00009329   Polyak:0.99990  Bf: 2  EN:0.2799  Loss: -0.405 4.193 2.967\n",
      "Ep:230   Rew:-110.29  Avg Rew:-112.61  LR:0.00009252   Polyak:0.99990  Bf: 2  EN:0.2776  Loss: -0.571 2.740 2.309\n",
      "Ep:240   Rew:-112.87  Avg Rew:-108.86  LR:0.00009177   Polyak:0.99990  Bf: 3  EN:0.2753  Loss: -0.198 3.139 7.960\n",
      "Ep:250   Rew:-110.91  Avg Rew:-109.03  LR:0.00009181   Polyak:0.99990  Bf: 3  EN:0.2754  Loss: -0.404 2.514 3.439\n",
      "Ep:260   Rew:-114.96  Avg Rew:-109.26  LR:0.00009185   Polyak:0.99990  Bf: 3  EN:0.2756  Loss: -0.293 10.883 12.390\n",
      "Ep:270   Rew:-112.25  Avg Rew:-109.59  LR:0.00009192   Polyak:0.99990  Bf: 3  EN:0.2758  Loss: -0.391 14.214 13.027\n",
      "Ep:280   Rew:-108.62  Avg Rew:-109.67  LR:0.00009193   Polyak:0.99990  Bf: 3  EN:0.2758  Loss: -0.383 4.223 9.696\n",
      "Ep:290   Rew:-116.72  Avg Rew:-109.84  LR:0.00009197   Polyak:0.99990  Bf: 3  EN:0.2759  Loss: -0.624 2.767 8.195\n",
      "Ep:300   Rew:-110.97  Avg Rew:-110.26  LR:0.00009205   Polyak:0.99990  Bf: 3  EN:0.2762  Loss: -0.553 11.394 11.924\n",
      "Ep:310   Rew:-123.06  Avg Rew:-110.95  LR:0.00009219   Polyak:0.99990  Bf: 3  EN:0.2766  Loss: -0.874 8.635 17.432\n",
      "Ep:320   Rew:-111.32  Avg Rew:-111.35  LR:0.00009227   Polyak:0.99990  Bf: 3  EN:0.2768  Loss: -0.061 1.924 2.833\n",
      "Ep:330   Rew:-108.95  Avg Rew:-112.03  LR:0.00009241   Polyak:0.99990  Bf: 3  EN:0.2772  Loss: -0.293 2.160 7.414\n",
      "Ep:340   Rew:-117.19  Avg Rew:-112.45  LR:0.00009249   Polyak:0.99990  Bf: 3  EN:0.2775  Loss: -0.037 3.096 4.179\n",
      "Ep:350   Rew:-123.11  Avg Rew:-112.92  LR:0.00009258   Polyak:0.99990  Bf: 3  EN:0.2778  Loss: -0.207 15.829 20.471\n",
      "Ep:360   Rew:-112.55  Avg Rew:-112.99  LR:0.00009260   Polyak:0.99990  Bf: 3  EN:0.2778  Loss: -1.078 4.811 3.994\n",
      "Ep:370   Rew:-108.47  Avg Rew:-112.64  LR:0.00009253   Polyak:0.99990  Bf: 3  EN:0.2776  Loss: -0.320 2.638 2.936\n",
      "Ep:380   Rew:-108.08  Avg Rew:-112.96  LR:0.00009259   Polyak:0.99990  Bf: 3  EN:0.2778  Loss: -0.141 3.859 5.043\n",
      "Ep:390   Rew:-109.01  Avg Rew:-112.93  LR:0.00009259   Polyak:0.99990  Bf: 3  EN:0.2778  Loss: -0.495 6.689 12.744\n",
      "Ep:400   Rew:-108.47  Avg Rew:-112.41  LR:0.00009248   Polyak:0.99990  Bf: 3  EN:0.2774  Loss: 0.162 3.347 9.235\n",
      "Ep:410   Rew:-117.74  Avg Rew:-112.28  LR:0.00009246   Polyak:0.99990  Bf: 3  EN:0.2774  Loss: -0.662 6.825 4.125\n",
      "Ep:420   Rew:-108.98  Avg Rew:-112.08  LR:0.00009242   Polyak:0.99990  Bf: 3  EN:0.2772  Loss: -0.949 5.746 5.573\n",
      "Ep:430   Rew:-111.31  Avg Rew:-111.96  LR:0.00009239   Polyak:0.99990  Bf: 3  EN:0.2772  Loss: 0.159 2.227 4.962\n",
      "Ep:440   Rew:-114.89  Avg Rew:-112.32  LR:0.00009246   Polyak:0.99990  Bf: 3  EN:0.2774  Loss: -0.436 12.961 12.432\n",
      "Ep:450   Rew:-125.13  Avg Rew:-112.65  LR:0.00009253   Polyak:0.99990  Bf: 3  EN:0.2776  Loss: -0.275 3.865 4.306\n",
      "Ep:460   Rew:-111.83  Avg Rew:-113.36  LR:0.00009267   Polyak:0.99990  Bf: 3  EN:0.2780  Loss: -0.399 4.228 3.386\n",
      "Ep:470   Rew:-124.07  Avg Rew:-113.97  LR:0.00009279   Polyak:0.99990  Bf: 3  EN:0.2784  Loss: -0.567 2.705 2.043\n",
      "Ep:480   Rew:-126.45  Avg Rew:-113.94  LR:0.00009279   Polyak:0.99990  Bf: 4  EN:0.2784  Loss: -0.990 3.047 5.696\n",
      "Ep:490   Rew:-114.69  Avg Rew:-114.33  LR:0.00009287   Polyak:0.99990  Bf: 4  EN:0.2786  Loss: -0.091 2.269 2.427\n",
      "Ep:500   Rew:-111.47  Avg Rew:-114.79  LR:0.00009296   Polyak:0.99990  Bf: 4  EN:0.2789  Loss: -1.444 2.304 2.642\n",
      "Ep:510   Rew:-116.65  Avg Rew:-114.58  LR:0.00009292   Polyak:0.99990  Bf: 4  EN:0.2787  Loss: -1.076 4.458 9.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:520   Rew:-107.00  Avg Rew:-114.68  LR:0.00009294   Polyak:0.99990  Bf: 4  EN:0.2788  Loss: 0.176 4.608 4.119\n",
      "Ep:530   Rew:-118.60  Avg Rew:-114.95  LR:0.00009299   Polyak:0.99990  Bf: 4  EN:0.2790  Loss: -0.764 16.864 19.738\n",
      "Ep:540   Rew:-112.03  Avg Rew:-114.53  LR:0.00009291   Polyak:0.99990  Bf: 4  EN:0.2787  Loss: -0.699 9.118 8.386\n",
      "Ep:550   Rew:-112.98  Avg Rew:-114.19  LR:0.00009284   Polyak:0.99990  Bf: 4  EN:0.2785  Loss: -0.541 11.146 15.216\n",
      "Ep:560   Rew:-112.75  Avg Rew:-114.46  LR:0.00009289   Polyak:0.99990  Bf: 4  EN:0.2787  Loss: -0.699 2.923 3.456\n",
      "Ep:570   Rew:-113.02  Avg Rew:-114.22  LR:0.00009284   Polyak:0.99990  Bf: 4  EN:0.2785  Loss: 0.122 5.138 4.763\n",
      "Ep:580   Rew:-114.60  Avg Rew:-114.61  LR:0.00009292   Polyak:0.99990  Bf: 4  EN:0.2788  Loss: 0.268 7.745 3.808\n",
      "Ep:590   Rew:-117.33  Avg Rew:-114.71  LR:0.00009294   Polyak:0.99990  Bf: 4  EN:0.2788  Loss: 0.323 9.312 6.427\n",
      "Ep:600   Rew:-113.22  Avg Rew:-114.61  LR:0.00009292   Polyak:0.99990  Bf: 4  EN:0.2788  Loss: -0.073 2.505 2.212\n",
      "Ep:610   Rew:-113.43  Avg Rew:-115.00  LR:0.00009300   Polyak:0.99990  Bf: 4  EN:0.2790  Loss: 0.246 2.959 2.746\n",
      "Ep:620   Rew:-118.90  Avg Rew:-115.61  LR:0.00009312   Polyak:0.99990  Bf: 4  EN:0.2794  Loss: -0.364 3.484 4.319\n",
      "Ep:630   Rew:-112.84  Avg Rew:-115.58  LR:0.00009312   Polyak:0.99990  Bf: 4  EN:0.2793  Loss: -0.541 12.968 10.804\n",
      "Ep:640   Rew:-115.79  Avg Rew:-115.93  LR:0.00009319   Polyak:0.99990  Bf: 4  EN:0.2796  Loss: -0.497 4.986 5.978\n",
      "Ep:650   Rew:-115.98  Avg Rew:-116.35  LR:0.00009327   Polyak:0.99990  Bf: 4  EN:0.2798  Loss: 0.874 5.167 5.141\n",
      "Ep:660   Rew:-113.26  Avg Rew:-116.17  LR:0.00009323   Polyak:0.99990  Bf: 4  EN:0.2797  Loss: 0.006 5.111 4.562\n",
      "Ep:670   Rew:-115.25  Avg Rew:-116.29  LR:0.00009326   Polyak:0.99990  Bf: 4  EN:0.2798  Loss: 0.213 2.746 3.881\n",
      "Ep:680   Rew:-115.26  Avg Rew:-115.93  LR:0.00009319   Polyak:0.99990  Bf: 4  EN:0.2796  Loss: 0.702 3.693 4.281\n",
      "Ep:690   Rew:-116.60  Avg Rew:-116.73  LR:0.00009335   Polyak:0.99990  Bf: 5  EN:0.2800  Loss: 0.741 7.494 2.716\n",
      "Ep:700   Rew:-116.36  Avg Rew:-117.46  LR:0.00009349   Polyak:0.99990  Bf: 5  EN:0.2805  Loss: 0.808 1.776 1.827\n",
      "Ep:710   Rew:-110.69  Avg Rew:-117.79  LR:0.00009356   Polyak:0.99990  Bf: 5  EN:0.2807  Loss: 0.969 2.727 3.255\n",
      "Ep:720   Rew:-111.36  Avg Rew:-117.96  LR:0.00009359   Polyak:0.99990  Bf: 5  EN:0.2808  Loss: 0.285 2.696 3.281\n",
      "Ep:730   Rew:-110.58  Avg Rew:-118.21  LR:0.00009364   Polyak:0.99990  Bf: 5  EN:0.2809  Loss: 0.786 2.963 2.178\n",
      "Ep:740   Rew:-110.94  Avg Rew:-118.27  LR:0.00009365   Polyak:0.99990  Bf: 5  EN:0.2810  Loss: 1.702 3.903 5.331\n",
      "Ep:750   Rew:-110.57  Avg Rew:-117.58  LR:0.00009352   Polyak:0.99990  Bf: 5  EN:0.2806  Loss: 0.495 4.874 4.244\n",
      "Ep:760   Rew:-109.02  Avg Rew:-117.42  LR:0.00009348   Polyak:0.99990  Bf: 5  EN:0.2804  Loss: 1.702 5.075 4.711\n",
      "Ep:770   Rew:-113.08  Avg Rew:-116.95  LR:0.00009339   Polyak:0.99990  Bf: 5  EN:0.2802  Loss: 1.397 3.701 4.055\n",
      "Ep:780   Rew:-111.82  Avg Rew:-116.54  LR:0.00009331   Polyak:0.99990  Bf: 5  EN:0.2799  Loss: 1.533 2.197 2.116\n",
      "Ep:790   Rew:-108.99  Avg Rew:-115.66  LR:0.00009313   Polyak:0.99990  Bf: 5  EN:0.2794  Loss: 1.471 3.857 4.980\n",
      "Ep:800   Rew:-107.90  Avg Rew:-115.69  LR:0.00009314   Polyak:0.99990  Bf: 5  EN:0.2794  Loss: 0.847 2.905 2.414\n",
      "Ep:810   Rew:-111.21  Avg Rew:-114.96  LR:0.00009299   Polyak:0.99990  Bf: 6  EN:0.2790  Loss: 1.511 3.369 3.713\n",
      "Ep:820   Rew:-111.00  Avg Rew:-114.16  LR:0.00009283   Polyak:0.99990  Bf: 6  EN:0.2785  Loss: 0.897 2.548 2.931\n",
      "Ep:830   Rew:-117.40  Avg Rew:-113.44  LR:0.00009269   Polyak:0.99990  Bf: 6  EN:0.2781  Loss: 1.146 5.468 4.051\n",
      "Ep:840   Rew:-109.88  Avg Rew:-112.78  LR:0.00009256   Polyak:0.99990  Bf: 6  EN:0.2777  Loss: 1.290 4.199 5.526\n",
      "Ep:850   Rew:-108.49  Avg Rew:-112.71  LR:0.00009254   Polyak:0.99990  Bf: 6  EN:0.2776  Loss: 1.206 2.905 2.880\n",
      "Ep:860   Rew:-110.43  Avg Rew:-112.05  LR:0.00009241   Polyak:0.99990  Bf: 6  EN:0.2772  Loss: 2.086 3.797 3.703\n",
      "Ep:870   Rew:-107.28  Avg Rew:-112.19  LR:0.00009244   Polyak:0.99990  Bf: 6  EN:0.2773  Loss: 2.144 3.937 4.671\n",
      "Ep:880   Rew:-113.23  Avg Rew:-112.06  LR:0.00009241   Polyak:0.99990  Bf: 6  EN:0.2772  Loss: 2.174 3.382 3.852\n",
      "Ep:890   Rew:-107.90  Avg Rew:-111.70  LR:0.00009234   Polyak:0.99990  Bf: 6  EN:0.2770  Loss: 1.381 2.850 2.005\n",
      "Ep:900   Rew:-111.03  Avg Rew:-110.86  LR:0.00009217   Polyak:0.99990  Bf: 6  EN:0.2765  Loss: 1.201 5.798 9.735\n",
      "Ep:910   Rew:-108.39  Avg Rew:-110.51  LR:0.00009210   Polyak:0.99990  Bf: 6  EN:0.2763  Loss: 2.436 6.468 4.830\n",
      "Ep:920   Rew:-111.38  Avg Rew:-110.31  LR:0.00009206   Polyak:0.99990  Bf: 6  EN:0.2762  Loss: 2.726 4.682 4.403\n",
      "Ep:930   Rew:-106.47  Avg Rew:-110.15  LR:0.00009203   Polyak:0.99990  Bf: 6  EN:0.2761  Loss: 2.141 5.040 4.094\n",
      "Ep:940   Rew:-130.54  Avg Rew:-110.34  LR:0.00009207   Polyak:0.99990  Bf: 6  EN:0.2762  Loss: 2.299 5.121 4.043\n",
      "Ep:950   Rew:-111.57  Avg Rew:-112.15  LR:0.00009243   Polyak:0.99990  Bf: 6  EN:0.2773  Loss: 2.275 3.335 3.507\n",
      "Ep:960   Rew:-115.85  Avg Rew:-111.93  LR:0.00009239   Polyak:0.99990  Bf: 6  EN:0.2772  Loss: 2.384 3.744 4.293\n",
      "Ep:970   Rew:-113.02  Avg Rew:-111.82  LR:0.00009236   Polyak:0.99990  Bf: 6  EN:0.2771  Loss: 2.716 3.974 3.599\n",
      "Ep:980   Rew:-107.10  Avg Rew:-111.44  LR:0.00009229   Polyak:0.99990  Bf: 6  EN:0.2769  Loss: 3.399 3.495 3.722\n",
      "Ep:990   Rew:-111.80  Avg Rew:-110.96  LR:0.00009219   Polyak:0.99990  Bf: 6  EN:0.2766  Loss: 1.692 7.230 7.919\n",
      "Ep:1000   Rew:-109.31  Avg Rew:-110.58  LR:0.00009212   Polyak:0.99990  Bf: 6  EN:0.2763  Loss: 3.045 2.605 3.346\n",
      "Ep:1010   Rew:-101.83  Avg Rew:-110.10  LR:0.00009202   Polyak:0.99990  Bf: 7  EN:0.2761  Loss: 3.126 5.953 5.647\n",
      "Ep:1020   Rew:-108.83  Avg Rew:-109.95  LR:0.00009199   Polyak:0.99990  Bf: 7  EN:0.2760  Loss: 2.809 15.333 15.148\n",
      "Ep:1030   Rew:-102.40  Avg Rew:-109.65  LR:0.00009193   Polyak:0.99990  Bf: 7  EN:0.2758  Loss: 2.406 3.242 4.206\n",
      "Ep:1040   Rew:-107.55  Avg Rew:-109.04  LR:0.00009181   Polyak:0.99990  Bf: 7  EN:0.2754  Loss: 1.983 2.319 3.884\n",
      "Ep:1050   Rew:-105.55  Avg Rew:-106.62  LR:0.00009132   Polyak:0.99990  Bf: 7  EN:0.2740  Loss: 2.706 8.637 9.762\n",
      "Ep:1060   Rew:-109.04  Avg Rew:-106.27  LR:0.00009125   Polyak:0.99990  Bf: 7  EN:0.2738  Loss: 2.442 11.032 11.235\n",
      "Ep:1070   Rew:-104.35  Avg Rew:-105.99  LR:0.00009120   Polyak:0.99990  Bf: 7  EN:0.2736  Loss: 3.624 10.535 11.856\n",
      "Ep:1080   Rew:-103.85  Avg Rew:-106.07  LR:0.00009121   Polyak:0.99990  Bf: 7  EN:0.2736  Loss: 3.172 3.800 3.984\n",
      "Ep:1090   Rew:-105.89  Avg Rew:-106.16  LR:0.00009123   Polyak:0.99990  Bf: 7  EN:0.2737  Loss: 2.450 3.363 3.626\n",
      "Ep:1100   Rew:-114.29  Avg Rew:-106.41  LR:0.00009128   Polyak:0.99990  Bf: 7  EN:0.2738  Loss: 2.866 3.576 3.806\n",
      "Ep:1110   Rew:-105.74  Avg Rew:-106.78  LR:0.00009136   Polyak:0.99990  Bf: 7  EN:0.2741  Loss: 2.401 4.802 5.734\n",
      "Ep:1120   Rew:-107.42  Avg Rew:-106.89  LR:0.00009138   Polyak:0.99990  Bf: 7  EN:0.2741  Loss: 3.552 3.489 4.139\n",
      "Ep:1130   Rew:-107.86  Avg Rew:-107.15  LR:0.00009143   Polyak:0.99990  Bf: 7  EN:0.2743  Loss: 2.577 6.396 6.778\n",
      "Ep:1140   Rew:-109.68  Avg Rew:-107.36  LR:0.00009147   Polyak:0.99990  Bf: 7  EN:0.2744  Loss: 2.415 2.635 3.718\n",
      "Ep:1150   Rew:-108.75  Avg Rew:-107.55  LR:0.00009151   Polyak:0.99990  Bf: 7  EN:0.2745  Loss: 2.925 3.794 4.168\n",
      "Ep:1160   Rew:-113.04  Avg Rew:-107.85  LR:0.00009157   Polyak:0.99990  Bf: 7  EN:0.2747  Loss: 3.138 4.865 5.134\n",
      "Ep:1170   Rew:-104.26  Avg Rew:-107.78  LR:0.00009156   Polyak:0.99990  Bf: 7  EN:0.2747  Loss: 2.976 3.766 3.544\n",
      "Ep:1180   Rew:-107.72  Avg Rew:-107.80  LR:0.00009156   Polyak:0.99990  Bf: 7  EN:0.2747  Loss: 3.776 9.568 11.184\n",
      "Ep:1190   Rew:-105.51  Avg Rew:-107.86  LR:0.00009157   Polyak:0.99990  Bf: 7  EN:0.2747  Loss: 3.718 6.103 6.137\n",
      "Ep:1200   Rew:-105.12  Avg Rew:-107.51  LR:0.00009150   Polyak:0.99990  Bf: 7  EN:0.2745  Loss: 4.855 13.722 13.740\n",
      "Ep:1210   Rew:-109.65  Avg Rew:-107.48  LR:0.00009150   Polyak:0.99990  Bf: 7  EN:0.2745  Loss: 4.108 7.170 8.657\n",
      "Ep:1220   Rew:-112.76  Avg Rew:-107.37  LR:0.00009147   Polyak:0.99990  Bf: 7  EN:0.2744  Loss: 3.721 3.806 3.164\n",
      "Ep:1230   Rew:-103.84  Avg Rew:-107.15  LR:0.00009143   Polyak:0.99990  Bf: 7  EN:0.2743  Loss: 4.347 5.416 4.055\n",
      "Ep:1240   Rew:-109.40  Avg Rew:-107.33  LR:0.00009147   Polyak:0.99990  Bf: 7  EN:0.2744  Loss: 3.660 4.665 4.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1250   Rew:-106.59  Avg Rew:-107.40  LR:0.00009148   Polyak:0.99990  Bf: 7  EN:0.2744  Loss: 4.002 2.446 3.100\n",
      "Ep:1260   Rew:-107.95  Avg Rew:-107.23  LR:0.00009145   Polyak:0.99990  Bf: 7  EN:0.2743  Loss: 4.257 7.205 7.886\n",
      "Ep:1270   Rew:-105.67  Avg Rew:-107.49  LR:0.00009150   Polyak:0.99990  Bf: 7  EN:0.2745  Loss: 4.288 4.886 5.490\n",
      "Ep:1280   Rew:-104.94  Avg Rew:-107.57  LR:0.00009151   Polyak:0.99990  Bf: 7  EN:0.2745  Loss: 3.705 2.528 3.045\n",
      "Ep:1290   Rew:-104.15  Avg Rew:-107.54  LR:0.00009151   Polyak:0.99990  Bf: 7  EN:0.2745  Loss: 4.200 4.599 5.504\n",
      "Ep:1300   Rew:-106.16  Avg Rew:-107.62  LR:0.00009152   Polyak:0.99990  Bf: 8  EN:0.2746  Loss: 4.511 5.570 6.719\n",
      "Ep:1310   Rew:-105.81  Avg Rew:-107.55  LR:0.00009151   Polyak:0.99990  Bf: 8  EN:0.2745  Loss: 3.563 12.756 5.500\n",
      "Ep:1320   Rew:-104.12  Avg Rew:-107.38  LR:0.00009148   Polyak:0.99990  Bf: 8  EN:0.2744  Loss: 4.965 4.991 5.488\n",
      "Ep:1330   Rew:-107.80  Avg Rew:-107.46  LR:0.00009149   Polyak:0.99990  Bf: 8  EN:0.2745  Loss: 3.788 7.755 8.250\n",
      "Ep:1340   Rew:-102.17  Avg Rew:-107.20  LR:0.00009144   Polyak:0.99990  Bf: 8  EN:0.2743  Loss: 4.833 3.626 4.050\n",
      "Ep:1350   Rew:-104.55  Avg Rew:-107.04  LR:0.00009141   Polyak:0.99990  Bf: 8  EN:0.2742  Loss: 4.833 2.906 2.406\n",
      "Ep:1360   Rew:-105.26  Avg Rew:-106.91  LR:0.00009138   Polyak:0.99990  Bf: 8  EN:0.2741  Loss: 4.071 4.969 5.023\n",
      "Ep:1370   Rew:-106.52  Avg Rew:-106.61  LR:0.00009132   Polyak:0.99990  Bf: 8  EN:0.2740  Loss: 4.407 6.217 7.197\n",
      "Ep:1380   Rew:-103.82  Avg Rew:-106.26  LR:0.00009125   Polyak:0.99990  Bf: 8  EN:0.2738  Loss: 5.934 10.759 10.157\n",
      "Ep:1390   Rew:-106.95  Avg Rew:-106.11  LR:0.00009122   Polyak:0.99990  Bf: 8  EN:0.2737  Loss: 4.497 5.437 6.020\n",
      "Ep:1400   Rew:-105.79  Avg Rew:-106.06  LR:0.00009121   Polyak:0.99990  Bf: 8  EN:0.2736  Loss: 4.563 6.425 4.995\n",
      "Ep:1410   Rew:-113.90  Avg Rew:-106.01  LR:0.00009120   Polyak:0.99990  Bf: 8  EN:0.2736  Loss: 5.026 4.610 5.753\n",
      "Ep:1420   Rew:-104.62  Avg Rew:-105.99  LR:0.00009120   Polyak:0.99990  Bf: 8  EN:0.2736  Loss: 4.623 6.903 7.867\n",
      "Ep:1430   Rew:-106.61  Avg Rew:-105.92  LR:0.00009118   Polyak:0.99990  Bf: 8  EN:0.2736  Loss: 4.518 3.357 3.290\n",
      "Ep:1440   Rew:-104.07  Avg Rew:-105.73  LR:0.00009115   Polyak:0.99990  Bf: 8  EN:0.2734  Loss: 5.246 3.681 4.328\n",
      "Ep:1450   Rew:-105.77  Avg Rew:-105.64  LR:0.00009113   Polyak:0.99990  Bf: 8  EN:0.2734  Loss: 3.883 3.077 4.202\n",
      "Ep:1460   Rew:-103.99  Avg Rew:-105.62  LR:0.00009112   Polyak:0.99990  Bf: 8  EN:0.2734  Loss: 6.056 4.819 4.935\n",
      "Ep:1470   Rew:-103.62  Avg Rew:-105.45  LR:0.00009109   Polyak:0.99990  Bf: 8  EN:0.2733  Loss: 4.325 9.647 2.645\n",
      "Ep:1480   Rew:-107.98  Avg Rew:-105.60  LR:0.00009112   Polyak:0.99990  Bf: 8  EN:0.2734  Loss: 5.862 4.432 5.275\n",
      "Ep:1490   Rew:-105.19  Avg Rew:-105.40  LR:0.00009108   Polyak:0.99990  Bf: 8  EN:0.2732  Loss: 5.779 8.443 8.600\n",
      "Ep:1500   Rew:-104.87  Avg Rew:-105.24  LR:0.00009105   Polyak:0.99990  Bf: 8  EN:0.2731  Loss: 5.610 5.067 4.946\n",
      "Ep:1510   Rew:-103.12  Avg Rew:-105.18  LR:0.00009104   Polyak:0.99990  Bf: 8  EN:0.2731  Loss: 4.630 5.604 5.814\n",
      "Ep:1520   Rew:-104.92  Avg Rew:-105.28  LR:0.00009106   Polyak:0.99990  Bf: 8  EN:0.2732  Loss: 6.098 3.176 3.894\n",
      "Ep:1530   Rew:-105.15  Avg Rew:-105.18  LR:0.00009104   Polyak:0.99990  Bf: 8  EN:0.2731  Loss: 5.807 6.536 6.005\n",
      "Ep:1540   Rew:-97.86  Avg Rew:-105.18  LR:0.00009104   Polyak:0.99990  Bf: 8  EN:0.2731  Loss: 4.722 4.749 3.898\n",
      "Ep:1550   Rew:-112.19  Avg Rew:-105.17  LR:0.00009103   Polyak:0.99990  Bf: 8  EN:0.2731  Loss: 5.855 6.956 5.520\n",
      "Ep:1560   Rew:-101.35  Avg Rew:-105.34  LR:0.00009107   Polyak:0.99990  Bf: 8  EN:0.2732  Loss: 5.851 3.732 3.419\n",
      "Ep:1570   Rew:-102.93  Avg Rew:-105.60  LR:0.00009112   Polyak:0.99990  Bf: 9  EN:0.2734  Loss: 5.275 4.106 3.944\n",
      "Ep:1580   Rew:-105.73  Avg Rew:-105.66  LR:0.00009113   Polyak:0.99990  Bf: 9  EN:0.2734  Loss: 6.524 10.485 11.657\n",
      "Ep:1590   Rew:-106.00  Avg Rew:-105.84  LR:0.00009117   Polyak:0.99990  Bf: 9  EN:0.2735  Loss: 5.221 3.601 4.172\n",
      "Ep:1600   Rew:-106.05  Avg Rew:-105.91  LR:0.00009118   Polyak:0.99990  Bf: 9  EN:0.2735  Loss: 5.190 3.973 3.403\n",
      "Ep:1610   Rew:-109.36  Avg Rew:-105.94  LR:0.00009119   Polyak:0.99990  Bf: 9  EN:0.2736  Loss: 6.256 5.737 3.785\n",
      "Ep:1620   Rew:-129.28  Avg Rew:-105.92  LR:0.00009118   Polyak:0.99990  Bf: 9  EN:0.2736  Loss: 4.432 14.510 14.838\n",
      "Ep:1630   Rew:-99.89  Avg Rew:-106.19  LR:0.00009124   Polyak:0.99990  Bf: 9  EN:0.2737  Loss: 6.221 4.132 5.313\n",
      "Ep:1640   Rew:-104.55  Avg Rew:-106.55  LR:0.00009131   Polyak:0.99990  Bf: 9  EN:0.2739  Loss: 4.247 2.863 3.299\n",
      "Ep:1650   Rew:-104.26  Avg Rew:-106.65  LR:0.00009133   Polyak:0.99990  Bf: 9  EN:0.2740  Loss: 6.457 6.386 5.694\n",
      "Ep:1660   Rew:-118.98  Avg Rew:-106.56  LR:0.00009131   Polyak:0.99990  Bf: 9  EN:0.2739  Loss: 5.708 3.457 4.017\n",
      "Ep:1670   Rew:-103.57  Avg Rew:-106.45  LR:0.00009129   Polyak:0.99990  Bf: 9  EN:0.2739  Loss: 7.467 6.190 5.443\n",
      "Ep:1680   Rew:-109.27  Avg Rew:-106.10  LR:0.00009122   Polyak:0.99990  Bf: 9  EN:0.2737  Loss: 6.525 6.094 5.986\n",
      "Ep:1690   Rew:-101.32  Avg Rew:-105.53  LR:0.00009111   Polyak:0.99990  Bf: 9  EN:0.2733  Loss: 7.368 7.433 5.804\n",
      "Ep:1700   Rew:-85.59  Avg Rew:-106.04  LR:0.00009121   Polyak:0.99990  Bf: 9  EN:0.2736  Loss: 7.362 10.017 10.165\n",
      "Ep:1710   Rew:-102.09  Avg Rew:-106.07  LR:0.00009121   Polyak:0.99990  Bf: 9  EN:0.2736  Loss: 7.183 3.389 3.342\n",
      "Ep:1720   Rew:-105.76  Avg Rew:-106.10  LR:0.00009122   Polyak:0.99990  Bf: 9  EN:0.2737  Loss: 7.400 7.699 7.440\n",
      "Ep:1730   Rew:-110.50  Avg Rew:-106.21  LR:0.00009124   Polyak:0.99990  Bf: 9  EN:0.2737  Loss: 8.376 3.833 4.254\n",
      "Ep:1740   Rew:-98.39  Avg Rew:-105.56  LR:0.00009111   Polyak:0.99990  Bf: 9  EN:0.2733  Loss: 7.857 2.812 3.090\n",
      "Ep:1750   Rew:-117.06  Avg Rew:-105.81  LR:0.00009116   Polyak:0.99990  Bf: 9  EN:0.2735  Loss: 7.849 4.602 5.743\n",
      "Ep:1760   Rew:-95.83  Avg Rew:-106.05  LR:0.00009121   Polyak:0.99990  Bf: 9  EN:0.2736  Loss: 7.964 4.878 5.220\n",
      "Ep:1770   Rew:-123.53  Avg Rew:-106.20  LR:0.00009124   Polyak:0.99990  Bf: 9  EN:0.2737  Loss: 6.620 3.466 4.208\n",
      "Ep:1780   Rew:-106.89  Avg Rew:-107.12  LR:0.00009142   Polyak:0.99990  Bf:10  EN:0.2743  Loss: 6.968 3.826 3.516\n",
      "Ep:1790   Rew:-102.60  Avg Rew:-107.56  LR:0.00009151   Polyak:0.99990  Bf:10  EN:0.2745  Loss: 6.625 5.732 4.371\n",
      "Ep:1800   Rew:-106.81  Avg Rew:-107.38  LR:0.00009148   Polyak:0.99990  Bf:10  EN:0.2744  Loss: 7.862 5.466 5.340\n",
      "Ep:1810   Rew:-104.19  Avg Rew:-107.76  LR:0.00009155   Polyak:0.99990  Bf:10  EN:0.2747  Loss: 7.622 3.358 3.876\n",
      "Ep:1820   Rew:-107.74  Avg Rew:-108.45  LR:0.00009169   Polyak:0.99990  Bf:10  EN:0.2751  Loss: 7.034 4.463 4.021\n",
      "Ep:1830   Rew:-108.13  Avg Rew:-108.90  LR:0.00009178   Polyak:0.99990  Bf:10  EN:0.2753  Loss: 6.147 2.042 2.036\n",
      "Ep:1840   Rew:-113.25  Avg Rew:-110.40  LR:0.00009208   Polyak:0.99990  Bf:10  EN:0.2762  Loss: 6.789 3.755 3.649\n",
      "Ep:1850   Rew:-113.06  Avg Rew:-110.92  LR:0.00009218   Polyak:0.99990  Bf:10  EN:0.2765  Loss: 7.529 3.473 3.660\n",
      "Ep:1860   Rew:-119.96  Avg Rew:-111.59  LR:0.00009232   Polyak:0.99990  Bf:10  EN:0.2770  Loss: 7.414 5.145 4.967\n",
      "Ep:1870   Rew:-116.37  Avg Rew:-112.67  LR:0.00009253   Polyak:0.99990  Bf:10  EN:0.2776  Loss: 7.551 4.257 4.246\n",
      "Ep:1880   Rew:-102.54  Avg Rew:-112.80  LR:0.00009256   Polyak:0.99990  Bf:10  EN:0.2777  Loss: 8.492 3.653 3.824\n",
      "Ep:1890   Rew:-104.60  Avg Rew:-113.87  LR:0.00009277   Polyak:0.99990  Bf:10  EN:0.2783  Loss: 7.854 3.803 4.324\n",
      "Ep:1900   Rew:-119.99  Avg Rew:-114.42  LR:0.00009288   Polyak:0.99990  Bf:10  EN:0.2786  Loss: 5.897 3.064 3.084\n",
      "Ep:1910   Rew:-110.03  Avg Rew:-114.77  LR:0.00009295   Polyak:0.99990  Bf:10  EN:0.2789  Loss: 7.982 2.820 3.254\n",
      "Ep:1920   Rew:-112.82  Avg Rew:-114.79  LR:0.00009296   Polyak:0.99990  Bf:10  EN:0.2789  Loss: 8.256 3.631 3.285\n",
      "Ep:1930   Rew:-107.32  Avg Rew:-114.43  LR:0.00009289   Polyak:0.99990  Bf:10  EN:0.2787  Loss: 8.779 3.616 3.916\n",
      "Ep:1940   Rew:-121.07  Avg Rew:-113.94  LR:0.00009279   Polyak:0.99990  Bf:10  EN:0.2784  Loss: 9.621 2.838 3.308\n",
      "Ep:1950   Rew:-111.60  Avg Rew:-113.40  LR:0.00009268   Polyak:0.99990  Bf:10  EN:0.2780  Loss: 8.319 3.203 3.938\n",
      "Ep:1960   Rew:-108.87  Avg Rew:-112.94  LR:0.00009259   Polyak:0.99990  Bf:10  EN:0.2778  Loss: 9.093 4.635 4.386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1970   Rew:-116.95  Avg Rew:-112.58  LR:0.00009252   Polyak:0.99990  Bf:10  EN:0.2775  Loss: 7.119 2.351 2.472\n",
      "Ep:1980   Rew:-119.68  Avg Rew:-112.74  LR:0.00009255   Polyak:0.99990  Bf:10  EN:0.2776  Loss: 8.336 4.245 4.295\n",
      "Ep:1990   Rew:-117.73  Avg Rew:-112.36  LR:0.00009247   Polyak:0.99990  Bf:10  EN:0.2774  Loss: 8.168 3.060 4.002\n",
      "Ep:2000   Rew:-112.57  Avg Rew:-111.98  LR:0.00009240   Polyak:0.99990  Bf:11  EN:0.2772  Loss: 8.202 3.790 3.239\n",
      "Ep:2010   Rew:-106.57  Avg Rew:-111.91  LR:0.00009238   Polyak:0.99990  Bf:11  EN:0.2771  Loss: 9.620 4.922 5.720\n",
      "Ep:2020   Rew:-107.21  Avg Rew:-111.87  LR:0.00009237   Polyak:0.99990  Bf:11  EN:0.2771  Loss: 9.690 9.340 9.233\n",
      "Ep:2030   Rew:-105.89  Avg Rew:-112.23  LR:0.00009245   Polyak:0.99990  Bf:11  EN:0.2773  Loss: 9.496 3.939 3.647\n",
      "Ep:2040   Rew:-118.67  Avg Rew:-112.36  LR:0.00009247   Polyak:0.99990  Bf:11  EN:0.2774  Loss: 8.647 3.235 3.462\n",
      "Ep:2050   Rew:-117.54  Avg Rew:-112.80  LR:0.00009256   Polyak:0.99990  Bf:11  EN:0.2777  Loss: 9.174 2.878 2.758\n",
      "Ep:2060   Rew:-123.22  Avg Rew:-113.00  LR:0.00009260   Polyak:0.99990  Bf:11  EN:0.2778  Loss: 8.381 2.473 2.735\n",
      "Ep:2070   Rew:-120.95  Avg Rew:-112.71  LR:0.00009254   Polyak:0.99990  Bf:11  EN:0.2776  Loss: 9.192 3.733 4.141\n",
      "Ep:2080   Rew:-121.91  Avg Rew:-112.41  LR:0.00009248   Polyak:0.99990  Bf:11  EN:0.2774  Loss: 8.482 2.368 2.895\n",
      "Ep:2090   Rew:-109.20  Avg Rew:-112.73  LR:0.00009255   Polyak:0.99990  Bf:11  EN:0.2776  Loss: 9.169 2.684 3.425\n",
      "Ep:2100   Rew:-116.21  Avg Rew:-113.19  LR:0.00009264   Polyak:0.99990  Bf:11  EN:0.2779  Loss: 9.463 10.255 9.904\n",
      "Ep:2110   Rew:-116.93  Avg Rew:-113.31  LR:0.00009266   Polyak:0.99990  Bf:11  EN:0.2780  Loss: 10.625 3.358 2.894\n",
      "Ep:2120   Rew:-105.87  Avg Rew:-113.41  LR:0.00009268   Polyak:0.99990  Bf:11  EN:0.2780  Loss: 8.732 2.771 3.387\n",
      "Ep:2130   Rew:-105.29  Avg Rew:-113.52  LR:0.00009270   Polyak:0.99990  Bf:11  EN:0.2781  Loss: 9.651 3.289 2.875\n",
      "Ep:2140   Rew:-115.83  Avg Rew:-113.79  LR:0.00009276   Polyak:0.99990  Bf:11  EN:0.2783  Loss: 9.645 3.026 3.400\n",
      "Ep:2150   Rew:-121.01  Avg Rew:-114.12  LR:0.00009282   Polyak:0.99990  Bf:11  EN:0.2785  Loss: 8.433 2.616 2.424\n",
      "Ep:2160   Rew:-116.03  Avg Rew:-114.22  LR:0.00009284   Polyak:0.99990  Bf:11  EN:0.2785  Loss: 9.761 3.448 3.279\n",
      "Ep:2170   Rew:-107.17  Avg Rew:-114.72  LR:0.00009294   Polyak:0.99990  Bf:11  EN:0.2788  Loss: 9.524 3.762 4.568\n",
      "Ep:2180   Rew:-123.52  Avg Rew:-115.09  LR:0.00009302   Polyak:0.99990  Bf:11  EN:0.2791  Loss: 8.412 4.913 4.144\n",
      "Ep:2190   Rew:-116.41  Avg Rew:-115.19  LR:0.00009304   Polyak:0.99990  Bf:11  EN:0.2791  Loss: 8.992 4.341 4.489\n",
      "Ep:2200   Rew:-122.36  Avg Rew:-115.27  LR:0.00009305   Polyak:0.99990  Bf:11  EN:0.2792  Loss: 9.907 2.194 2.423\n",
      "Ep:2210   Rew:-111.50  Avg Rew:-115.60  LR:0.00009312   Polyak:0.99990  Bf:11  EN:0.2794  Loss: 10.730 2.729 2.794\n",
      "Ep:2220   Rew:-128.43  Avg Rew:-116.08  LR:0.00009322   Polyak:0.99990  Bf:12  EN:0.2796  Loss: 8.726 3.358 3.171\n",
      "Ep:2230   Rew:-107.04  Avg Rew:-116.36  LR:0.00009327   Polyak:0.99990  Bf:12  EN:0.2798  Loss: 9.710 3.000 2.654\n",
      "Ep:2240   Rew:-117.73  Avg Rew:-116.19  LR:0.00009324   Polyak:0.99990  Bf:12  EN:0.2797  Loss: 11.043 2.081 2.114\n",
      "Ep:2250   Rew:-109.39  Avg Rew:-115.86  LR:0.00009317   Polyak:0.99990  Bf:12  EN:0.2795  Loss: 9.784 2.264 2.304\n",
      "Ep:2260   Rew:-114.18  Avg Rew:-116.46  LR:0.00009329   Polyak:0.99990  Bf:12  EN:0.2799  Loss: 10.307 5.574 5.094\n",
      "Ep:2270   Rew:-107.48  Avg Rew:-115.88  LR:0.00009318   Polyak:0.99990  Bf:12  EN:0.2795  Loss: 8.764 2.378 2.267\n",
      "Ep:2280   Rew:-123.34  Avg Rew:-115.97  LR:0.00009319   Polyak:0.99990  Bf:12  EN:0.2796  Loss: 10.675 2.532 1.883\n",
      "Ep:2290   Rew:-107.04  Avg Rew:-116.16  LR:0.00009323   Polyak:0.99990  Bf:12  EN:0.2797  Loss: 9.188 2.559 1.761\n",
      "Ep:2300   Rew:-114.30  Avg Rew:-115.81  LR:0.00009316   Polyak:0.99990  Bf:12  EN:0.2795  Loss: 10.447 4.155 4.278\n",
      "Ep:2310   Rew:-116.71  Avg Rew:-115.47  LR:0.00009309   Polyak:0.99990  Bf:12  EN:0.2793  Loss: 9.173 2.073 2.215\n",
      "Ep:2320   Rew:-125.30  Avg Rew:-114.91  LR:0.00009298   Polyak:0.99990  Bf:12  EN:0.2789  Loss: 9.410 2.016 2.135\n",
      "Ep:2330   Rew:-123.65  Avg Rew:-114.80  LR:0.00009296   Polyak:0.99990  Bf:12  EN:0.2789  Loss: 9.832 3.714 4.034\n",
      "Ep:2340   Rew:-105.32  Avg Rew:-114.69  LR:0.00009294   Polyak:0.99990  Bf:12  EN:0.2788  Loss: 8.838 2.068 1.907\n",
      "Ep:2350   Rew:-130.87  Avg Rew:-114.63  LR:0.00009293   Polyak:0.99990  Bf:12  EN:0.2788  Loss: 9.753 1.862 2.359\n",
      "Ep:2360   Rew:-108.67  Avg Rew:-114.49  LR:0.00009290   Polyak:0.99990  Bf:12  EN:0.2787  Loss: 12.534 3.031 2.429\n",
      "Ep:2370   Rew:-105.23  Avg Rew:-114.23  LR:0.00009285   Polyak:0.99990  Bf:12  EN:0.2785  Loss: 9.693 2.097 2.154\n",
      "Ep:2380   Rew:-114.62  Avg Rew:-113.87  LR:0.00009277   Polyak:0.99990  Bf:12  EN:0.2783  Loss: 10.247 2.771 2.753\n",
      "Ep:2390   Rew:-106.34  Avg Rew:-113.45  LR:0.00009269   Polyak:0.99990  Bf:12  EN:0.2781  Loss: 11.356 2.444 2.405\n",
      "Ep:2400   Rew:-108.80  Avg Rew:-113.70  LR:0.00009274   Polyak:0.99990  Bf:12  EN:0.2782  Loss: 10.851 1.866 1.771\n",
      "Ep:2410   Rew:-121.63  Avg Rew:-113.83  LR:0.00009277   Polyak:0.99990  Bf:12  EN:0.2783  Loss: 11.392 2.580 3.020\n",
      "Ep:2420   Rew:-126.43  Avg Rew:-113.76  LR:0.00009275   Polyak:0.99990  Bf:12  EN:0.2783  Loss: 12.129 8.488 8.444\n",
      "Ep:2430   Rew:-118.43  Avg Rew:-113.89  LR:0.00009278   Polyak:0.99990  Bf:12  EN:0.2783  Loss: 9.264 2.579 3.088\n",
      "Ep:2440   Rew:-102.28  Avg Rew:-113.70  LR:0.00009274   Polyak:0.99990  Bf:13  EN:0.2782  Loss: 9.905 2.342 2.247\n",
      "Ep:2450   Rew:-106.28  Avg Rew:-113.31  LR:0.00009266   Polyak:0.99990  Bf:13  EN:0.2780  Loss: 11.230 2.096 2.088\n",
      "Ep:2460   Rew:-121.18  Avg Rew:-112.73  LR:0.00009255   Polyak:0.99990  Bf:13  EN:0.2776  Loss: 11.545 1.997 1.859\n",
      "Ep:2470   Rew:-104.36  Avg Rew:-113.18  LR:0.00009264   Polyak:0.99990  Bf:13  EN:0.2779  Loss: 12.309 2.783 2.665\n",
      "Ep:2480   Rew:-107.89  Avg Rew:-113.09  LR:0.00009262   Polyak:0.99990  Bf:13  EN:0.2779  Loss: 10.704 2.660 2.450\n",
      "Ep:2490   Rew:-104.80  Avg Rew:-113.41  LR:0.00009268   Polyak:0.99990  Bf:13  EN:0.2780  Loss: 10.194 1.798 1.625\n",
      "Ep:2500   Rew:-113.73  Avg Rew:-113.15  LR:0.00009263   Polyak:0.99990  Bf:13  EN:0.2779  Loss: 10.225 1.865 1.901\n",
      "Ep:2510   Rew:-114.91  Avg Rew:-113.02  LR:0.00009260   Polyak:0.99990  Bf:13  EN:0.2778  Loss: 10.443 2.575 8.652\n",
      "Ep:2520   Rew:-100.18  Avg Rew:-112.98  LR:0.00009260   Polyak:0.99990  Bf:13  EN:0.2778  Loss: 11.050 2.416 2.283\n",
      "Ep:2530   Rew:-116.84  Avg Rew:-112.61  LR:0.00009252   Polyak:0.99990  Bf:13  EN:0.2776  Loss: 10.533 2.521 2.781\n",
      "Ep:2540   Rew:-104.79  Avg Rew:-113.20  LR:0.00009264   Polyak:0.99990  Bf:13  EN:0.2779  Loss: 10.720 2.373 2.633\n",
      "Ep:2550   Rew:-115.95  Avg Rew:-113.76  LR:0.00009275   Polyak:0.99990  Bf:13  EN:0.2783  Loss: 11.628 2.959 2.970\n",
      "Ep:2560   Rew:-103.27  Avg Rew:-114.11  LR:0.00009282   Polyak:0.99990  Bf:13  EN:0.2785  Loss: 10.708 1.741 2.342\n",
      "Ep:2570   Rew:-116.22  Avg Rew:-114.65  LR:0.00009293   Polyak:0.99990  Bf:13  EN:0.2788  Loss: 10.794 2.690 2.415\n",
      "Ep:2580   Rew:-114.27  Avg Rew:-115.14  LR:0.00009303   Polyak:0.99990  Bf:13  EN:0.2791  Loss: 11.882 2.214 8.464\n",
      "Ep:2590   Rew:-127.25  Avg Rew:-115.24  LR:0.00009305   Polyak:0.99990  Bf:13  EN:0.2791  Loss: 13.184 2.798 2.647\n",
      "Ep:2600   Rew:-126.05  Avg Rew:-115.67  LR:0.00009313   Polyak:0.99990  Bf:13  EN:0.2794  Loss: 12.513 3.455 3.466\n",
      "Ep:2610   Rew:-104.39  Avg Rew:-115.96  LR:0.00009319   Polyak:0.99990  Bf:13  EN:0.2796  Loss: 12.767 3.034 2.746\n",
      "Ep:2620   Rew:-104.22  Avg Rew:-116.49  LR:0.00009330   Polyak:0.99990  Bf:13  EN:0.2799  Loss: 12.012 1.701 1.676\n",
      "Ep:2630   Rew:-123.10  Avg Rew:-116.65  LR:0.00009333   Polyak:0.99990  Bf:13  EN:0.2800  Loss: 10.880 2.285 2.635\n",
      "Ep:2640   Rew:-114.60  Avg Rew:-116.75  LR:0.00009335   Polyak:0.99990  Bf:13  EN:0.2801  Loss: 10.884 2.056 1.989\n",
      "Ep:2650   Rew:-111.03  Avg Rew:-117.15  LR:0.00009343   Polyak:0.99990  Bf:13  EN:0.2803  Loss: 10.400 3.233 3.137\n",
      "Ep:2660   Rew:-106.81  Avg Rew:-117.34  LR:0.00009347   Polyak:0.99990  Bf:13  EN:0.2804  Loss: 11.837 1.997 2.343\n",
      "Ep:2670   Rew:-116.99  Avg Rew:-117.14  LR:0.00009343   Polyak:0.99990  Bf:13  EN:0.2803  Loss: 13.352 2.751 3.033\n",
      "Ep:2680   Rew:-123.09  Avg Rew:-117.71  LR:0.00009354   Polyak:0.99990  Bf:14  EN:0.2806  Loss: 12.358 2.169 3.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2690   Rew:-121.60  Avg Rew:-118.31  LR:0.00009366   Polyak:0.99990  Bf:14  EN:0.2810  Loss: 12.109 2.007 1.769\n",
      "Ep:2700   Rew:-120.59  Avg Rew:-118.63  LR:0.00009373   Polyak:0.99990  Bf:14  EN:0.2812  Loss: 14.330 2.953 2.777\n",
      "Ep:2710   Rew:-126.39  Avg Rew:-119.41  LR:0.00009388   Polyak:0.99990  Bf:14  EN:0.2816  Loss: 13.824 6.412 6.296\n",
      "Ep:2720   Rew:-107.86  Avg Rew:-120.00  LR:0.00009400   Polyak:0.99990  Bf:14  EN:0.2820  Loss: 12.386 2.404 2.626\n",
      "Ep:2730   Rew:-118.93  Avg Rew:-121.05  LR:0.00009421   Polyak:0.99990  Bf:14  EN:0.2826  Loss: 12.896 2.484 2.401\n",
      "Ep:2740   Rew:-128.27  Avg Rew:-121.15  LR:0.00009423   Polyak:0.99990  Bf:14  EN:0.2827  Loss: 12.337 1.760 1.854\n",
      "Ep:2750   Rew:-106.90  Avg Rew:-121.42  LR:0.00009428   Polyak:0.99990  Bf:14  EN:0.2829  Loss: 12.913 3.228 3.065\n",
      "Ep:2760   Rew:-137.93  Avg Rew:-121.73  LR:0.00009435   Polyak:0.99990  Bf:14  EN:0.2830  Loss: 11.987 2.312 2.160\n",
      "Ep:2770   Rew:-135.48  Avg Rew:-122.51  LR:0.00009450   Polyak:0.99990  Bf:14  EN:0.2835  Loss: 12.411 2.200 2.725\n",
      "Ep:2780   Rew:-110.44  Avg Rew:-121.78  LR:0.00009436   Polyak:0.99990  Bf:14  EN:0.2831  Loss: 12.927 2.317 2.377\n",
      "Ep:2790   Rew:-132.51  Avg Rew:-122.04  LR:0.00009441   Polyak:0.99990  Bf:14  EN:0.2832  Loss: 13.363 2.258 2.318\n",
      "Ep:2800   Rew:-125.61  Avg Rew:-123.47  LR:0.00009469   Polyak:0.99990  Bf:14  EN:0.2841  Loss: 13.094 1.824 2.055\n",
      "Ep:2810   Rew:-105.77  Avg Rew:-124.97  LR:0.00009499   Polyak:0.99990  Bf:15  EN:0.2850  Loss: 13.144 4.660 4.338\n",
      "Ep:2820   Rew:-106.87  Avg Rew:-124.73  LR:0.00009495   Polyak:0.99990  Bf:15  EN:0.2848  Loss: 11.351 2.354 2.289\n",
      "Ep:2830   Rew:-103.75  Avg Rew:-123.26  LR:0.00009465   Polyak:0.99990  Bf:15  EN:0.2840  Loss: 12.563 2.792 2.516\n",
      "Ep:2840   Rew:-107.18  Avg Rew:-122.88  LR:0.00009458   Polyak:0.99990  Bf:15  EN:0.2837  Loss: 12.240 2.664 2.797\n",
      "Ep:2850   Rew:-123.08  Avg Rew:-122.47  LR:0.00009449   Polyak:0.99990  Bf:15  EN:0.2835  Loss: 13.809 1.953 1.632\n",
      "Ep:2860   Rew:-119.30  Avg Rew:-121.77  LR:0.00009435   Polyak:0.99990  Bf:15  EN:0.2831  Loss: 13.271 1.922 1.988\n",
      "Ep:2870   Rew:-130.61  Avg Rew:-121.05  LR:0.00009421   Polyak:0.99990  Bf:16  EN:0.2826  Loss: 13.867 2.683 2.644\n",
      "Ep:2880   Rew:-103.71  Avg Rew:-120.43  LR:0.00009409   Polyak:0.99990  Bf:16  EN:0.2823  Loss: 11.406 1.333 1.428\n",
      "Ep:2890   Rew:-122.59  Avg Rew:-119.26  LR:0.00009385   Polyak:0.99990  Bf:16  EN:0.2816  Loss: 12.567 1.579 1.563\n",
      "Ep:2900   Rew:-123.03  Avg Rew:-117.23  LR:0.00009345   Polyak:0.99990  Bf:16  EN:0.2803  Loss: 12.799 2.045 2.131\n",
      "Ep:2910   Rew:-116.29  Avg Rew:-114.51  LR:0.00009290   Polyak:0.99990  Bf:16  EN:0.2787  Loss: 12.510 2.147 2.075\n",
      "Ep:2920   Rew:-139.60  Avg Rew:-114.47  LR:0.00009289   Polyak:0.99990  Bf:16  EN:0.2787  Loss: 13.938 2.497 2.514\n",
      "Ep:2930   Rew:-101.37  Avg Rew:-114.76  LR:0.00009295   Polyak:0.99990  Bf:16  EN:0.2789  Loss: 12.696 1.733 2.075\n",
      "Ep:2940   Rew:-125.22  Avg Rew:-114.08  LR:0.00009282   Polyak:0.99990  Bf:16  EN:0.2784  Loss: 14.089 1.783 1.861\n",
      "Ep:2950   Rew:-93.72  Avg Rew:-113.25  LR:0.00009265   Polyak:0.99990  Bf:16  EN:0.2779  Loss: 12.772 2.863 3.013\n",
      "Ep:2960   Rew:-118.16  Avg Rew:-113.72  LR:0.00009274   Polyak:0.99990  Bf:16  EN:0.2782  Loss: 12.935 1.579 1.661\n",
      "Ep:2970   Rew:-94.60  Avg Rew:-112.72  LR:0.00009254   Polyak:0.99990  Bf:16  EN:0.2776  Loss: 12.183 2.611 2.805\n",
      "Ep:2980   Rew:-135.52  Avg Rew:-113.28  LR:0.00009266   Polyak:0.99990  Bf:16  EN:0.2780  Loss: 13.626 2.812 2.748\n",
      "Ep:2990   Rew:-96.38  Avg Rew:-112.76  LR:0.00009255   Polyak:0.99990  Bf:16  EN:0.2777  Loss: 12.729 1.755 1.992\n",
      "Ep:3000   Rew:-126.16  Avg Rew:-112.22  LR:0.00009244   Polyak:0.99990  Bf:17  EN:0.2773  Loss: 13.868 2.464 2.679\n",
      "Ep:3010   Rew:-104.49  Avg Rew:-112.01  LR:0.00009240   Polyak:0.99990  Bf:17  EN:0.2772  Loss: 11.858 1.713 1.798\n",
      "Ep:3020   Rew:-106.96  Avg Rew:-110.97  LR:0.00009219   Polyak:0.99990  Bf:17  EN:0.2766  Loss: 13.210 1.566 1.608\n",
      "Ep:3030   Rew:-100.63  Avg Rew:-110.55  LR:0.00009211   Polyak:0.99990  Bf:17  EN:0.2763  Loss: 13.245 2.966 2.674\n",
      "Ep:3040   Rew:-100.62  Avg Rew:-110.67  LR:0.00009213   Polyak:0.99990  Bf:17  EN:0.2764  Loss: 12.793 2.157 2.304\n",
      "Ep:3050   Rew:-105.02  Avg Rew:-110.87  LR:0.00009217   Polyak:0.99990  Bf:17  EN:0.2765  Loss: 14.352 1.898 1.935\n",
      "Ep:3060   Rew:-119.01  Avg Rew:-110.52  LR:0.00009210   Polyak:0.99990  Bf:17  EN:0.2763  Loss: 12.806 2.094 2.236\n",
      "Ep:3070   Rew:-115.04  Avg Rew:-112.14  LR:0.00009243   Polyak:0.99990  Bf:17  EN:0.2773  Loss: 14.354 3.083 2.694\n",
      "Ep:3080   Rew:-121.91  Avg Rew:-112.38  LR:0.00009248   Polyak:0.99990  Bf:17  EN:0.2774  Loss: 14.249 2.284 1.916\n",
      "Ep:3090   Rew:-94.06  Avg Rew:-113.44  LR:0.00009269   Polyak:0.99990  Bf:17  EN:0.2781  Loss: 12.694 1.279 1.298\n",
      "Ep:3100   Rew:-102.98  Avg Rew:-113.48  LR:0.00009270   Polyak:0.99990  Bf:18  EN:0.2781  Loss: 14.546 1.959 1.828\n",
      "Ep:3110   Rew:-97.03  Avg Rew:-113.15  LR:0.00009263   Polyak:0.99990  Bf:18  EN:0.2779  Loss: 13.915 2.365 2.498\n",
      "Ep:3120   Rew:-102.88  Avg Rew:-112.81  LR:0.00009256   Polyak:0.99990  Bf:18  EN:0.2777  Loss: 12.611 1.641 1.724\n",
      "Ep:3130   Rew:-107.88  Avg Rew:-112.97  LR:0.00009259   Polyak:0.99990  Bf:18  EN:0.2778  Loss: 14.163 1.681 1.669\n",
      "Ep:3140   Rew:-102.99  Avg Rew:-113.38  LR:0.00009268   Polyak:0.99990  Bf:18  EN:0.2780  Loss: 14.094 1.901 1.942\n",
      "Ep:3150   Rew:-104.94  Avg Rew:-113.09  LR:0.00009262   Polyak:0.99990  Bf:18  EN:0.2779  Loss: 13.616 2.051 2.472\n",
      "Ep:3160   Rew:-101.60  Avg Rew:-112.32  LR:0.00009246   Polyak:0.99990  Bf:18  EN:0.2774  Loss: 13.253 2.380 2.340\n",
      "Ep:3170   Rew:-123.18  Avg Rew:-111.42  LR:0.00009228   Polyak:0.99990  Bf:18  EN:0.2769  Loss: 12.890 2.288 2.339\n",
      "Ep:3180   Rew:-107.87  Avg Rew:-110.81  LR:0.00009216   Polyak:0.99990  Bf:18  EN:0.2765  Loss: 12.369 1.299 1.766\n",
      "Ep:3190   Rew:-118.56  Avg Rew:-109.84  LR:0.00009197   Polyak:0.99990  Bf:18  EN:0.2759  Loss: 13.985 7.692 8.994\n",
      "Ep:3200   Rew:-102.93  Avg Rew:-109.54  LR:0.00009191   Polyak:0.99990  Bf:18  EN:0.2757  Loss: 13.863 2.011 2.295\n",
      "Ep:3210   Rew:-103.84  Avg Rew:-109.39  LR:0.00009188   Polyak:0.99990  Bf:19  EN:0.2756  Loss: 13.535 1.731 1.858\n",
      "Ep:3220   Rew:-117.54  Avg Rew:-109.83  LR:0.00009197   Polyak:0.99990  Bf:19  EN:0.2759  Loss: 13.883 2.145 2.019\n",
      "Ep:3230   Rew:-93.26  Avg Rew:-109.88  LR:0.00009198   Polyak:0.99990  Bf:19  EN:0.2759  Loss: 13.414 2.105 1.760\n",
      "Ep:3240   Rew:-113.28  Avg Rew:-109.27  LR:0.00009185   Polyak:0.99990  Bf:19  EN:0.2756  Loss: 13.673 1.738 1.846\n",
      "Ep:3250   Rew:-112.62  Avg Rew:-109.12  LR:0.00009182   Polyak:0.99990  Bf:19  EN:0.2755  Loss: 13.360 2.045 1.924\n",
      "Ep:3260   Rew:-105.44  Avg Rew:-108.85  LR:0.00009177   Polyak:0.99990  Bf:19  EN:0.2753  Loss: 13.147 1.817 1.738\n",
      "Ep:3270   Rew:-104.76  Avg Rew:-107.77  LR:0.00009155   Polyak:0.99990  Bf:19  EN:0.2747  Loss: 13.111 2.226 2.002\n",
      "Ep:3280   Rew:-103.16  Avg Rew:-107.57  LR:0.00009151   Polyak:0.99990  Bf:19  EN:0.2745  Loss: 15.870 1.649 1.660\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5faf752aa9e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 episode, ep_reward, avg_reward, learning_rate, polyak, replay_buffer.get_fill(), exploration_noise, policy.actor_loss, policy.loss_Q1, policy.loss_Q2))\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-5faf752aa9e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# if episode is done then update policy:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_timesteps\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolyak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_delay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/gym/bipedal_walker_hardcore/TD3_torch/TD3.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, replay_buffer, n_iter, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# Optimize Critic 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mcurrent_Q1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_Q1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_Q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_Q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_1_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_Q1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pointwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[0;34m(lambd, lambd_optimized, input, target, reduction)\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elementwise_mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "from TD3_torch.TD3 import TD3\n",
    "from PIL import Image\n",
    "from TD3_torch.utils import ReplayBuffer\n",
    "\n",
    "env_name = 'BipedalWalkerHardcore-v2'\n",
    "learning_rate_base = 0.0001\n",
    "log_interval = 10           # print avg reward after interval\n",
    "random_seed = 123\n",
    "gamma = 0.99                # discount for future rewards\n",
    "batch_size = 1024        # num of transitions sampled from replay buffer\n",
    "exploration_noise_base = 0.3 \n",
    "polyak_int = [0.9999, 0.999999]              # target policy update parameter (1-tau)\n",
    "policy_noise = 0.2          # target policy smoothing noise\n",
    "noise_clip = 0.5\n",
    "policy_delay = 2            # delayed policy updates parameter\n",
    "max_episodes = 100000         # max num of episodes\n",
    "max_timesteps = 3000        # max timesteps in one episode\n",
    "max_buffer_length = 2000000\n",
    "directory = \"./preTrained/td3_torch/{}\".format(env_name) # save trained models\n",
    "filename = \"TD3_torch_{}_{}\".format(env_name, random_seed)\n",
    "reward_history = []\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    polyak = polyak_int[0]\n",
    "    exploration_noise = exploration_noise_base\n",
    "    \n",
    "    actor_config = [\n",
    "        {'dim': (state_dim, 256), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (256, 256), 'dropout': True, 'activation':'relu'},\n",
    "        {'dim': (256, 128), 'dropout': True, 'activation': 'relu'},\n",
    "        {'dim': (128, 64), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (64, action_dim),'dropout': False, 'activation': False}\n",
    "    ]\n",
    "    \n",
    "    critic_config = [\n",
    "        {'dim': (state_dim + action_dim, 256), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (256, 320), 'dropout': False , 'activation':'relu'},\n",
    "        {'dim': (320, 160), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (160, 1), 'dropout': False, 'activation': False}\n",
    "    ]\n",
    "    \n",
    "    policy = TD3(actor_config, critic_config, max_action, lr=learning_rate_base)   \n",
    "    replay_buffer = ReplayBuffer(max_length=max_buffer_length)\n",
    "    \n",
    "    print(\"action_space={}\".format(env.action_space))\n",
    "    print(\"obs_space={}\".format(env.observation_space))\n",
    "    print(\"threshold={} \\n\".format(env.spec.reward_threshold))     \n",
    "    \n",
    "    if random_seed:\n",
    "        print(\"Random Seed: {}\".format(random_seed))\n",
    "        env.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # loading models\n",
    "    policy.load(directory, filename)\n",
    "    \n",
    "    # logging variables:        \n",
    "    log_f = open(\"log.txt\",\"w+\")\n",
    "    \n",
    "    # training procedure:\n",
    "    for episode in range(1, max_episodes+1):\n",
    "        ep_reward = 0\n",
    "        state = env.reset()\n",
    "       \n",
    "        for t in range(max_timesteps):\n",
    "            # select action and add exploration noise:\n",
    "            action = policy.select_action(state)\n",
    "            action = action + np.random.normal(0, exploration_noise, size=env.action_space.shape[0])\n",
    "            action = action.clip(env.action_space.low, env.action_space.high)\n",
    "            \n",
    "            # take action in env:\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            replay_buffer.add((state, action, reward, next_state, float(done)))\n",
    "            state = next_state\n",
    "            \n",
    "            ep_reward += reward\n",
    "            \n",
    "            # if episode is done then update policy:\n",
    "            if done or t==(max_timesteps-1):\n",
    "                policy.update(replay_buffer, t, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay)\n",
    "                break\n",
    "        \n",
    "        reward_history.append(ep_reward)\n",
    "        avg_reward = np.mean(reward_history[-100:]) \n",
    "        \n",
    "        # logging updates:        \n",
    "        log_f.write('{},{}\\n'.format(episode, ep_reward))\n",
    "        log_f.flush()\n",
    "       \n",
    "        \n",
    "        # if avg reward > 300 then save and stop traning:\n",
    "        if avg_reward >= env.spec.reward_threshold: \n",
    "            print(\"########## Solved! ###########\")\n",
    "            name = filename + '_solved'\n",
    "            policy.save(directory, name)\n",
    "            log_f.close()\n",
    "            break\n",
    "            \n",
    "        # Calculate polyak\n",
    "        #part = (env.spec.reward_threshold - avg_reward) / (env.spec.reward_threshold + 150)\n",
    "        #if part > 1:\n",
    "        #    part = 1\n",
    "        #polyak = polyak_int[0] + (1 - part) * (polyak_int[1] - polyak_int[0])     \n",
    "        \n",
    "        # Calculate LR\n",
    "        part = (env.spec.reward_threshold - avg_reward) / (env.spec.reward_threshold + 150)\n",
    "        if part > 1:\n",
    "            part = 1\n",
    "        learning_rate = learning_rate_base - learning_rate_base * (1 - part) * 0.9\n",
    "        policy.set_optimizers(lr=learning_rate)\n",
    "        \n",
    "        # Calculate Exploration Noise\n",
    "        exploration_noise = exploration_noise_base - exploration_noise_base * (1 - part) * 0.9\n",
    "        \n",
    "        \n",
    "        if episode > 500:\n",
    "            policy.save(directory, filename)\n",
    "        \n",
    "        # print avg reward every log interval:\n",
    "        if episode % log_interval == 0:            \n",
    "            print(\"Ep:{}   Rew:{:3.2f}  Avg Rew:{:3.2f}  LR:{:8.8f}   Polyak:{:5.5f}  Bf:{:2.0f}  EN:{:0.4f}  Loss: {:5.3f} {:5.3f} {:5.3f}\".format(\n",
    "                episode, ep_reward, avg_reward, learning_rate, polyak, replay_buffer.get_fill(), exploration_noise, policy.actor_loss, policy.loss_Q1, policy.loss_Q2))\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():  \n",
    "    random_seed = 0\n",
    "    n_episodes = 3\n",
    "    max_timesteps = 2000\n",
    "    render = True\n",
    "    save_gif = True\n",
    "    \n",
    "    filename = \"TD3_torch_{}_{}\".format(env_name, random_seed)\n",
    "    filename += ''\n",
    "    directory = \"./preTrained/td3_torch/{}\".format(env_name)\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    \n",
    "    policy = TD3(state_dim, action_dim, max_action)\n",
    "    \n",
    "    policy.load_actor(directory, filename)\n",
    "    \n",
    "    for ep in range(1, n_episodes+1):\n",
    "        ep_reward = 0\n",
    "        state = env.reset()\n",
    "        for t in range(max_timesteps):\n",
    "            action = policy.select_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            ep_reward += reward\n",
    "            if render:\n",
    "                env.render()\n",
    "                if save_gif:\n",
    "                    dirname = './gif/td3_torch/{}'.format(ep)\n",
    "                    if not os.path.isdir(dirname):\n",
    "                        os.mkdir(dirname)\n",
    "                    img = env.render(mode = 'rgb_array')\n",
    "                    img = Image.fromarray(img)\n",
    "                    img.save('./gif/td3_torch/{}/{}.jpg'.format(ep,t))\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        print('Episode: {}\\tReward: {}'.format(ep, int(ep_reward)))\n",
    "        ep_reward = 0\n",
    "        env.close()        \n",
    "                \n",
    "test()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
