{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "ACTOR=Sequential(\n",
      "  (0): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=160, out_features=64, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n",
      "ACTOR=Sequential(\n",
      "  (0): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=160, out_features=64, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=320, bias=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "action_space=Box(4,)\n",
      "obs_space=Box(24,)\n",
      "threshold=300 \n",
      "\n",
      "Random Seed: 555\n",
      "DIR=./preTrained/td3_torch/BipedalWalkerHardcore-v2 NAME=TD3_torch_BipedalWalkerHardcore-v2_555\n",
      "Models loaded\n",
      "Ep: 10   Rew: -59.84   Avg Rew: -72.63   LR: 0.00008453   Polyak: 0.999900   Bf:  1   Loss: 3.506  0.191  0.196\n",
      "Ep: 20   Rew: -56.52   Avg Rew: -68.56   LR: 0.00008371   Polyak: 0.999900   Bf:  2   Loss: 3.227  0.012  0.010\n",
      "Ep: 30   Rew: -71.38   Avg Rew: -67.97   LR: 0.00008359   Polyak: 0.999900   Bf:  3   Loss: 3.207  0.027  0.030\n",
      "Ep: 40   Rew: -57.11   Avg Rew: -66.33   LR: 0.00008327   Polyak: 0.999900   Bf:  4   Loss: 3.103  0.025  0.022\n",
      "Ep: 50   Rew: -48.47   Avg Rew: -64.37   LR: 0.00008287   Polyak: 0.999900   Bf:  5   Loss: 3.159  0.090  0.077\n",
      "Ep: 60   Rew: -58.09   Avg Rew: -64.53   LR: 0.00008291   Polyak: 0.999900   Bf:  6   Loss: 3.088  0.030  0.020\n",
      "Ep: 70   Rew: -96.10   Avg Rew: -64.09   LR: 0.00008282   Polyak: 0.999900   Bf:  7   Loss: 3.204  0.007  0.009\n",
      "Ep: 80   Rew: -101.00   Avg Rew: -64.37   LR: 0.00008287   Polyak: 0.999900   Bf:  8   Loss: 3.173  0.017  0.020\n",
      "Ep: 90   Rew: -44.46   Avg Rew: -63.87   LR: 0.00008277   Polyak: 0.999900   Bf:  9   Loss: 3.232  0.017  0.021\n",
      "Ep: 100   Rew: -59.51   Avg Rew: -67.17   LR: 0.00008343   Polyak: 0.999900   Bf: 10   Loss: 3.540  0.049  0.243\n",
      "Ep: 110   Rew: -47.78   Avg Rew: -65.72   LR: 0.00008314   Polyak: 0.999900   Bf: 11   Loss: 3.556  0.127  0.140\n",
      "Ep: 120   Rew: -87.49   Avg Rew: -65.75   LR: 0.00008315   Polyak: 0.999900   Bf: 12   Loss: 3.725  0.027  0.029\n",
      "Ep: 130   Rew: -160.09   Avg Rew: -65.99   LR: 0.00008320   Polyak: 0.999900   Bf: 13   Loss: 3.691  0.154  0.134\n",
      "Ep: 140   Rew: -43.49   Avg Rew: -66.57   LR: 0.00008331   Polyak: 0.999900   Bf: 14   Loss: 3.884  0.071  0.083\n",
      "Ep: 150   Rew: -87.78   Avg Rew: -67.49   LR: 0.00008350   Polyak: 0.999900   Bf: 15   Loss: 3.787  0.027  0.024\n",
      "Ep: 160   Rew: -90.17   Avg Rew: -68.00   LR: 0.00008360   Polyak: 0.999900   Bf: 16   Loss: 3.986  0.029  0.037\n",
      "Ep: 170   Rew: -56.13   Avg Rew: -69.05   LR: 0.00008381   Polyak: 0.999900   Bf: 17   Loss: 4.119  0.026  0.040\n",
      "Ep: 180   Rew: -84.06   Avg Rew: -68.57   LR: 0.00008371   Polyak: 0.999900   Bf: 18   Loss: 4.060  0.009  0.013\n",
      "Ep: 190   Rew: -56.29   Avg Rew: -69.05   LR: 0.00008381   Polyak: 0.999900   Bf: 19   Loss: 4.161  0.042  0.040\n",
      "Ep: 200   Rew: -84.84   Avg Rew: -66.30   LR: 0.00008326   Polyak: 0.999900   Bf: 20   Loss: 4.145  0.061  0.062\n",
      "Ep: 210   Rew: -44.13   Avg Rew: -66.25   LR: 0.00008325   Polyak: 0.999900   Bf: 21   Loss: 3.955  0.051  0.037\n",
      "Ep: 220   Rew: -142.63   Avg Rew: -66.68   LR: 0.00008334   Polyak: 0.999900   Bf: 22   Loss: 4.027  0.219  0.115\n",
      "Ep: 230   Rew: -56.88   Avg Rew: -66.59   LR: 0.00008332   Polyak: 0.999900   Bf: 23   Loss: 3.927  0.023  0.042\n",
      "Ep: 240   Rew: -55.22   Avg Rew: -66.27   LR: 0.00008325   Polyak: 0.999900   Bf: 24   Loss: 3.967  0.015  0.018\n",
      "Ep: 250   Rew: -89.50   Avg Rew: -66.73   LR: 0.00008335   Polyak: 0.999900   Bf: 25   Loss: 3.997  0.186  0.798\n",
      "Ep: 260   Rew: -64.27   Avg Rew: -66.11   LR: 0.00008322   Polyak: 0.999900   Bf: 26   Loss: 4.121  0.026  0.028\n",
      "Ep: 270   Rew: -52.98   Avg Rew: -64.84   LR: 0.00008297   Polyak: 0.999900   Bf: 27   Loss: 4.112  0.054  0.149\n",
      "Ep: 280   Rew: -45.22   Avg Rew: -65.17   LR: 0.00008303   Polyak: 0.999900   Bf: 28   Loss: 4.139  0.069  0.065\n",
      "Ep: 290   Rew: -62.79   Avg Rew: -65.12   LR: 0.00008302   Polyak: 0.999900   Bf: 29   Loss: 4.125  0.027  0.034\n",
      "Ep: 300   Rew: -62.72   Avg Rew: -64.69   LR: 0.00008294   Polyak: 0.999900   Bf: 30   Loss: 4.014  0.013  0.014\n",
      "Ep: 310   Rew: -79.14   Avg Rew: -65.14   LR: 0.00008303   Polyak: 0.999900   Bf: 31   Loss: 4.199  0.042  0.041\n",
      "Ep: 320   Rew: -42.11   Avg Rew: -63.99   LR: 0.00008280   Polyak: 0.999900   Bf: 32   Loss: 4.014  0.014  0.021\n",
      "Ep: 330   Rew: -62.42   Avg Rew: -62.92   LR: 0.00008258   Polyak: 0.999900   Bf: 33   Loss: 4.110  0.384  0.340\n",
      "Ep: 340   Rew: -42.83   Avg Rew: -62.15   LR: 0.00008243   Polyak: 0.999900   Bf: 34   Loss: 4.132  0.054  0.059\n",
      "Ep: 350   Rew: -51.12   Avg Rew: -61.12   LR: 0.00008222   Polyak: 0.999900   Bf: 35   Loss: 4.218  0.103  0.109\n",
      "Ep: 360   Rew: -55.29   Avg Rew: -60.32   LR: 0.00008206   Polyak: 0.999900   Bf: 36   Loss: 4.156  0.027  0.022\n",
      "Ep: 370   Rew: -53.09   Avg Rew: -60.14   LR: 0.00008203   Polyak: 0.999900   Bf: 37   Loss: 3.803  0.008  0.009\n",
      "Ep: 380   Rew: -65.29   Avg Rew: -59.52   LR: 0.00008190   Polyak: 0.999900   Bf: 38   Loss: 4.025  0.027  0.022\n",
      "Ep: 390   Rew: -50.39   Avg Rew: -58.43   LR: 0.00008169   Polyak: 0.999900   Bf: 39   Loss: 4.082  0.040  0.017\n",
      "Ep: 400   Rew: -54.33   Avg Rew: -57.64   LR: 0.00008153   Polyak: 0.999900   Bf: 40   Loss: 3.764  0.023  0.021\n",
      "Ep: 410   Rew: -57.07   Avg Rew: -56.89   LR: 0.00008138   Polyak: 0.999900   Bf: 41   Loss: 3.986  0.021  0.019\n",
      "Ep: 420   Rew: -57.60   Avg Rew: -56.44   LR: 0.00008129   Polyak: 0.999900   Bf: 42   Loss: 3.811  0.009  0.010\n",
      "Ep: 430   Rew: -58.56   Avg Rew: -56.06   LR: 0.00008121   Polyak: 0.999900   Bf: 43   Loss: 3.977  0.051  0.109\n",
      "Ep: 440   Rew: -54.35   Avg Rew: -55.63   LR: 0.00008113   Polyak: 0.999900   Bf: 44   Loss: 3.774  0.024  0.020\n",
      "Ep: 450   Rew: -54.19   Avg Rew: -55.15   LR: 0.00008103   Polyak: 0.999900   Bf: 45   Loss: 3.797  0.019  0.016\n",
      "Ep: 460   Rew: -50.75   Avg Rew: -54.62   LR: 0.00008092   Polyak: 0.999900   Bf: 46   Loss: 3.865  0.014  0.024\n",
      "Ep: 470   Rew: -57.56   Avg Rew: -54.27   LR: 0.00008085   Polyak: 0.999900   Bf: 47   Loss: 3.728  0.057  0.106\n",
      "Ep: 480   Rew: -49.57   Avg Rew: -53.55   LR: 0.00008071   Polyak: 0.999900   Bf: 48   Loss: 3.564  0.019  0.018\n",
      "Ep: 490   Rew: -51.34   Avg Rew: -53.77   LR: 0.00008075   Polyak: 0.999900   Bf: 49   Loss: 3.810  0.041  0.020\n",
      "Ep: 500   Rew: -53.63   Avg Rew: -53.03   LR: 0.00008061   Polyak: 0.999900   Bf: 50   Loss: 3.771  0.078  0.081\n",
      "Ep: 510   Rew: -48.88   Avg Rew: -53.29   LR: 0.00008066   Polyak: 0.999900   Bf: 50   Loss: 3.735  0.634  0.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 520   Rew: -54.59   Avg Rew: -53.45   LR: 0.00008069   Polyak: 0.999900   Bf: 51   Loss: 3.668  0.007  0.008\n",
      "Ep: 530   Rew: -53.91   Avg Rew: -53.33   LR: 0.00008067   Polyak: 0.999900   Bf: 52   Loss: 3.783  0.015  0.014\n",
      "Ep: 540   Rew: -55.08   Avg Rew: -53.74   LR: 0.00008075   Polyak: 0.999900   Bf: 53   Loss: 3.754  0.012  0.013\n",
      "Ep: 550   Rew: -60.48   Avg Rew: -53.75   LR: 0.00008075   Polyak: 0.999900   Bf: 54   Loss: 3.680  0.007  0.010\n",
      "Ep: 560   Rew: -59.55   Avg Rew: -54.00   LR: 0.00008080   Polyak: 0.999900   Bf: 55   Loss: 3.610  0.091  0.088\n",
      "Ep: 570   Rew: -63.45   Avg Rew: -53.74   LR: 0.00008075   Polyak: 0.999900   Bf: 56   Loss: 3.598  0.027  0.024\n",
      "Ep: 580   Rew: -55.35   Avg Rew: -53.97   LR: 0.00008079   Polyak: 0.999900   Bf: 57   Loss: 3.609  0.022  0.020\n",
      "Ep: 590   Rew: -61.73   Avg Rew: -54.15   LR: 0.00008083   Polyak: 0.999900   Bf: 58   Loss: 3.707  0.045  0.182\n",
      "Ep: 600   Rew: -38.96   Avg Rew: -54.57   LR: 0.00008091   Polyak: 0.999900   Bf: 59   Loss: 3.634  0.028  0.027\n",
      "Ep: 610   Rew: -41.59   Avg Rew: -54.28   LR: 0.00008086   Polyak: 0.999900   Bf: 60   Loss: 3.718  0.061  0.059\n",
      "Ep: 620   Rew: -66.89   Avg Rew: -54.26   LR: 0.00008085   Polyak: 0.999900   Bf: 61   Loss: 3.525  0.010  0.012\n",
      "Ep: 630   Rew: -44.73   Avg Rew: -54.16   LR: 0.00008083   Polyak: 0.999900   Bf: 62   Loss: 3.689  0.012  0.016\n",
      "Ep: 640   Rew: -65.57   Avg Rew: -53.95   LR: 0.00008079   Polyak: 0.999900   Bf: 63   Loss: 3.586  0.038  0.040\n",
      "Ep: 650   Rew: -54.28   Avg Rew: -53.84   LR: 0.00008077   Polyak: 0.999900   Bf: 64   Loss: 3.617  0.056  0.054\n",
      "Ep: 660   Rew: -57.95   Avg Rew: -53.42   LR: 0.00008068   Polyak: 0.999900   Bf: 65   Loss: 3.676  0.018  0.020\n",
      "Ep: 670   Rew: -53.31   Avg Rew: -53.75   LR: 0.00008075   Polyak: 0.999900   Bf: 66   Loss: 3.564  0.234  0.203\n",
      "Ep: 680   Rew: -66.14   Avg Rew: -53.93   LR: 0.00008079   Polyak: 0.999900   Bf: 67   Loss: 3.529  0.011  0.011\n",
      "Ep: 690   Rew: -63.63   Avg Rew: -53.23   LR: 0.00008065   Polyak: 0.999900   Bf: 68   Loss: 3.562  0.023  0.024\n",
      "Ep: 700   Rew: -42.12   Avg Rew: -53.19   LR: 0.00008064   Polyak: 0.999900   Bf: 69   Loss: 3.598  0.008  0.008\n",
      "Ep: 710   Rew: -50.09   Avg Rew: -52.64   LR: 0.00008053   Polyak: 0.999900   Bf: 70   Loss: 3.782  0.050  0.039\n",
      "Ep: 720   Rew: -57.80   Avg Rew: -52.26   LR: 0.00008045   Polyak: 0.999900   Bf: 71   Loss: 3.464  0.012  0.011\n",
      "Ep: 730   Rew: -55.25   Avg Rew: -52.33   LR: 0.00008047   Polyak: 0.999900   Bf: 72   Loss: 3.509  0.071  0.076\n",
      "Ep: 740   Rew: -52.66   Avg Rew: -52.15   LR: 0.00008043   Polyak: 0.999900   Bf: 73   Loss: 3.511  0.016  0.014\n",
      "Ep: 750   Rew: -45.66   Avg Rew: -52.02   LR: 0.00008040   Polyak: 0.999900   Bf: 74   Loss: 3.523  0.030  0.060\n",
      "Ep: 760   Rew: -56.33   Avg Rew: -52.24   LR: 0.00008045   Polyak: 0.999900   Bf: 75   Loss: 3.556  0.029  0.028\n",
      "Ep: 770   Rew: -52.79   Avg Rew: -52.00   LR: 0.00008040   Polyak: 0.999900   Bf: 76   Loss: 3.445  0.016  0.015\n",
      "Ep: 780   Rew: -55.14   Avg Rew: -51.60   LR: 0.00008032   Polyak: 0.999900   Bf: 77   Loss: 3.620  0.045  0.045\n",
      "Ep: 790   Rew: -51.58   Avg Rew: -51.85   LR: 0.00008037   Polyak: 0.999900   Bf: 78   Loss: 3.558  0.008  0.008\n",
      "Ep: 800   Rew: -60.21   Avg Rew: -51.74   LR: 0.00008035   Polyak: 0.999900   Bf: 79   Loss: 3.585  0.014  0.012\n",
      "Ep: 810   Rew: -52.93   Avg Rew: -51.99   LR: 0.00008040   Polyak: 0.999900   Bf: 80   Loss: 3.475  0.009  0.011\n",
      "Ep: 820   Rew: -47.62   Avg Rew: -52.14   LR: 0.00008043   Polyak: 0.999900   Bf: 81   Loss: 3.414  0.013  0.012\n",
      "Ep: 830   Rew: -49.86   Avg Rew: -52.78   LR: 0.00008056   Polyak: 0.999900   Bf: 82   Loss: 3.508  0.014  0.015\n",
      "Ep: 840   Rew: -51.99   Avg Rew: -52.66   LR: 0.00008053   Polyak: 0.999900   Bf: 83   Loss: 3.492  0.012  0.008\n",
      "Ep: 850   Rew: -56.19   Avg Rew: -52.63   LR: 0.00008053   Polyak: 0.999900   Bf: 84   Loss: 3.380  0.022  0.021\n",
      "Ep: 860   Rew: -51.66   Avg Rew: -52.79   LR: 0.00008056   Polyak: 0.999900   Bf: 85   Loss: 3.390  0.112  0.068\n",
      "Ep: 870   Rew: -56.00   Avg Rew: -52.94   LR: 0.00008059   Polyak: 0.999900   Bf: 86   Loss: 3.296  0.011  0.014\n",
      "Ep: 880   Rew: -53.51   Avg Rew: -52.92   LR: 0.00008058   Polyak: 0.999900   Bf: 87   Loss: 3.317  0.013  0.011\n",
      "Ep: 890   Rew: -66.50   Avg Rew: -53.22   LR: 0.00008064   Polyak: 0.999900   Bf: 88   Loss: 3.433  0.070  0.020\n",
      "Ep: 900   Rew: -44.23   Avg Rew: -52.94   LR: 0.00008059   Polyak: 0.999900   Bf: 89   Loss: 3.361  0.034  0.018\n",
      "Ep: 910   Rew: -51.91   Avg Rew: -52.84   LR: 0.00008057   Polyak: 0.999900   Bf: 90   Loss: 3.321  0.005  0.005\n",
      "Ep: 920   Rew: -50.04   Avg Rew: -52.81   LR: 0.00008056   Polyak: 0.999900   Bf: 91   Loss: 3.348  0.006  0.006\n",
      "Ep: 930   Rew: -46.12   Avg Rew: -52.21   LR: 0.00008044   Polyak: 0.999900   Bf: 92   Loss: 3.301  0.012  0.014\n",
      "Ep: 940   Rew: -47.55   Avg Rew: -51.96   LR: 0.00008039   Polyak: 0.999900   Bf: 93   Loss: 3.180  0.005  0.005\n",
      "Ep: 950   Rew: -41.99   Avg Rew: -51.47   LR: 0.00008029   Polyak: 0.999900   Bf: 94   Loss: 3.255  0.033  0.034\n",
      "Ep: 960   Rew: -53.77   Avg Rew: -51.33   LR: 0.00008027   Polyak: 0.999900   Bf: 95   Loss: 3.313  0.051  0.043\n",
      "Ep: 970   Rew: -54.79   Avg Rew: -51.18   LR: 0.00008024   Polyak: 0.999900   Bf: 96   Loss: 3.166  0.024  0.021\n",
      "Ep: 980   Rew: -64.05   Avg Rew: -51.61   LR: 0.00008032   Polyak: 0.999900   Bf: 97   Loss: 3.354  0.020  0.015\n",
      "Ep: 990   Rew: -51.85   Avg Rew: -51.31   LR: 0.00008026   Polyak: 0.999900   Bf: 98   Loss: 3.167  0.011  0.011\n",
      "Ep: 1000   Rew: -55.00   Avg Rew: -51.46   LR: 0.00008029   Polyak: 0.999900   Bf: 99   Loss: 3.224  0.008  0.009\n",
      "Ep: 1010   Rew: -51.64   Avg Rew: -51.51   LR: 0.00008030   Polyak: 0.999900   Bf: 100   Loss: 3.297  0.009  0.010\n",
      "Ep: 1020   Rew: -54.64   Avg Rew: -51.67   LR: 0.00008033   Polyak: 0.999900   Bf: 100   Loss: 3.379  0.012  0.013\n",
      "Ep: 1030   Rew: -59.35   Avg Rew: -51.53   LR: 0.00008031   Polyak: 0.999900   Bf: 100   Loss: 3.283  0.027  0.031\n",
      "Ep: 1040   Rew: -92.02   Avg Rew: -52.17   LR: 0.00008043   Polyak: 0.999900   Bf: 100   Loss: 3.254  0.013  0.012\n",
      "Ep: 1050   Rew: -55.99   Avg Rew: -52.86   LR: 0.00008057   Polyak: 0.999900   Bf: 100   Loss: 3.389  0.051  0.649\n",
      "Ep: 1060   Rew: -67.20   Avg Rew: -53.06   LR: 0.00008061   Polyak: 0.999900   Bf: 100   Loss: 3.140  0.019  0.016\n",
      "Ep: 1070   Rew: -43.34   Avg Rew: -52.63   LR: 0.00008053   Polyak: 0.999900   Bf: 100   Loss: 3.380  0.008  0.016\n",
      "Ep: 1080   Rew: -51.62   Avg Rew: -52.53   LR: 0.00008051   Polyak: 0.999900   Bf: 100   Loss: 3.328  0.011  0.011\n",
      "Ep: 1090   Rew: -45.24   Avg Rew: -52.34   LR: 0.00008047   Polyak: 0.999900   Bf: 100   Loss: 3.360  0.032  0.039\n",
      "Ep: 1100   Rew: -61.07   Avg Rew: -52.58   LR: 0.00008052   Polyak: 0.999900   Bf: 100   Loss: 3.328  0.018  0.017\n",
      "Ep: 1110   Rew: -45.07   Avg Rew: -52.70   LR: 0.00008054   Polyak: 0.999900   Bf: 100   Loss: 3.293  0.166  0.165\n",
      "Ep: 1120   Rew: -47.18   Avg Rew: -52.43   LR: 0.00008049   Polyak: 0.999900   Bf: 100   Loss: 3.317  0.006  0.005\n",
      "Ep: 1130   Rew: -45.41   Avg Rew: -52.24   LR: 0.00008045   Polyak: 0.999900   Bf: 100   Loss: 3.253  0.010  0.012\n",
      "Ep: 1140   Rew: -48.73   Avg Rew: -51.63   LR: 0.00008033   Polyak: 0.999900   Bf: 100   Loss: 3.181  0.146  0.121\n",
      "Ep: 1150   Rew: -61.10   Avg Rew: -51.94   LR: 0.00008039   Polyak: 0.999900   Bf: 100   Loss: 3.277  0.029  0.029\n",
      "Ep: 1160   Rew: -51.51   Avg Rew: -51.80   LR: 0.00008036   Polyak: 0.999900   Bf: 100   Loss: 3.331  0.006  0.006\n",
      "Ep: 1170   Rew: -47.55   Avg Rew: -53.16   LR: 0.00008063   Polyak: 0.999900   Bf: 100   Loss: 3.306  0.041  0.042\n",
      "Ep: 1180   Rew: -95.98   Avg Rew: -53.06   LR: 0.00008061   Polyak: 0.999900   Bf: 100   Loss: 3.347  0.020  0.021\n",
      "Ep: 1190   Rew: -58.69   Avg Rew: -53.02   LR: 0.00008060   Polyak: 0.999900   Bf: 100   Loss: 3.243  0.007  0.007\n",
      "Ep: 1200   Rew: -51.19   Avg Rew: -53.34   LR: 0.00008067   Polyak: 0.999900   Bf: 100   Loss: 3.251  0.009  0.008\n",
      "Ep: 1210   Rew: -44.70   Avg Rew: -53.53   LR: 0.00008071   Polyak: 0.999900   Bf: 100   Loss: 3.310  0.022  0.023\n",
      "Ep: 1220   Rew: -51.18   Avg Rew: -55.06   LR: 0.00008101   Polyak: 0.999900   Bf: 100   Loss: 3.346  0.436  0.033\n",
      "Ep: 1230   Rew: -128.56   Avg Rew: -57.61   LR: 0.00008152   Polyak: 0.999900   Bf: 100   Loss: 3.337  0.165  0.164\n",
      "Ep: 1240   Rew: -54.23   Avg Rew: -58.53   LR: 0.00008171   Polyak: 0.999900   Bf: 100   Loss: 3.366  0.014  0.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 1250   Rew: -41.06   Avg Rew: -57.79   LR: 0.00008156   Polyak: 0.999900   Bf: 100   Loss: 3.347  0.032  0.031\n",
      "Ep: 1260   Rew: -45.27   Avg Rew: -58.55   LR: 0.00008171   Polyak: 0.999900   Bf: 100   Loss: 3.311  0.008  0.006\n",
      "Ep: 1270   Rew: -38.02   Avg Rew: -57.45   LR: 0.00008149   Polyak: 0.999900   Bf: 100   Loss: 3.254  0.044  0.039\n",
      "Ep: 1280   Rew: -50.81   Avg Rew: -57.36   LR: 0.00008147   Polyak: 0.999900   Bf: 100   Loss: 3.338  0.003  0.004\n",
      "Ep: 1290   Rew: -50.70   Avg Rew: -57.65   LR: 0.00008153   Polyak: 0.999900   Bf: 100   Loss: 3.308  0.021  0.114\n",
      "Ep: 1300   Rew: -45.28   Avg Rew: -56.85   LR: 0.00008137   Polyak: 0.999900   Bf: 100   Loss: 3.251  0.013  0.013\n",
      "Ep: 1310   Rew: -54.85   Avg Rew: -56.42   LR: 0.00008128   Polyak: 0.999900   Bf: 100   Loss: 3.293  0.022  0.025\n",
      "Ep: 1320   Rew: -39.60   Avg Rew: -54.56   LR: 0.00008091   Polyak: 0.999900   Bf: 100   Loss: 3.276  0.009  0.009\n",
      "Ep: 1330   Rew: -40.75   Avg Rew: -52.03   LR: 0.00008041   Polyak: 0.999900   Bf: 100   Loss: 3.295  0.004  0.005\n",
      "Ep: 1340   Rew: -51.28   Avg Rew: -51.56   LR: 0.00008031   Polyak: 0.999900   Bf: 100   Loss: 3.327  0.004  0.005\n",
      "Ep: 1350   Rew: -55.20   Avg Rew: -51.35   LR: 0.00008027   Polyak: 0.999900   Bf: 100   Loss: 3.363  0.008  0.006\n",
      "Ep: 1360   Rew: -52.08   Avg Rew: -51.66   LR: 0.00008033   Polyak: 0.999900   Bf: 100   Loss: 3.332  0.065  0.091\n",
      "Ep: 1370   Rew: -53.99   Avg Rew: -51.65   LR: 0.00008033   Polyak: 0.999900   Bf: 100   Loss: 3.166  0.018  0.017\n",
      "Ep: 1380   Rew: -55.15   Avg Rew: -51.73   LR: 0.00008035   Polyak: 0.999900   Bf: 100   Loss: 3.225  0.006  0.004\n",
      "Ep: 1390   Rew: -52.81   Avg Rew: -53.55   LR: 0.00008071   Polyak: 0.999900   Bf: 100   Loss: 3.258  0.047  0.042\n",
      "Ep: 1400   Rew: -52.19   Avg Rew: -55.75   LR: 0.00008115   Polyak: 0.999900   Bf: 100   Loss: 3.174  0.157  0.154\n",
      "Ep: 1410   Rew: -57.22   Avg Rew: -56.11   LR: 0.00008122   Polyak: 0.999900   Bf: 100   Loss: 3.222  0.006  0.009\n",
      "Ep: 1420   Rew: -53.13   Avg Rew: -56.78   LR: 0.00008136   Polyak: 0.999900   Bf: 100   Loss: 3.274  0.007  0.009\n",
      "Ep: 1430   Rew: -47.78   Avg Rew: -57.32   LR: 0.00008146   Polyak: 0.999900   Bf: 100   Loss: 3.234  0.009  0.006\n",
      "Ep: 1440   Rew: -52.98   Avg Rew: -57.26   LR: 0.00008145   Polyak: 0.999900   Bf: 100   Loss: 3.524  2.381  1.227\n",
      "Ep: 1450   Rew: -66.02   Avg Rew: -57.67   LR: 0.00008153   Polyak: 0.999900   Bf: 100   Loss: 3.229  0.010  0.011\n",
      "Ep: 1460   Rew: -39.67   Avg Rew: -57.17   LR: 0.00008143   Polyak: 0.999900   Bf: 100   Loss: 3.200  0.014  0.013\n",
      "Ep: 1470   Rew: -52.93   Avg Rew: -57.70   LR: 0.00008154   Polyak: 0.999900   Bf: 100   Loss: 3.531  0.054  0.041\n",
      "Ep: 1480   Rew: -53.44   Avg Rew: -58.40   LR: 0.00008168   Polyak: 0.999900   Bf: 100   Loss: 3.229  0.015  0.010\n",
      "Ep: 1490   Rew: -43.11   Avg Rew: -56.16   LR: 0.00008123   Polyak: 0.999900   Bf: 100   Loss: 3.302  0.011  0.008\n",
      "Ep: 1500   Rew: -62.06   Avg Rew: -54.40   LR: 0.00008088   Polyak: 0.999900   Bf: 100   Loss: 3.274  0.008  0.007\n",
      "Ep: 1510   Rew: -41.53   Avg Rew: -53.62   LR: 0.00008072   Polyak: 0.999900   Bf: 100   Loss: 3.571  0.796  0.136\n",
      "Ep: 1520   Rew: -56.87   Avg Rew: -54.08   LR: 0.00008082   Polyak: 0.999900   Bf: 100   Loss: 3.242  0.023  0.022\n",
      "Ep: 1530   Rew: -46.92   Avg Rew: -53.93   LR: 0.00008079   Polyak: 0.999900   Bf: 100   Loss: 3.216  0.007  0.006\n",
      "Ep: 1540   Rew: -51.81   Avg Rew: -53.89   LR: 0.00008078   Polyak: 0.999900   Bf: 100   Loss: 3.376  0.024  0.096\n",
      "Ep: 1550   Rew: -63.56   Avg Rew: -53.89   LR: 0.00008078   Polyak: 0.999900   Bf: 100   Loss: 3.236  0.015  0.009\n",
      "Ep: 1560   Rew: -60.53   Avg Rew: -53.76   LR: 0.00008075   Polyak: 0.999900   Bf: 100   Loss: 3.209  0.035  0.035\n",
      "Ep: 1570   Rew: -60.84   Avg Rew: -53.54   LR: 0.00008071   Polyak: 0.999900   Bf: 100   Loss: 3.316  0.042  0.045\n",
      "Ep: 1580   Rew: -47.30   Avg Rew: -53.05   LR: 0.00008061   Polyak: 0.999900   Bf: 100   Loss: 3.352  0.101  0.100\n",
      "Ep: 1590   Rew: -55.09   Avg Rew: -53.49   LR: 0.00008070   Polyak: 0.999900   Bf: 100   Loss: 3.272  0.027  0.023\n",
      "Ep: 1600   Rew: -62.20   Avg Rew: -53.91   LR: 0.00008078   Polyak: 0.999900   Bf: 100   Loss: 3.273  0.020  0.012\n",
      "Ep: 1610   Rew: -57.27   Avg Rew: -55.37   LR: 0.00008107   Polyak: 0.999900   Bf: 100   Loss: 3.199  0.013  0.016\n",
      "Ep: 1620   Rew: -60.25   Avg Rew: -55.77   LR: 0.00008115   Polyak: 0.999900   Bf: 100   Loss: 3.294  0.009  0.010\n",
      "Ep: 1630   Rew: -52.96   Avg Rew: -55.73   LR: 0.00008115   Polyak: 0.999900   Bf: 100   Loss: 3.430  1.342  1.630\n",
      "Ep: 1640   Rew: -56.31   Avg Rew: -57.32   LR: 0.00008146   Polyak: 0.999900   Bf: 100   Loss: 3.435  0.021  0.013\n",
      "Ep: 1650   Rew: -58.76   Avg Rew: -58.92   LR: 0.00008178   Polyak: 0.999900   Bf: 100   Loss: 3.498  1.684  0.195\n",
      "Ep: 1660   Rew: -72.89   Avg Rew: -59.23   LR: 0.00008185   Polyak: 0.999900   Bf: 100   Loss: 3.365  0.010  0.009\n",
      "Ep: 1670   Rew: -43.85   Avg Rew: -60.94   LR: 0.00008219   Polyak: 0.999900   Bf: 100   Loss: 3.439  0.028  0.029\n",
      "Ep: 1680   Rew: -54.94   Avg Rew: -62.27   LR: 0.00008245   Polyak: 0.999900   Bf: 100   Loss: 3.261  0.162  0.120\n",
      "Ep: 1690   Rew: -61.92   Avg Rew: -65.17   LR: 0.00008303   Polyak: 0.999900   Bf: 100   Loss: 3.267  0.015  0.012\n",
      "Ep: 1700   Rew: -48.20   Avg Rew: -66.35   LR: 0.00008327   Polyak: 0.999900   Bf: 100   Loss: 3.376  0.021  0.221\n",
      "Ep: 1710   Rew: -50.30   Avg Rew: -67.92   LR: 0.00008358   Polyak: 0.999900   Bf: 100   Loss: 3.415  0.008  0.009\n",
      "Ep: 1720   Rew: -63.95   Avg Rew: -67.64   LR: 0.00008353   Polyak: 0.999900   Bf: 100   Loss: 3.504  0.403  0.183\n",
      "Ep: 1730   Rew: -50.60   Avg Rew: -69.68   LR: 0.00008394   Polyak: 0.999900   Bf: 100   Loss: 3.537  0.134  0.046\n",
      "Ep: 1740   Rew: -62.61   Avg Rew: -69.57   LR: 0.00008391   Polyak: 0.999900   Bf: 100   Loss: 3.428  0.021  0.021\n",
      "Ep: 1750   Rew: -63.24   Avg Rew: -68.65   LR: 0.00008373   Polyak: 0.999900   Bf: 100   Loss: 3.353  0.022  0.066\n",
      "Ep: 1760   Rew: -51.07   Avg Rew: -70.35   LR: 0.00008407   Polyak: 0.999900   Bf: 100   Loss: 3.340  0.024  0.026\n",
      "Ep: 1770   Rew: -73.06   Avg Rew: -70.10   LR: 0.00008402   Polyak: 0.999900   Bf: 100   Loss: 3.378  0.015  0.033\n",
      "Ep: 1780   Rew: -60.31   Avg Rew: -70.30   LR: 0.00008406   Polyak: 0.999900   Bf: 100   Loss: 3.398  0.028  0.021\n",
      "Ep: 1790   Rew: -63.33   Avg Rew: -69.20   LR: 0.00008384   Polyak: 0.999900   Bf: 100   Loss: 3.472  0.016  0.012\n",
      "Ep: 1800   Rew: -93.09   Avg Rew: -68.93   LR: 0.00008379   Polyak: 0.999900   Bf: 100   Loss: 3.421  0.062  0.036\n",
      "Ep: 1810   Rew: -56.12   Avg Rew: -69.62   LR: 0.00008392   Polyak: 0.999900   Bf: 100   Loss: 3.512  0.573  0.408\n",
      "Ep: 1820   Rew: -70.20   Avg Rew: -71.45   LR: 0.00008429   Polyak: 0.999900   Bf: 100   Loss: 3.513  0.025  0.022\n",
      "Ep: 1830   Rew: -77.28   Avg Rew: -70.40   LR: 0.00008408   Polyak: 0.999900   Bf: 100   Loss: 3.567  0.121  0.103\n",
      "Ep: 1840   Rew: -57.04   Avg Rew: -70.58   LR: 0.00008412   Polyak: 0.999900   Bf: 100   Loss: 3.366  0.052  0.042\n",
      "Ep: 1850   Rew: -65.15   Avg Rew: -72.36   LR: 0.00008447   Polyak: 0.999900   Bf: 100   Loss: 3.443  0.033  0.033\n",
      "Ep: 1860   Rew: -62.96   Avg Rew: -71.87   LR: 0.00008437   Polyak: 0.999900   Bf: 100   Loss: 3.482  0.384  0.590\n",
      "Ep: 1870   Rew: -71.09   Avg Rew: -72.01   LR: 0.00008440   Polyak: 0.999900   Bf: 100   Loss: 3.466  0.020  0.018\n",
      "Ep: 1880   Rew: -55.70   Avg Rew: -71.43   LR: 0.00008429   Polyak: 0.999900   Bf: 100   Loss: 3.377  0.017  0.019\n",
      "Ep: 1890   Rew: -64.58   Avg Rew: -71.82   LR: 0.00008436   Polyak: 0.999900   Bf: 100   Loss: 4.053  3.070  3.985\n",
      "Ep: 1900   Rew: -67.12   Avg Rew: -73.08   LR: 0.00008462   Polyak: 0.999900   Bf: 100   Loss: 3.426  0.022  0.022\n",
      "Ep: 1910   Rew: -77.29   Avg Rew: -72.08   LR: 0.00008442   Polyak: 0.999900   Bf: 100   Loss: 3.497  0.032  0.035\n",
      "Ep: 1920   Rew: -64.19   Avg Rew: -71.88   LR: 0.00008438   Polyak: 0.999900   Bf: 100   Loss: 3.354  0.029  0.020\n",
      "Ep: 1930   Rew: -61.73   Avg Rew: -72.71   LR: 0.00008454   Polyak: 0.999900   Bf: 100   Loss: 3.397  0.020  0.012\n",
      "Ep: 1940   Rew: -67.62   Avg Rew: -72.87   LR: 0.00008457   Polyak: 0.999900   Bf: 100   Loss: 3.402  0.075  0.039\n",
      "Ep: 1950   Rew: -69.22   Avg Rew: -72.55   LR: 0.00008451   Polyak: 0.999900   Bf: 100   Loss: 3.626  0.202  0.936\n",
      "Ep: 1960   Rew: -56.31   Avg Rew: -71.69   LR: 0.00008434   Polyak: 0.999900   Bf: 100   Loss: 3.655  0.058  0.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 1970   Rew: -67.13   Avg Rew: -72.07   LR: 0.00008441   Polyak: 0.999900   Bf: 100   Loss: 3.593  0.047  0.055\n",
      "Ep: 1980   Rew: -56.73   Avg Rew: -74.69   LR: 0.00008494   Polyak: 0.999900   Bf: 100   Loss: 3.519  0.038  0.029\n",
      "Ep: 1990   Rew: -74.76   Avg Rew: -77.27   LR: 0.00008545   Polyak: 0.999900   Bf: 100   Loss: 3.570  0.018  0.082\n",
      "Ep: 2000   Rew: -56.18   Avg Rew: -77.55   LR: 0.00008551   Polyak: 0.999900   Bf: 100   Loss: 3.622  0.143  0.277\n",
      "Ep: 2010   Rew: -57.62   Avg Rew: -80.23   LR: 0.00008605   Polyak: 0.999900   Bf: 100   Loss: 3.536  0.058  0.050\n",
      "Ep: 2020   Rew: -100.97   Avg Rew: -81.98   LR: 0.00008640   Polyak: 0.999900   Bf: 100   Loss: 3.580  0.087  0.076\n",
      "Ep: 2030   Rew: -68.49   Avg Rew: -82.88   LR: 0.00008658   Polyak: 0.999900   Bf: 100   Loss: 3.789  0.246  0.234\n",
      "Ep: 2040   Rew: -110.12   Avg Rew: -84.97   LR: 0.00008699   Polyak: 0.999900   Bf: 100   Loss: 3.599  0.081  0.057\n",
      "Ep: 2050   Rew: -58.92   Avg Rew: -85.12   LR: 0.00008702   Polyak: 0.999900   Bf: 100   Loss: 3.729  0.157  0.256\n",
      "Ep: 2060   Rew: -65.40   Avg Rew: -86.53   LR: 0.00008731   Polyak: 0.999900   Bf: 100   Loss: 3.888  0.072  0.138\n",
      "Ep: 2070   Rew: -57.46   Avg Rew: -86.39   LR: 0.00008728   Polyak: 0.999900   Bf: 100   Loss: 3.945  1.001  0.411\n",
      "Ep: 2080   Rew: -70.04   Avg Rew: -84.88   LR: 0.00008698   Polyak: 0.999900   Bf: 100   Loss: 3.656  0.136  0.779\n",
      "Ep: 2090   Rew: -109.39   Avg Rew: -84.17   LR: 0.00008683   Polyak: 0.999900   Bf: 100   Loss: 3.727  0.116  0.127\n",
      "Ep: 2100   Rew: -69.29   Avg Rew: -83.45   LR: 0.00008669   Polyak: 0.999900   Bf: 100   Loss: 3.798  0.039  0.116\n",
      "Ep: 2110   Rew: -98.57   Avg Rew: -80.89   LR: 0.00008618   Polyak: 0.999900   Bf: 100   Loss: 3.613  0.026  0.084\n",
      "Ep: 2120   Rew: -80.56   Avg Rew: -79.36   LR: 0.00008587   Polyak: 0.999900   Bf: 100   Loss: 3.644  0.023  0.021\n",
      "Ep: 2130   Rew: -82.75   Avg Rew: -78.69   LR: 0.00008574   Polyak: 0.999900   Bf: 100   Loss: 3.958  0.049  0.484\n",
      "Ep: 2140   Rew: -108.75   Avg Rew: -77.37   LR: 0.00008547   Polyak: 0.999900   Bf: 100   Loss: 3.674  0.259  0.081\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f74587ceb429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 episode, ep_reward, avg_reward, learning_rate, polyak, replay_buffer.get_fill(), policy.actor_loss, policy.loss_Q1, policy.loss_Q2))\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-f74587ceb429>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# if episode is done then update policy:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_timesteps\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolyak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_delay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/gym/bipedal_walker_hardcore/TD3_torch/TD3.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, replay_buffer, n_iter, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnoise_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mnext_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mnext_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/gym/bipedal_walker_hardcore/TD3_torch/TD3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "from TD3_torch.TD3 import TD3\n",
    "from PIL import Image\n",
    "from TD3_torch.utils import ReplayBuffer\n",
    "\n",
    "env_name = 'BipedalWalkerHardcore-v2'\n",
    "learning_rate_base = 0.0001\n",
    "log_interval = 10           # print avg reward after interval\n",
    "random_seed = 555\n",
    "gamma = 0.99                # discount for future rewards\n",
    "batch_size = 1024        # num of transitions sampled from replay buffer\n",
    "exploration_noise = 0.3 \n",
    "polyak_int = [0.9999, 0.999999]              # target policy update parameter (1-tau)\n",
    "policy_noise = 0.2          # target policy smoothing noise\n",
    "noise_clip = 0.5\n",
    "policy_delay = 2            # delayed policy updates parameter\n",
    "max_episodes = 100000         # max num of episodes\n",
    "max_timesteps = 3000        # max timesteps in one episode\n",
    "max_buffer_length = 2000000\n",
    "directory = \"./preTrained/td3_torch/{}\".format(env_name) # save trained models\n",
    "filename = \"TD3_torch_{}_{}\".format(env_name, random_seed)\n",
    "reward_history = []\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    polyak = polyak_int[0]\n",
    "    \n",
    "    actor_config = [\n",
    "        {'dim': (state_dim, 256), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (256, 320), 'dropout': True, 'activation':'relu'},\n",
    "        {'dim': (320, 160), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (160, 64), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (64, action_dim),'dropout': False, 'activation': False}\n",
    "    ]\n",
    "    \n",
    "    critic_config = [\n",
    "        {'dim': (state_dim + action_dim, 256), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (256, 320), 'dropout': True, 'activation':'relu'},\n",
    "        {'dim': (320, 160), 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': (160, 1), 'dropout': False, 'activation': False}\n",
    "    ]\n",
    "    \n",
    "    policy = TD3(actor_config, critic_config, max_action, lr=learning_rate_base)   \n",
    "    replay_buffer = ReplayBuffer(max_length=max_buffer_length)\n",
    "    \n",
    "    print(\"action_space={}\".format(env.action_space))\n",
    "    print(\"obs_space={}\".format(env.observation_space))\n",
    "    print(\"threshold={} \\n\".format(env.spec.reward_threshold))     \n",
    "    \n",
    "    if random_seed:\n",
    "        print(\"Random Seed: {}\".format(random_seed))\n",
    "        env.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # loading models\n",
    "    policy.load(directory, filename)\n",
    "    \n",
    "    # logging variables:        \n",
    "    log_f = open(\"log.txt\",\"w+\")\n",
    "    \n",
    "    # training procedure:\n",
    "    for episode in range(1, max_episodes+1):\n",
    "        ep_reward = 0\n",
    "        state = env.reset()\n",
    "       \n",
    "        for t in range(max_timesteps):\n",
    "            # select action and add exploration noise:\n",
    "            action = policy.select_action(state)\n",
    "            action = action + np.random.normal(0, exploration_noise, size=env.action_space.shape[0])\n",
    "            action = action.clip(env.action_space.low, env.action_space.high)\n",
    "            \n",
    "            # take action in env:\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            replay_buffer.add((state, action, reward, next_state, float(done)))\n",
    "            state = next_state\n",
    "            \n",
    "            ep_reward += reward\n",
    "            \n",
    "            # if episode is done then update policy:\n",
    "            if done or t==(max_timesteps-1):\n",
    "                policy.update(replay_buffer, t, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay)\n",
    "                break\n",
    "        \n",
    "        reward_history.append(ep_reward)\n",
    "        avg_reward = np.mean(reward_history[-100:]) \n",
    "        \n",
    "        # logging updates:        \n",
    "        log_f.write('{},{}\\n'.format(episode, ep_reward))\n",
    "        log_f.flush()\n",
    "       \n",
    "        \n",
    "        # if avg reward > 300 then save and stop traning:\n",
    "        if avg_reward >= env.spec.reward_threshold: \n",
    "            print(\"########## Solved! ###########\")\n",
    "            name = filename + '_solved'\n",
    "            policy.save(directory, name)\n",
    "            log_f.close()\n",
    "            break\n",
    "            \n",
    "        # Calculate polyak\n",
    "        #part = (env.spec.reward_threshold - avg_reward) / (env.spec.reward_threshold + 150)\n",
    "        #if part > 1:\n",
    "        #    part = 1\n",
    "        #polyak = polyak_int[0] + (1 - part) * (polyak_int[1] - polyak_int[0])     \n",
    "        \n",
    "        # Calculate LR\n",
    "        part = (env.spec.reward_threshold - avg_reward) / (env.spec.reward_threshold + 150)\n",
    "        if part > 1:\n",
    "            part = 1\n",
    "        learning_rate = learning_rate_base - learning_rate_base * (1 - part) * 0.9\n",
    "        policy.set_optimizers(lr=learning_rate)\n",
    "        \n",
    "        \n",
    "        if episode > 500:\n",
    "            policy.save(directory, filename)\n",
    "        \n",
    "        # print avg reward every log interval:\n",
    "        if episode % log_interval == 0:            \n",
    "            print(\"Ep: {}   Rew: {:3.2f}   Avg Rew: {:3.2f}   LR: {:8.8f}   Polyak: {:6.6f}   Bf: {:2.0f}   Loss: {:5.3f}  {:5.3f}  {:5.3f}\".format(\n",
    "                episode, ep_reward, avg_reward, learning_rate, polyak, replay_buffer.get_fill(), policy.actor_loss, policy.loss_Q1, policy.loss_Q2))\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():  \n",
    "    random_seed = 0\n",
    "    n_episodes = 3\n",
    "    max_timesteps = 2000\n",
    "    render = True\n",
    "    save_gif = True\n",
    "    \n",
    "    filename = \"TD3_torch_{}_{}\".format(env_name, random_seed)\n",
    "    filename += ''\n",
    "    directory = \"./preTrained/td3_torch/{}\".format(env_name)\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    \n",
    "    policy = TD3(state_dim, action_dim, max_action)\n",
    "    \n",
    "    policy.load_actor(directory, filename)\n",
    "    \n",
    "    for ep in range(1, n_episodes+1):\n",
    "        ep_reward = 0\n",
    "        state = env.reset()\n",
    "        for t in range(max_timesteps):\n",
    "            action = policy.select_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            ep_reward += reward\n",
    "            if render:\n",
    "                env.render()\n",
    "                if save_gif:\n",
    "                    dirname = './gif/td3_torch/{}'.format(ep)\n",
    "                    if not os.path.isdir(dirname):\n",
    "                        os.mkdir(dirname)\n",
    "                    img = env.render(mode = 'rgb_array')\n",
    "                    img = Image.fromarray(img)\n",
    "                    img.save('./gif/td3_torch/{}/{}.jpg'.format(ep,t))\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        print('Episode: {}\\tReward: {}'.format(ep, int(ep_reward)))\n",
    "        ep_reward = 0\n",
    "        env.close()        \n",
    "                \n",
    "test()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
