{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import wrappers\n",
    "from PIL import Image\n",
    "\n",
    "from TD3.td3 import TD3\n",
    "from TD3.utils import ReplayBuffer, mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Pendulum-v0'\n",
    "lr_base = 0.001\n",
    "lr_decay = 0.0001\n",
    "exp_noise_base = 0.2 \n",
    "exp_noise_decay = 0.0001\n",
    "\n",
    "random_seed = 42\n",
    "gamma = 0.99                # discount for future rewards\n",
    "batch_size = 1024        # num of transitions sampled from replay buffer\n",
    "polyak = 0.9999              # target policy update parameter (1-tau)\n",
    "policy_noise = 0.2          # target policy smoothing noise\n",
    "noise_clip = 0.5\n",
    "policy_delay = 2            # delayed policy updates parameter\n",
    "max_episodes = 100000         # max num of episodes\n",
    "max_timesteps = 3000        # max timesteps in one episode\n",
    "max_buffer_length = 5000000\n",
    "log_interval = 5           # print avg reward after interval\n",
    "threshold = -140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_config = [\n",
    "        {'dim': [None, 32], 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': [32, 32], 'dropout': False, 'activation':'relu'},\n",
    "        {'dim': [32, None], 'dropout': False, 'activation': 'sigmoid'}\n",
    "    ]\n",
    "    \n",
    "critic_config = [\n",
    "        {'dim': [None, 32], 'dropout': False, 'activation': 'relu'},\n",
    "        {'dim': [32, 32], 'dropout': False , 'activation':'relu'},\n",
    "        {'dim': [32, 1], 'dropout': False, 'activation': False}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TD3Trainer():\n",
    "    \n",
    "    def __init__(self, env_name, actor_config, critic_config, random_seed=42, lr_base=0.001, lr_decay=0.00005, \n",
    "                 exp_noise_base=0.3, exp_noise_decay=0.0001, gamma=0.99, batch_size=1024, \n",
    "                 polyak=0.9999, policy_noise=0.2, noise_clip=0.5, policy_delay=2, \n",
    "                 max_episodes=100000, max_timesteps=3000, max_buffer_length=5000000, \n",
    "                 log_interval=5, threshold=None, lr_minimum=1e-10, exp_noise_minimum=1e-10,\n",
    "                 record_videos=True, record_interval=100):        \n",
    "        \n",
    "        self.algorithm_name = 'td3'\n",
    "        self.env_name = env_name\n",
    "        self.env = gym.make(env_name)\n",
    "        self.record_videos = record_videos\n",
    "        self.record_interval = record_interval        \n",
    "        if self.record_videos == True:\n",
    "            videos_dir = mkdir('.', 'videos')\n",
    "            monitor_dir = mkdir(videos_dir, self.algorithm_name)\n",
    "            should_record = lambda i: self.should_record\n",
    "            self.env = wrappers.Monitor(self.env, monitor_dir, video_callable=should_record, force=True)            \n",
    "        self.state_dim = self.env.observation_space.shape[0]\n",
    "        self.action_dim = self.env.action_space.shape[0]\n",
    "        self.action_low = self.env.action_space.low\n",
    "        self.action_high = self.env.action_space.high        \n",
    "        self.should_record = False\n",
    "        if not threshold == None:\n",
    "            self.threshold = threshold\n",
    "        else:    \n",
    "            self.threshold = self.env.spec.reward_threshold\n",
    "        \n",
    "        self.actor_config = actor_config\n",
    "        self.critic_config = critic_config\n",
    "        self.actor_config[0]['dim'][0] = self.state_dim\n",
    "        self.actor_config[-1]['dim'][1] = self.action_dim\n",
    "        self.critic_config[0]['dim'][0] = self.state_dim + self.action_dim\n",
    "        \n",
    "        self.actor_config = actor_config\n",
    "        self.critic_config = critic_config\n",
    "        self.random_seed = random_seed\n",
    "        self.lr_base = lr_base\n",
    "        self.lr_decay = lr_decay   \n",
    "        self.lr_minimum = lr_minimum\n",
    "        self.exp_noise_base = exp_noise_base\n",
    "        self.exp_noise_decay = exp_noise_decay     \n",
    "        self.exp_noise_minimum = exp_noise_minimum                \n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size        \n",
    "        self.polyak = polyak\n",
    "        self.policy_noise = policy_noise\n",
    "        self.noise_clip = noise_clip\n",
    "        self.policy_delay = policy_delay\n",
    "        self.max_episodes = max_episodes\n",
    "        self.max_timesteps = max_timesteps\n",
    "        self.max_buffer_length = max_buffer_length\n",
    "        self.log_interval = log_interval\n",
    "        \n",
    "        prdir = mkdir('.', 'preTrained')\n",
    "        self.directory = mkdir(prdir, self.algorithm_name)\n",
    "        self.filename = \"{}_{}_{}\".format(self.algorithm_name, self.env_name, self.random_seed)\n",
    "                \n",
    "        self.policy = TD3(self.actor_config, self.critic_config, self.action_low, self.action_high)   \n",
    "        self.replay_buffer = ReplayBuffer(max_length=self.max_buffer_length)\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.make_plots = False       \n",
    "        \n",
    "        if self.random_seed:\n",
    "            print(\"Random Seed: {}\".format(self.random_seed))\n",
    "            self.env.seed(self.random_seed)\n",
    "            torch.manual_seed(self.random_seed)\n",
    "            np.random.seed(self.random_seed)\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        print(\"Training started ... \\n\")\n",
    "        print(\"action_space={}\".format(self.env.action_space))\n",
    "        print(\"obs_space={}\".format(self.env.observation_space))\n",
    "        print(\"threshold={}\".format(self.threshold))     \n",
    "        print(\"action_low={} action_high={} \\n\".format(self.action_low, self.action_high))         \n",
    "\n",
    "        # loading models\n",
    "        self.policy.load(self.directory, self.filename)\n",
    "                \n",
    "        # logging variables:        \n",
    "        log_f = open(\"train_{}.txt\".format(self.algorithm_name), \"w+\")\n",
    "\n",
    "        # training procedure:\n",
    "        for episode in range(1, self.max_episodes+1):\n",
    "            \n",
    "            # Only record video during evaluation, every n steps\n",
    "            if episode % self.record_interval == 0:\n",
    "                self.should_record = True\n",
    "            \n",
    "            ep_reward = 0.0\n",
    "            state = self.env.reset()\n",
    "            \n",
    "            # calculate params\n",
    "            exploration_noise = max(self.exp_noise_base / (1.0 + episode * self.exp_noise_decay), self.exp_noise_minimum)\n",
    "            learning_rate = max(self.lr_base / (1.0 + episode * self.lr_decay), self.lr_minimum)            \n",
    "            self.policy.set_optimizers(lr=learning_rate)\n",
    "\n",
    "            for t in range(self.max_timesteps):\n",
    "                \n",
    "                # select action and add exploration noise:\n",
    "                action = self.policy.select_action(state)\n",
    "                action = action + np.random.normal(0, exploration_noise, size=self.action_dim)\n",
    "                action = action.clip(self.action_low, self.action_high)\n",
    "\n",
    "                # take action in env:\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                self.replay_buffer.add((state, action, reward, next_state, float(done)))\n",
    "                state = next_state\n",
    "\n",
    "                ep_reward += reward\n",
    "\n",
    "                # if episode is done then update policy:\n",
    "                if done or t==(self.max_timesteps-1):\n",
    "                    self.policy.update(self.replay_buffer, t, self.batch_size, self.gamma, self.polyak, \n",
    "                                       self.policy_noise, self.noise_clip, self.policy_delay)\n",
    "                    break\n",
    "\n",
    "            self.reward_history.append(ep_reward)\n",
    "            avg_reward = np.mean(self.reward_history[-100:]) \n",
    "\n",
    "            # logging updates:        \n",
    "            log_f.write('{},{}\\n'.format(episode, ep_reward))\n",
    "            log_f.flush()\n",
    "            \n",
    "            # Calculate polyak\n",
    "            #part = (env.spec.reward_threshold - avg_reward) / (env.spec.reward_threshold + 150)\n",
    "            #if part > 1:\n",
    "            #    part = 1\n",
    "            #polyak = polyak_int[0] + (1 - part) * (polyak_int[1] - polyak_int[0])     \n",
    "\n",
    "            # Calculate LR\n",
    "            #part = min((env.spec.reward_threshold - avg_reward) / (env.spec.reward_threshold + 150), 1)\n",
    "                        \n",
    "            avg_actor_loss = np.mean(self.policy.actor_loss_list[-100:])\n",
    "            avg_Q1_loss = np.mean(self.policy.Q1_loss_list[-100:])\n",
    "            avg_Q2_loss = np.mean(self.policy.Q2_loss_list[-100:])\n",
    "\n",
    "            if not self.make_plots and len(self.policy.actor_loss_list) > 200:\n",
    "                self.policy.actor_loss_list.pop(0)\n",
    "                self.policy.Q1_loss_list.pop(0)\n",
    "                self.policy.Q2_loss_list.pop(0)  \n",
    "                self.reward_history.pop(0)    \n",
    "\n",
    "            # Print avg reward every log interval:\n",
    "            if episode % self.log_interval == 0 and episode > 100:            \n",
    "                self.policy.save(self.directory, self.filename)\n",
    "                print(\"Ep:{}   Rew:{:3.2f}  Avg Rew:{:3.2f}  LR:{:8.8f}   Polyak:{:5.5f}  Bf:{:2.0f}  EN:{:0.4f}  Loss: {:5.3f} {:5.3f} {:5.3f}\".format(\n",
    "                    episode, ep_reward, avg_reward, learning_rate, self.polyak, self.replay_buffer.get_fill(), \n",
    "                    exploration_noise, avg_actor_loss, avg_Q1_loss, avg_Q2_loss))\n",
    "                \n",
    "            self.should_record = False    \n",
    "                \n",
    "            # if avg reward > threshold then save and stop traning:\n",
    "            if avg_reward >= self.threshold: \n",
    "                print(\"Ep:{}   Rew:{:3.2f}  Avg Rew:{:3.2f}  LR:{:8.8f}   Polyak:{:5.5f}  Bf:{:2.0f}  EN:{:0.4f}  Loss: {:5.3f} {:5.3f} {:5.3f}\".format(\n",
    "                    episode, ep_reward, avg_reward, learning_rate, self.polyak, self.replay_buffer.get_fill(), \n",
    "                    exploration_noise, avg_actor_loss, avg_Q1_loss, avg_Q2_loss))\n",
    "                print(\"########## Solved! ###########\")\n",
    "                name = self.filename + '_solved'\n",
    "                self.policy.save(self.directory, name)\n",
    "                log_f.close()\n",
    "                training_time = time.time() - start_time\n",
    "                print(\"Training time: {:6.2f} sec\".format(training_time))\n",
    "                break    \n",
    "       \n",
    "    def test(self, episodes=3, render=True, save_gif=True):   \n",
    "        \n",
    "        gifdir = mkdir('.','gif')\n",
    "        algdir = mkdir(gifdir, self.algorithm_name)\n",
    "\n",
    "        for episode in range(1, episodes+1):\n",
    "            ep_reward = 0.0\n",
    "            state = self.env.reset()\n",
    "            epdir = mkdir(algdir, str(episode))\n",
    "            \n",
    "            for t in range(self.max_timesteps):\n",
    "                action = self.policy.select_action(state)\n",
    "                state, reward, done, _ = self.env.step(action)\n",
    "                ep_reward += reward\n",
    "                \n",
    "                if save_gif:                                       \n",
    "                    img = self.env.render(mode = 'rgb_array')\n",
    "                    img = Image.fromarray(img)\n",
    "                    img.save('{}/{}.jpg'.format(epdir, t))\n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "\n",
    "            print('Test episode: {}\\tReward: {:4.2f}'.format(episode, ep_reward))           \n",
    "            self.env.close()        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTOR=Sequential(\n",
      "  (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "ACTOR=Sequential(\n",
      "  (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "CRITIC=Sequential(\n",
      "  (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Random Seed: 42\n",
      "Training started ... \n",
      "\n",
      "action_space=Box(1,)\n",
      "obs_space=Box(3,)\n",
      "threshold=-140 \n",
      "\n",
      "action_low=[-2.] action_high=[2.] \n",
      "\n",
      "DIR=./preTrained/td3 NAME=td3_Pendulum-v0_42\n",
      "No models to load\n",
      "Ep:5   Rew:-1558.60  Avg Rew:-1534.80  LR:0.00099950   Polyak:0.99990  Bf: 0  EN:0.1999  Loss: 7.357 0.039 0.056\n",
      "Ep:10   Rew:-1572.82  Avg Rew:-1535.60  LR:0.00099900   Polyak:0.99990  Bf: 0  EN:0.1998  Loss: 7.750 0.007 0.010\n",
      "Ep:15   Rew:-1568.33  Avg Rew:-1578.41  LR:0.00099850   Polyak:0.99990  Bf: 0  EN:0.1997  Loss: 7.959 0.003 0.004\n",
      "Ep:20   Rew:-1642.08  Avg Rew:-1628.57  LR:0.00099800   Polyak:0.99990  Bf: 0  EN:0.1996  Loss: 8.165 0.002 0.003\n",
      "Ep:25   Rew:-1535.99  Avg Rew:-1555.64  LR:0.00099751   Polyak:0.99990  Bf: 0  EN:0.1995  Loss: 8.293 0.003 0.003\n",
      "Ep:30   Rew:-1696.59  Avg Rew:-1683.31  LR:0.00099701   Polyak:0.99990  Bf: 0  EN:0.1994  Loss: 8.494 0.003 0.003\n",
      "Ep:35   Rew:-1574.45  Avg Rew:-1607.55  LR:0.00099651   Polyak:0.99990  Bf: 0  EN:0.1993  Loss: 8.641 0.004 0.004\n",
      "Ep:40   Rew:-1680.78  Avg Rew:-1612.69  LR:0.00099602   Polyak:0.99990  Bf: 0  EN:0.1992  Loss: 8.820 0.005 0.005\n",
      "Ep:45   Rew:-1714.94  Avg Rew:-1705.00  LR:0.00099552   Polyak:0.99990  Bf: 0  EN:0.1991  Loss: 9.043 0.007 0.007\n",
      "Ep:50   Rew:-1672.14  Avg Rew:-1664.62  LR:0.00099502   Polyak:0.99990  Bf: 0  EN:0.1990  Loss: 9.254 0.009 0.009\n",
      "Ep:55   Rew:-1660.74  Avg Rew:-1610.66  LR:0.00099453   Polyak:0.99990  Bf: 0  EN:0.1989  Loss: 9.465 0.012 0.012\n",
      "Ep:60   Rew:-1523.57  Avg Rew:-1555.84  LR:0.00099404   Polyak:0.99990  Bf: 0  EN:0.1988  Loss: 9.657 0.015 0.016\n",
      "Ep:65   Rew:-1381.77  Avg Rew:-1459.28  LR:0.00099354   Polyak:0.99990  Bf: 0  EN:0.1987  Loss: 9.814 0.018 0.019\n",
      "Ep:70   Rew:-1562.93  Avg Rew:-1536.22  LR:0.00099305   Polyak:0.99990  Bf: 0  EN:0.1986  Loss: 10.031 0.025 0.025\n",
      "Ep:75   Rew:-1544.99  Avg Rew:-1546.47  LR:0.00099256   Polyak:0.99990  Bf: 0  EN:0.1985  Loss: 10.243 0.029 0.029\n",
      "Ep:80   Rew:-1496.46  Avg Rew:-1503.90  LR:0.00099206   Polyak:0.99990  Bf: 0  EN:0.1984  Loss: 10.450 0.033 0.034\n",
      "Ep:85   Rew:-1501.22  Avg Rew:-1513.81  LR:0.00099157   Polyak:0.99990  Bf: 0  EN:0.1983  Loss: 10.673 0.043 0.043\n",
      "Ep:90   Rew:-1526.94  Avg Rew:-1465.15  LR:0.00099108   Polyak:0.99990  Bf: 0  EN:0.1982  Loss: 10.891 0.055 0.055\n",
      "Ep:95   Rew:-1455.10  Avg Rew:-1498.85  LR:0.00099059   Polyak:0.99990  Bf: 0  EN:0.1981  Loss: 11.134 0.059 0.059\n",
      "Ep:100   Rew:-1531.26  Avg Rew:-1526.16  LR:0.00099010   Polyak:0.99990  Bf: 0  EN:0.1980  Loss: 11.391 0.072 0.072\n",
      "Ep:105   Rew:-1531.47  Avg Rew:-1504.05  LR:0.00098961   Polyak:0.99990  Bf: 0  EN:0.1979  Loss: 11.626 0.078 0.078\n",
      "Ep:110   Rew:-1523.84  Avg Rew:-1519.30  LR:0.00098912   Polyak:0.99990  Bf: 0  EN:0.1978  Loss: 11.898 0.088 0.088\n",
      "Ep:115   Rew:-1523.85  Avg Rew:-1508.00  LR:0.00098863   Polyak:0.99990  Bf: 0  EN:0.1977  Loss: 12.157 0.102 0.102\n",
      "Ep:120   Rew:-1455.17  Avg Rew:-1496.38  LR:0.00098814   Polyak:0.99990  Bf: 0  EN:0.1976  Loss: 12.422 0.120 0.120\n",
      "Ep:125   Rew:-1401.94  Avg Rew:-1475.74  LR:0.00098765   Polyak:0.99990  Bf: 0  EN:0.1975  Loss: 12.676 0.121 0.121\n",
      "Ep:130   Rew:-1539.52  Avg Rew:-1525.21  LR:0.00098717   Polyak:0.99990  Bf: 1  EN:0.1974  Loss: 12.957 0.143 0.143\n",
      "Ep:135   Rew:-1534.78  Avg Rew:-1514.11  LR:0.00098668   Polyak:0.99990  Bf: 1  EN:0.1973  Loss: 13.222 0.156 0.156\n",
      "Ep:140   Rew:-1521.29  Avg Rew:-1534.85  LR:0.00098619   Polyak:0.99990  Bf: 1  EN:0.1972  Loss: 13.522 0.181 0.181\n",
      "Ep:145   Rew:-1527.28  Avg Rew:-1473.75  LR:0.00098571   Polyak:0.99990  Bf: 1  EN:0.1971  Loss: 13.775 0.173 0.174\n",
      "Ep:150   Rew:-1455.38  Avg Rew:-1473.35  LR:0.00098522   Polyak:0.99990  Bf: 1  EN:0.1970  Loss: 14.051 0.199 0.199\n",
      "Ep:155   Rew:-1455.16  Avg Rew:-1480.40  LR:0.00098474   Polyak:0.99990  Bf: 1  EN:0.1969  Loss: 14.349 0.221 0.221\n",
      "Ep:160   Rew:-1536.94  Avg Rew:-1524.88  LR:0.00098425   Polyak:0.99990  Bf: 1  EN:0.1969  Loss: 14.617 0.247 0.247\n",
      "Ep:165   Rew:-1532.74  Avg Rew:-1526.56  LR:0.00098377   Polyak:0.99990  Bf: 1  EN:0.1968  Loss: 14.887 0.268 0.267\n",
      "Ep:170   Rew:-1549.38  Avg Rew:-1483.87  LR:0.00098328   Polyak:0.99990  Bf: 1  EN:0.1967  Loss: 15.191 0.289 0.289\n",
      "Ep:175   Rew:-1508.83  Avg Rew:-1507.28  LR:0.00098280   Polyak:0.99990  Bf: 1  EN:0.1966  Loss: 15.484 0.309 0.309\n",
      "Ep:180   Rew:-1408.37  Avg Rew:-1494.78  LR:0.00098232   Polyak:0.99990  Bf: 1  EN:0.1965  Loss: 15.779 0.356 0.357\n",
      "Ep:185   Rew:-1440.75  Avg Rew:-1514.30  LR:0.00098184   Polyak:0.99990  Bf: 1  EN:0.1964  Loss: 16.079 0.378 0.379\n",
      "Ep:190   Rew:-1457.61  Avg Rew:-1487.75  LR:0.00098135   Polyak:0.99990  Bf: 1  EN:0.1963  Loss: 16.354 0.387 0.388\n",
      "Ep:195   Rew:-1588.21  Avg Rew:-1508.13  LR:0.00098087   Polyak:0.99990  Bf: 1  EN:0.1962  Loss: 16.671 0.401 0.401\n",
      "Ep:200   Rew:-1523.30  Avg Rew:-1494.89  LR:0.00098039   Polyak:0.99990  Bf: 1  EN:0.1961  Loss: 16.971 0.470 0.471\n",
      "Ep:205   Rew:-1484.25  Avg Rew:-1511.22  LR:0.00097991   Polyak:0.99990  Bf: 1  EN:0.1960  Loss: 17.256 0.465 0.465\n",
      "Ep:210   Rew:-1527.86  Avg Rew:-1524.21  LR:0.00097943   Polyak:0.99990  Bf: 1  EN:0.1959  Loss: 17.604 0.523 0.524\n",
      "Ep:215   Rew:-1397.82  Avg Rew:-1488.89  LR:0.00097895   Polyak:0.99990  Bf: 1  EN:0.1958  Loss: 17.893 0.514 0.515\n",
      "Ep:220   Rew:-1602.90  Avg Rew:-1501.84  LR:0.00097847   Polyak:0.99990  Bf: 1  EN:0.1957  Loss: 18.187 0.555 0.556\n",
      "Ep:225   Rew:-1513.45  Avg Rew:-1516.35  LR:0.00097800   Polyak:0.99990  Bf: 1  EN:0.1956  Loss: 18.512 0.659 0.660\n",
      "Ep:230   Rew:-1473.53  Avg Rew:-1501.11  LR:0.00097752   Polyak:0.99990  Bf: 1  EN:0.1955  Loss: 18.801 0.669 0.670\n",
      "Ep:235   Rew:-1506.05  Avg Rew:-1506.46  LR:0.00097704   Polyak:0.99990  Bf: 1  EN:0.1954  Loss: 19.123 0.651 0.652\n",
      "Ep:240   Rew:-1497.01  Avg Rew:-1531.15  LR:0.00097656   Polyak:0.99990  Bf: 1  EN:0.1953  Loss: 19.436 0.703 0.704\n",
      "Ep:245   Rew:-1513.08  Avg Rew:-1515.26  LR:0.00097609   Polyak:0.99990  Bf: 1  EN:0.1952  Loss: 19.733 0.822 0.822\n",
      "Ep:250   Rew:-1504.74  Avg Rew:-1453.05  LR:0.00097561   Polyak:0.99990  Bf: 1  EN:0.1951  Loss: 20.028 0.796 0.797\n",
      "Ep:255   Rew:-1508.55  Avg Rew:-1515.96  LR:0.00097513   Polyak:0.99990  Bf: 1  EN:0.1950  Loss: 20.339 0.881 0.882\n",
      "Ep:260   Rew:-1540.61  Avg Rew:-1492.26  LR:0.00097466   Polyak:0.99990  Bf: 1  EN:0.1949  Loss: 20.633 0.849 0.851\n",
      "Ep:265   Rew:-1288.70  Avg Rew:-1412.28  LR:0.00097418   Polyak:0.99990  Bf: 1  EN:0.1948  Loss: 20.937 0.928 0.930\n",
      "Ep:270   Rew:-1459.11  Avg Rew:-1465.74  LR:0.00097371   Polyak:0.99990  Bf: 1  EN:0.1947  Loss: 21.225 1.002 1.002\n",
      "Ep:275   Rew:-1484.94  Avg Rew:-1479.83  LR:0.00097324   Polyak:0.99990  Bf: 1  EN:0.1946  Loss: 21.515 1.006 1.007\n",
      "Ep:280   Rew:-1514.35  Avg Rew:-1386.54  LR:0.00097276   Polyak:0.99990  Bf: 1  EN:0.1946  Loss: 21.809 1.124 1.125\n",
      "Ep:285   Rew:-1416.58  Avg Rew:-1424.67  LR:0.00097229   Polyak:0.99990  Bf: 1  EN:0.1945  Loss: 22.126 1.045 1.045\n",
      "Ep:290   Rew:-1506.41  Avg Rew:-1508.52  LR:0.00097182   Polyak:0.99990  Bf: 1  EN:0.1944  Loss: 22.436 1.146 1.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:295   Rew:-1513.52  Avg Rew:-1455.40  LR:0.00097135   Polyak:0.99990  Bf: 1  EN:0.1943  Loss: 22.727 1.190 1.192\n",
      "Ep:300   Rew:-1500.38  Avg Rew:-1464.33  LR:0.00097087   Polyak:0.99990  Bf: 1  EN:0.1942  Loss: 23.024 1.189 1.190\n",
      "Ep:305   Rew:-1518.37  Avg Rew:-1444.61  LR:0.00097040   Polyak:0.99990  Bf: 1  EN:0.1941  Loss: 23.337 1.243 1.244\n",
      "Ep:310   Rew:-1517.06  Avg Rew:-1472.46  LR:0.00096993   Polyak:0.99990  Bf: 1  EN:0.1940  Loss: 23.671 1.238 1.240\n",
      "Ep:315   Rew:-1500.02  Avg Rew:-1508.77  LR:0.00096946   Polyak:0.99990  Bf: 1  EN:0.1939  Loss: 23.951 1.333 1.333\n",
      "Ep:320   Rew:-1452.79  Avg Rew:-1493.95  LR:0.00096899   Polyak:0.99990  Bf: 1  EN:0.1938  Loss: 24.275 1.602 1.604\n",
      "Ep:325   Rew:-1347.78  Avg Rew:-1459.95  LR:0.00096852   Polyak:0.99990  Bf: 1  EN:0.1937  Loss: 24.568 1.480 1.479\n",
      "Ep:330   Rew:-1512.91  Avg Rew:-1493.04  LR:0.00096805   Polyak:0.99990  Bf: 1  EN:0.1936  Loss: 24.855 1.567 1.568\n",
      "Ep:335   Rew:-1501.34  Avg Rew:-1447.18  LR:0.00096759   Polyak:0.99990  Bf: 1  EN:0.1935  Loss: 25.167 1.719 1.721\n",
      "Ep:340   Rew:-1492.58  Avg Rew:-1501.37  LR:0.00096712   Polyak:0.99990  Bf: 1  EN:0.1934  Loss: 25.536 1.599 1.599\n",
      "Ep:345   Rew:-1470.89  Avg Rew:-1483.47  LR:0.00096665   Polyak:0.99990  Bf: 1  EN:0.1933  Loss: 25.813 1.750 1.750\n",
      "Ep:350   Rew:-1513.82  Avg Rew:-1502.37  LR:0.00096618   Polyak:0.99990  Bf: 1  EN:0.1932  Loss: 26.128 1.878 1.880\n",
      "Ep:355   Rew:-1363.80  Avg Rew:-1463.38  LR:0.00096572   Polyak:0.99990  Bf: 1  EN:0.1931  Loss: 26.419 1.938 1.939\n",
      "Ep:360   Rew:-1428.23  Avg Rew:-1427.82  LR:0.00096525   Polyak:0.99990  Bf: 1  EN:0.1931  Loss: 26.713 2.041 2.042\n",
      "Ep:365   Rew:-1465.42  Avg Rew:-1486.65  LR:0.00096479   Polyak:0.99990  Bf: 1  EN:0.1930  Loss: 27.041 2.070 2.071\n",
      "Ep:370   Rew:-1490.69  Avg Rew:-1482.93  LR:0.00096432   Polyak:0.99990  Bf: 1  EN:0.1929  Loss: 27.392 2.032 2.033\n",
      "Ep:375   Rew:-1523.11  Avg Rew:-1464.48  LR:0.00096386   Polyak:0.99990  Bf: 2  EN:0.1928  Loss: 27.682 2.096 2.097\n",
      "Ep:380   Rew:-1509.76  Avg Rew:-1462.32  LR:0.00096339   Polyak:0.99990  Bf: 2  EN:0.1927  Loss: 28.035 2.246 2.247\n",
      "Ep:385   Rew:-1523.70  Avg Rew:-1419.14  LR:0.00096293   Polyak:0.99990  Bf: 2  EN:0.1926  Loss: 28.315 2.232 2.233\n",
      "Ep:390   Rew:-1457.36  Avg Rew:-1474.35  LR:0.00096246   Polyak:0.99990  Bf: 2  EN:0.1925  Loss: 28.649 2.375 2.378\n",
      "Ep:395   Rew:-1419.39  Avg Rew:-1453.47  LR:0.00096200   Polyak:0.99990  Bf: 2  EN:0.1924  Loss: 28.931 2.480 2.479\n",
      "Ep:400   Rew:-1516.67  Avg Rew:-1477.91  LR:0.00096154   Polyak:0.99990  Bf: 2  EN:0.1923  Loss: 29.253 2.423 2.426\n",
      "Ep:405   Rew:-1414.81  Avg Rew:-1484.37  LR:0.00096108   Polyak:0.99990  Bf: 2  EN:0.1922  Loss: 29.531 2.561 2.564\n",
      "Ep:410   Rew:-1516.77  Avg Rew:-1520.44  LR:0.00096061   Polyak:0.99990  Bf: 2  EN:0.1921  Loss: 29.901 2.565 2.568\n",
      "Ep:415   Rew:-1504.30  Avg Rew:-1477.99  LR:0.00096015   Polyak:0.99990  Bf: 2  EN:0.1920  Loss: 30.196 2.679 2.681\n",
      "Ep:420   Rew:-1259.07  Avg Rew:-1390.55  LR:0.00095969   Polyak:0.99990  Bf: 2  EN:0.1919  Loss: 30.541 2.852 2.855\n",
      "Ep:425   Rew:-1519.14  Avg Rew:-1459.23  LR:0.00095923   Polyak:0.99990  Bf: 2  EN:0.1918  Loss: 30.847 2.948 2.949\n",
      "Ep:430   Rew:-1522.42  Avg Rew:-1514.37  LR:0.00095877   Polyak:0.99990  Bf: 2  EN:0.1918  Loss: 31.138 2.807 2.808\n",
      "Ep:435   Rew:-1518.52  Avg Rew:-1485.80  LR:0.00095831   Polyak:0.99990  Bf: 2  EN:0.1917  Loss: 31.483 3.211 3.214\n",
      "Ep:440   Rew:-1450.49  Avg Rew:-1449.17  LR:0.00095785   Polyak:0.99990  Bf: 2  EN:0.1916  Loss: 31.785 3.209 3.211\n",
      "Ep:445   Rew:-1509.94  Avg Rew:-1500.43  LR:0.00095740   Polyak:0.99990  Bf: 2  EN:0.1915  Loss: 32.107 3.263 3.266\n",
      "Ep:450   Rew:-1497.99  Avg Rew:-1487.22  LR:0.00095694   Polyak:0.99990  Bf: 2  EN:0.1914  Loss: 32.469 3.469 3.473\n",
      "Ep:455   Rew:-1519.17  Avg Rew:-1500.43  LR:0.00095648   Polyak:0.99990  Bf: 2  EN:0.1913  Loss: 32.772 3.368 3.368\n",
      "Ep:460   Rew:-1491.32  Avg Rew:-1508.33  LR:0.00095602   Polyak:0.99990  Bf: 2  EN:0.1912  Loss: 33.135 3.479 3.480\n",
      "Ep:465   Rew:-1514.89  Avg Rew:-1494.18  LR:0.00095557   Polyak:0.99990  Bf: 2  EN:0.1911  Loss: 33.410 3.432 3.433\n",
      "Ep:470   Rew:-1510.26  Avg Rew:-1445.14  LR:0.00095511   Polyak:0.99990  Bf: 2  EN:0.1910  Loss: 33.768 3.418 3.421\n",
      "Ep:475   Rew:-1509.92  Avg Rew:-1502.12  LR:0.00095465   Polyak:0.99990  Bf: 2  EN:0.1909  Loss: 34.055 3.749 3.754\n",
      "Ep:480   Rew:-1514.29  Avg Rew:-1499.92  LR:0.00095420   Polyak:0.99990  Bf: 2  EN:0.1908  Loss: 34.385 3.746 3.750\n",
      "Ep:485   Rew:-1468.37  Avg Rew:-1433.03  LR:0.00095374   Polyak:0.99990  Bf: 2  EN:0.1907  Loss: 34.702 3.917 3.919\n",
      "Ep:490   Rew:-1458.03  Avg Rew:-1464.44  LR:0.00095329   Polyak:0.99990  Bf: 2  EN:0.1907  Loss: 35.016 4.006 4.009\n",
      "Ep:495   Rew:-1519.73  Avg Rew:-1508.42  LR:0.00095283   Polyak:0.99990  Bf: 2  EN:0.1906  Loss: 35.338 4.132 4.134\n",
      "Ep:500   Rew:-1506.63  Avg Rew:-1490.51  LR:0.00095238   Polyak:0.99990  Bf: 2  EN:0.1905  Loss: 35.674 3.958 3.959\n",
      "Ep:505   Rew:-1498.07  Avg Rew:-1448.39  LR:0.00095193   Polyak:0.99990  Bf: 2  EN:0.1904  Loss: 36.001 4.248 4.250\n",
      "Ep:510   Rew:-1473.02  Avg Rew:-1459.04  LR:0.00095147   Polyak:0.99990  Bf: 2  EN:0.1903  Loss: 36.293 4.291 4.294\n",
      "Ep:515   Rew:-1477.17  Avg Rew:-1419.37  LR:0.00095102   Polyak:0.99990  Bf: 2  EN:0.1902  Loss: 36.571 4.471 4.472\n",
      "Ep:520   Rew:-1513.76  Avg Rew:-1473.34  LR:0.00095057   Polyak:0.99990  Bf: 2  EN:0.1901  Loss: 36.970 4.529 4.530\n",
      "Ep:525   Rew:-1492.39  Avg Rew:-1495.15  LR:0.00095012   Polyak:0.99990  Bf: 2  EN:0.1900  Loss: 37.245 4.814 4.817\n",
      "Ep:530   Rew:-1404.17  Avg Rew:-1467.35  LR:0.00094967   Polyak:0.99990  Bf: 2  EN:0.1899  Loss: 37.533 4.679 4.679\n",
      "Ep:535   Rew:-1487.96  Avg Rew:-1467.18  LR:0.00094922   Polyak:0.99990  Bf: 2  EN:0.1898  Loss: 37.880 5.203 5.205\n",
      "Ep:540   Rew:-1522.50  Avg Rew:-1451.85  LR:0.00094877   Polyak:0.99990  Bf: 2  EN:0.1898  Loss: 38.201 5.048 5.052\n",
      "Ep:545   Rew:-1453.99  Avg Rew:-1477.87  LR:0.00094832   Polyak:0.99990  Bf: 2  EN:0.1897  Loss: 38.527 5.132 5.133\n",
      "Ep:550   Rew:-1519.27  Avg Rew:-1441.04  LR:0.00094787   Polyak:0.99990  Bf: 2  EN:0.1896  Loss: 38.835 5.189 5.191\n",
      "Ep:555   Rew:-1384.57  Avg Rew:-1403.16  LR:0.00094742   Polyak:0.99990  Bf: 2  EN:0.1895  Loss: 39.173 5.549 5.545\n",
      "Ep:560   Rew:-1415.87  Avg Rew:-1432.20  LR:0.00094697   Polyak:0.99990  Bf: 2  EN:0.1894  Loss: 39.490 5.489 5.490\n",
      "Ep:565   Rew:-1503.04  Avg Rew:-1434.68  LR:0.00094652   Polyak:0.99990  Bf: 2  EN:0.1893  Loss: 39.792 5.095 5.099\n",
      "Ep:570   Rew:-1301.03  Avg Rew:-1438.02  LR:0.00094607   Polyak:0.99990  Bf: 2  EN:0.1892  Loss: 40.105 5.431 5.432\n",
      "Ep:575   Rew:-1416.26  Avg Rew:-1445.92  LR:0.00094563   Polyak:0.99990  Bf: 2  EN:0.1891  Loss: 40.403 5.428 5.429\n",
      "Ep:580   Rew:-1518.13  Avg Rew:-1483.90  LR:0.00094518   Polyak:0.99990  Bf: 2  EN:0.1890  Loss: 40.728 5.752 5.755\n",
      "Ep:585   Rew:-1499.49  Avg Rew:-1489.35  LR:0.00094473   Polyak:0.99990  Bf: 2  EN:0.1889  Loss: 41.071 5.730 5.731\n",
      "Ep:590   Rew:-1485.41  Avg Rew:-1418.63  LR:0.00094429   Polyak:0.99990  Bf: 2  EN:0.1889  Loss: 41.329 6.528 6.529\n",
      "Ep:595   Rew:-1518.95  Avg Rew:-1482.24  LR:0.00094384   Polyak:0.99990  Bf: 2  EN:0.1888  Loss: 41.665 6.495 6.499\n",
      "Ep:600   Rew:-1397.53  Avg Rew:-1471.20  LR:0.00094340   Polyak:0.99990  Bf: 2  EN:0.1887  Loss: 42.049 6.413 6.414\n",
      "Ep:605   Rew:-1424.93  Avg Rew:-1432.87  LR:0.00094295   Polyak:0.99990  Bf: 2  EN:0.1886  Loss: 42.319 6.406 6.409\n",
      "Ep:610   Rew:-1388.92  Avg Rew:-1471.28  LR:0.00094251   Polyak:0.99990  Bf: 2  EN:0.1885  Loss: 42.604 7.067 7.067\n",
      "Ep:615   Rew:-1375.50  Avg Rew:-1380.79  LR:0.00094206   Polyak:0.99990  Bf: 2  EN:0.1884  Loss: 42.983 6.490 6.492\n",
      "Ep:620   Rew:-1514.86  Avg Rew:-1460.88  LR:0.00094162   Polyak:0.99990  Bf: 2  EN:0.1883  Loss: 43.293 6.333 6.339\n",
      "Ep:625   Rew:-1436.57  Avg Rew:-1491.12  LR:0.00094118   Polyak:0.99990  Bf: 2  EN:0.1882  Loss: 43.534 6.853 6.853\n",
      "Ep:630   Rew:-1500.17  Avg Rew:-1499.83  LR:0.00094073   Polyak:0.99990  Bf: 3  EN:0.1881  Loss: 43.863 6.788 6.791\n",
      "Ep:635   Rew:-1425.87  Avg Rew:-1457.40  LR:0.00094029   Polyak:0.99990  Bf: 3  EN:0.1881  Loss: 44.184 6.705 6.706\n",
      "Ep:640   Rew:-1415.80  Avg Rew:-1485.50  LR:0.00093985   Polyak:0.99990  Bf: 3  EN:0.1880  Loss: 44.487 7.466 7.471\n",
      "Ep:645   Rew:-1515.16  Avg Rew:-1464.78  LR:0.00093941   Polyak:0.99990  Bf: 3  EN:0.1879  Loss: 44.790 7.533 7.537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:650   Rew:-1517.05  Avg Rew:-1517.55  LR:0.00093897   Polyak:0.99990  Bf: 3  EN:0.1878  Loss: 45.119 7.744 7.750\n",
      "Ep:655   Rew:-1426.14  Avg Rew:-1409.93  LR:0.00093853   Polyak:0.99990  Bf: 3  EN:0.1877  Loss: 45.437 7.681 7.684\n",
      "Ep:660   Rew:-1451.13  Avg Rew:-1491.05  LR:0.00093809   Polyak:0.99990  Bf: 3  EN:0.1876  Loss: 45.752 7.668 7.671\n",
      "Ep:665   Rew:-1154.81  Avg Rew:-1358.56  LR:0.00093765   Polyak:0.99990  Bf: 3  EN:0.1875  Loss: 46.079 7.696 7.701\n",
      "Ep:670   Rew:-1479.24  Avg Rew:-1408.75  LR:0.00093721   Polyak:0.99990  Bf: 3  EN:0.1874  Loss: 46.352 8.159 8.168\n",
      "Ep:675   Rew:-1368.29  Avg Rew:-1387.54  LR:0.00093677   Polyak:0.99990  Bf: 3  EN:0.1874  Loss: 46.672 8.639 8.646\n",
      "Ep:680   Rew:-1368.85  Avg Rew:-1388.73  LR:0.00093633   Polyak:0.99990  Bf: 3  EN:0.1873  Loss: 46.991 7.871 7.876\n",
      "Ep:685   Rew:-965.90  Avg Rew:-1311.48  LR:0.00093589   Polyak:0.99990  Bf: 3  EN:0.1872  Loss: 47.307 8.941 8.947\n",
      "Ep:690   Rew:-1327.15  Avg Rew:-1363.42  LR:0.00093545   Polyak:0.99990  Bf: 3  EN:0.1871  Loss: 47.572 8.514 8.523\n",
      "Ep:695   Rew:-7.30  Avg Rew:-918.68  LR:0.00093502   Polyak:0.99990  Bf: 3  EN:0.1870  Loss: 47.797 9.285 9.292\n",
      "Ep:700   Rew:-1514.21  Avg Rew:-1012.66  LR:0.00093458   Polyak:0.99990  Bf: 3  EN:0.1869  Loss: 48.038 9.302 9.314\n",
      "Ep:705   Rew:-1303.90  Avg Rew:-1290.30  LR:0.00093414   Polyak:0.99990  Bf: 3  EN:0.1868  Loss: 48.360 9.229 9.232\n",
      "Ep:710   Rew:-1509.26  Avg Rew:-1365.37  LR:0.00093371   Polyak:0.99990  Bf: 3  EN:0.1867  Loss: 48.591 8.849 8.855\n",
      "Ep:715   Rew:-1341.29  Avg Rew:-1354.91  LR:0.00093327   Polyak:0.99990  Bf: 3  EN:0.1867  Loss: 48.839 9.528 9.531\n",
      "Ep:720   Rew:-1189.20  Avg Rew:-1266.84  LR:0.00093284   Polyak:0.99990  Bf: 3  EN:0.1866  Loss: 49.132 9.415 9.423\n",
      "Ep:725   Rew:-1199.54  Avg Rew:-1339.65  LR:0.00093240   Polyak:0.99990  Bf: 3  EN:0.1865  Loss: 49.445 9.514 9.521\n",
      "Ep:730   Rew:-1265.10  Avg Rew:-1247.98  LR:0.00093197   Polyak:0.99990  Bf: 3  EN:0.1864  Loss: 49.717 9.351 9.361\n",
      "Ep:735   Rew:-1235.28  Avg Rew:-1270.23  LR:0.00093153   Polyak:0.99990  Bf: 3  EN:0.1863  Loss: 49.985 10.247 10.256\n",
      "Ep:740   Rew:-1274.68  Avg Rew:-1262.03  LR:0.00093110   Polyak:0.99990  Bf: 3  EN:0.1862  Loss: 50.351 9.859 9.868\n",
      "Ep:745   Rew:-1241.38  Avg Rew:-1364.31  LR:0.00093067   Polyak:0.99990  Bf: 3  EN:0.1861  Loss: 50.572 9.734 9.738\n",
      "Ep:750   Rew:-1109.99  Avg Rew:-1187.15  LR:0.00093023   Polyak:0.99990  Bf: 3  EN:0.1860  Loss: 50.779 10.676 10.688\n",
      "Ep:755   Rew:-1170.55  Avg Rew:-1281.74  LR:0.00092980   Polyak:0.99990  Bf: 3  EN:0.1860  Loss: 51.145 10.966 10.975\n",
      "Ep:760   Rew:-1220.54  Avg Rew:-1345.67  LR:0.00092937   Polyak:0.99990  Bf: 3  EN:0.1859  Loss: 51.409 10.360 10.372\n",
      "Ep:765   Rew:-1192.22  Avg Rew:-1253.28  LR:0.00092894   Polyak:0.99990  Bf: 3  EN:0.1858  Loss: 51.719 10.147 10.156\n",
      "Ep:770   Rew:-1187.21  Avg Rew:-1309.23  LR:0.00092851   Polyak:0.99990  Bf: 3  EN:0.1857  Loss: 51.938 11.471 11.479\n",
      "Ep:775   Rew:-1508.84  Avg Rew:-1271.71  LR:0.00092807   Polyak:0.99990  Bf: 3  EN:0.1856  Loss: 52.213 11.465 11.476\n",
      "Ep:780   Rew:-1509.76  Avg Rew:-1285.28  LR:0.00092764   Polyak:0.99990  Bf: 3  EN:0.1855  Loss: 52.495 10.783 10.791\n",
      "Ep:785   Rew:-1187.94  Avg Rew:-1043.28  LR:0.00092721   Polyak:0.99990  Bf: 3  EN:0.1854  Loss: 52.756 10.517 10.526\n",
      "Ep:790   Rew:-1180.30  Avg Rew:-1282.92  LR:0.00092678   Polyak:0.99990  Bf: 3  EN:0.1854  Loss: 52.978 11.065 11.070\n",
      "Ep:795   Rew:-1196.39  Avg Rew:-1156.32  LR:0.00092635   Polyak:0.99990  Bf: 3  EN:0.1853  Loss: 53.279 11.476 11.489\n",
      "Ep:800   Rew:-1196.52  Avg Rew:-1144.39  LR:0.00092593   Polyak:0.99990  Bf: 3  EN:0.1852  Loss: 53.461 12.363 12.373\n",
      "Ep:805   Rew:-1172.02  Avg Rew:-1132.22  LR:0.00092550   Polyak:0.99990  Bf: 3  EN:0.1851  Loss: 53.695 11.090 11.099\n",
      "Ep:810   Rew:-953.29  Avg Rew:-1083.22  LR:0.00092507   Polyak:0.99990  Bf: 3  EN:0.1850  Loss: 53.974 11.484 11.496\n",
      "Ep:815   Rew:-1188.34  Avg Rew:-1144.60  LR:0.00092464   Polyak:0.99990  Bf: 3  EN:0.1849  Loss: 54.226 12.023 12.037\n",
      "Ep:820   Rew:-822.49  Avg Rew:-1006.02  LR:0.00092421   Polyak:0.99990  Bf: 3  EN:0.1848  Loss: 54.482 11.901 11.917\n",
      "Ep:825   Rew:-1080.88  Avg Rew:-1138.13  LR:0.00092379   Polyak:0.99990  Bf: 3  EN:0.1848  Loss: 54.700 12.434 12.444\n",
      "Ep:830   Rew:-1122.02  Avg Rew:-1134.74  LR:0.00092336   Polyak:0.99990  Bf: 3  EN:0.1847  Loss: 55.008 12.232 12.232\n",
      "Ep:835   Rew:-1515.31  Avg Rew:-1265.25  LR:0.00092293   Polyak:0.99990  Bf: 3  EN:0.1846  Loss: 55.210 12.337 12.342\n",
      "Ep:840   Rew:-1080.55  Avg Rew:-1042.32  LR:0.00092251   Polyak:0.99990  Bf: 3  EN:0.1845  Loss: 55.478 12.475 12.477\n",
      "Ep:845   Rew:-1136.00  Avg Rew:-1103.81  LR:0.00092208   Polyak:0.99990  Bf: 3  EN:0.1844  Loss: 55.744 12.251 12.253\n",
      "Ep:850   Rew:-1071.88  Avg Rew:-1213.94  LR:0.00092166   Polyak:0.99990  Bf: 3  EN:0.1843  Loss: 55.934 13.266 13.273\n",
      "Ep:855   Rew:-1042.54  Avg Rew:-1062.84  LR:0.00092123   Polyak:0.99990  Bf: 3  EN:0.1842  Loss: 56.234 11.851 11.851\n",
      "Ep:860   Rew:-1048.96  Avg Rew:-1052.42  LR:0.00092081   Polyak:0.99990  Bf: 3  EN:0.1842  Loss: 56.386 13.455 13.462\n",
      "Ep:865   Rew:-1044.25  Avg Rew:-1066.42  LR:0.00092039   Polyak:0.99990  Bf: 3  EN:0.1841  Loss: 56.623 12.950 12.961\n",
      "Ep:870   Rew:-953.00  Avg Rew:-1174.26  LR:0.00091996   Polyak:0.99990  Bf: 3  EN:0.1840  Loss: 56.877 13.364 13.359\n",
      "Ep:875   Rew:-1517.59  Avg Rew:-1211.61  LR:0.00091954   Polyak:0.99990  Bf: 4  EN:0.1839  Loss: 57.216 13.244 13.241\n",
      "Ep:880   Rew:-1066.86  Avg Rew:-1070.52  LR:0.00091912   Polyak:0.99990  Bf: 4  EN:0.1838  Loss: 57.418 12.546 12.552\n",
      "Ep:885   Rew:-1074.86  Avg Rew:-1206.03  LR:0.00091870   Polyak:0.99990  Bf: 4  EN:0.1837  Loss: 57.627 13.437 13.446\n",
      "Ep:890   Rew:-1111.93  Avg Rew:-1134.59  LR:0.00091827   Polyak:0.99990  Bf: 4  EN:0.1837  Loss: 57.917 14.663 14.666\n",
      "Ep:895   Rew:-919.53  Avg Rew:-927.41  LR:0.00091785   Polyak:0.99990  Bf: 4  EN:0.1836  Loss: 58.062 14.479 14.477\n",
      "Ep:900   Rew:-1110.90  Avg Rew:-1099.10  LR:0.00091743   Polyak:0.99990  Bf: 4  EN:0.1835  Loss: 58.360 14.582 14.583\n",
      "Ep:905   Rew:-1059.25  Avg Rew:-1208.90  LR:0.00091701   Polyak:0.99990  Bf: 4  EN:0.1834  Loss: 58.552 14.038 14.045\n",
      "Ep:910   Rew:-1515.04  Avg Rew:-1159.74  LR:0.00091659   Polyak:0.99990  Bf: 4  EN:0.1833  Loss: 58.758 14.044 14.061\n",
      "Ep:915   Rew:-997.76  Avg Rew:-1017.40  LR:0.00091617   Polyak:0.99990  Bf: 4  EN:0.1832  Loss: 59.044 15.259 15.262\n",
      "Ep:920   Rew:-1508.29  Avg Rew:-1511.37  LR:0.00091575   Polyak:0.99990  Bf: 4  EN:0.1832  Loss: 59.378 16.560 16.569\n",
      "Ep:925   Rew:-1053.40  Avg Rew:-1069.59  LR:0.00091533   Polyak:0.99990  Bf: 4  EN:0.1831  Loss: 59.545 15.064 15.072\n",
      "Ep:930   Rew:-1102.24  Avg Rew:-1067.75  LR:0.00091491   Polyak:0.99990  Bf: 4  EN:0.1830  Loss: 59.838 14.710 14.713\n",
      "Ep:935   Rew:-1059.77  Avg Rew:-1197.54  LR:0.00091449   Polyak:0.99990  Bf: 4  EN:0.1829  Loss: 60.069 15.723 15.734\n",
      "Ep:940   Rew:-1021.91  Avg Rew:-725.06  LR:0.00091408   Polyak:0.99990  Bf: 4  EN:0.1828  Loss: 60.189 16.120 16.122\n",
      "Ep:945   Rew:-1113.53  Avg Rew:-1073.25  LR:0.00091366   Polyak:0.99990  Bf: 4  EN:0.1827  Loss: 60.454 15.251 15.254\n",
      "Ep:950   Rew:-1508.33  Avg Rew:-1015.04  LR:0.00091324   Polyak:0.99990  Bf: 4  EN:0.1826  Loss: 60.643 16.284 16.294\n",
      "Ep:955   Rew:-1055.80  Avg Rew:-1013.91  LR:0.00091283   Polyak:0.99990  Bf: 4  EN:0.1826  Loss: 60.886 15.977 15.974\n",
      "Ep:960   Rew:-1049.72  Avg Rew:-1057.32  LR:0.00091241   Polyak:0.99990  Bf: 4  EN:0.1825  Loss: 61.086 15.701 15.709\n",
      "Ep:965   Rew:-1521.71  Avg Rew:-1207.70  LR:0.00091199   Polyak:0.99990  Bf: 4  EN:0.1824  Loss: 61.353 15.813 15.813\n",
      "Ep:970   Rew:-882.35  Avg Rew:-979.28  LR:0.00091158   Polyak:0.99990  Bf: 4  EN:0.1823  Loss: 61.508 15.523 15.538\n",
      "Ep:975   Rew:-1516.13  Avg Rew:-1336.73  LR:0.00091116   Polyak:0.99990  Bf: 4  EN:0.1822  Loss: 61.791 16.653 16.662\n",
      "Ep:980   Rew:-1072.29  Avg Rew:-1231.69  LR:0.00091075   Polyak:0.99990  Bf: 4  EN:0.1821  Loss: 62.103 17.879 17.890\n",
      "Ep:985   Rew:-915.50  Avg Rew:-998.49  LR:0.00091033   Polyak:0.99990  Bf: 4  EN:0.1821  Loss: 62.341 16.056 16.066\n",
      "Ep:990   Rew:-1031.54  Avg Rew:-984.58  LR:0.00090992   Polyak:0.99990  Bf: 4  EN:0.1820  Loss: 62.573 16.299 16.326\n",
      "Ep:995   Rew:-1510.30  Avg Rew:-1155.37  LR:0.00090950   Polyak:0.99990  Bf: 4  EN:0.1819  Loss: 62.698 17.922 17.921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1000   Rew:-1005.54  Avg Rew:-654.77  LR:0.00090909   Polyak:0.99990  Bf: 4  EN:0.1818  Loss: 62.953 17.089 17.091\n",
      "Ep:1005   Rew:-1048.10  Avg Rew:-994.56  LR:0.00090868   Polyak:0.99990  Bf: 4  EN:0.1817  Loss: 63.065 17.629 17.633\n",
      "Ep:1010   Rew:-1038.99  Avg Rew:-969.81  LR:0.00090827   Polyak:0.99990  Bf: 4  EN:0.1817  Loss: 63.268 18.414 18.413\n",
      "Ep:1015   Rew:-668.63  Avg Rew:-532.12  LR:0.00090785   Polyak:0.99990  Bf: 4  EN:0.1816  Loss: 63.498 18.201 18.210\n",
      "Ep:1020   Rew:-919.94  Avg Rew:-1135.79  LR:0.00090744   Polyak:0.99990  Bf: 4  EN:0.1815  Loss: 63.677 18.530 18.532\n",
      "Ep:1025   Rew:-955.29  Avg Rew:-636.29  LR:0.00090703   Polyak:0.99990  Bf: 4  EN:0.1814  Loss: 63.816 18.401 18.400\n",
      "Ep:1030   Rew:-897.37  Avg Rew:-906.09  LR:0.00090662   Polyak:0.99990  Bf: 4  EN:0.1813  Loss: 64.164 17.474 17.476\n",
      "Ep:1035   Rew:-965.79  Avg Rew:-861.53  LR:0.00090621   Polyak:0.99990  Bf: 4  EN:0.1812  Loss: 64.125 17.271 17.286\n",
      "Ep:1040   Rew:-929.42  Avg Rew:-1040.24  LR:0.00090580   Polyak:0.99990  Bf: 4  EN:0.1812  Loss: 64.372 18.218 18.230\n",
      "Ep:1045   Rew:-929.00  Avg Rew:-831.22  LR:0.00090539   Polyak:0.99990  Bf: 4  EN:0.1811  Loss: 64.530 18.102 18.110\n",
      "Ep:1050   Rew:-529.28  Avg Rew:-615.37  LR:0.00090498   Polyak:0.99990  Bf: 4  EN:0.1810  Loss: 64.842 17.788 17.802\n",
      "Ep:1055   Rew:-719.46  Avg Rew:-682.61  LR:0.00090457   Polyak:0.99990  Bf: 4  EN:0.1809  Loss: 64.886 18.768 18.798\n",
      "Ep:1060   Rew:-785.85  Avg Rew:-1032.49  LR:0.00090416   Polyak:0.99990  Bf: 4  EN:0.1808  Loss: 65.061 19.011 19.014\n",
      "Ep:1065   Rew:-789.09  Avg Rew:-790.23  LR:0.00090375   Polyak:0.99990  Bf: 4  EN:0.1808  Loss: 65.290 18.415 18.423\n",
      "Ep:1070   Rew:-696.99  Avg Rew:-958.40  LR:0.00090334   Polyak:0.99990  Bf: 4  EN:0.1807  Loss: 65.413 19.093 19.092\n",
      "Ep:1075   Rew:-909.73  Avg Rew:-1086.59  LR:0.00090293   Polyak:0.99990  Bf: 4  EN:0.1806  Loss: 65.544 19.737 19.747\n",
      "Ep:1080   Rew:-660.96  Avg Rew:-858.19  LR:0.00090253   Polyak:0.99990  Bf: 4  EN:0.1805  Loss: 65.767 18.498 18.490\n",
      "Ep:1085   Rew:-532.50  Avg Rew:-578.95  LR:0.00090212   Polyak:0.99990  Bf: 4  EN:0.1804  Loss: 65.918 19.124 19.123\n",
      "Ep:1090   Rew:-534.88  Avg Rew:-583.88  LR:0.00090171   Polyak:0.99990  Bf: 4  EN:0.1803  Loss: 66.072 18.742 18.748\n",
      "Ep:1095   Rew:-431.08  Avg Rew:-498.18  LR:0.00090131   Polyak:0.99990  Bf: 4  EN:0.1803  Loss: 66.196 21.632 21.614\n",
      "Ep:1100   Rew:-266.50  Avg Rew:-359.38  LR:0.00090090   Polyak:0.99990  Bf: 4  EN:0.1802  Loss: 66.232 19.082 19.078\n",
      "Ep:1105   Rew:-401.70  Avg Rew:-357.28  LR:0.00090050   Polyak:0.99990  Bf: 4  EN:0.1801  Loss: 66.254 19.169 19.165\n",
      "Ep:1110   Rew:-397.34  Avg Rew:-481.42  LR:0.00090009   Polyak:0.99990  Bf: 4  EN:0.1800  Loss: 66.381 21.196 21.198\n",
      "Ep:1115   Rew:-262.97  Avg Rew:-218.18  LR:0.00089969   Polyak:0.99990  Bf: 4  EN:0.1799  Loss: 66.334 19.941 19.944\n",
      "Ep:1120   Rew:-639.83  Avg Rew:-547.28  LR:0.00089928   Polyak:0.99990  Bf: 4  EN:0.1799  Loss: 66.386 19.220 19.212\n",
      "Ep:1125   Rew:-400.06  Avg Rew:-491.28  LR:0.00089888   Polyak:0.99990  Bf: 4  EN:0.1798  Loss: 66.629 18.115 18.123\n",
      "Ep:1130   Rew:-539.11  Avg Rew:-488.82  LR:0.00089847   Polyak:0.99990  Bf: 5  EN:0.1797  Loss: 66.829 19.144 19.135\n",
      "Ep:1135   Rew:-265.61  Avg Rew:-179.52  LR:0.00089807   Polyak:0.99990  Bf: 5  EN:0.1796  Loss: 66.675 19.398 19.409\n",
      "Ep:1137   Rew:-136.51  Avg Rew:-135.05  LR:0.00089791   Polyak:0.99990  Bf: 5  EN:0.1796  Loss: 66.787 19.999 20.009\n",
      "########## Solved! ###########\n",
      "Training time: 2443.00 sec\n"
     ]
    }
   ],
   "source": [
    "agent = TD3Trainer(env_name, actor_config, critic_config, random_seed=random_seed, lr_base=lr_base, lr_decay=lr_decay, \n",
    "                   exp_noise_base=exp_noise_base, exp_noise_decay=exp_noise_decay, gamma=gamma, batch_size=batch_size,\n",
    "                   polyak=polyak, policy_noise=policy_noise, noise_clip=noise_clip, policy_delay=policy_delay, \n",
    "                   max_episodes=max_episodes, max_timesteps=max_timesteps, max_buffer_length=max_buffer_length, \n",
    "                   log_interval=log_interval, threshold=threshold)\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test episode: 1\tReward: -1492.13\n",
      "Test episode: 2\tReward: -263.43\n",
      "Test episode: 3\tReward: -520.86\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
