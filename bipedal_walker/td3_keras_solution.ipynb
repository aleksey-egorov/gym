{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "action_space=Box(4,)\n",
      "obs_space=Box(24,)\n",
      "threshold=300 \n",
      "\n",
      "Episode 0\tLast length:    84\t Reward: -101.03\t Avg Reward: -101.03\t Noise: 1.00\n",
      "Episode 1\tLast length:    89\t Reward: -108.50\t Avg Reward: -104.77\t Noise: 1.00\n",
      "Episode 2\tLast length:    46\t Reward: -110.69\t Avg Reward: -106.74\t Noise: 1.00\n",
      "Episode 3\tLast length:    62\t Reward: -117.69\t Avg Reward: -109.48\t Noise: 1.00\n",
      "Episode 4\tLast length:   119\t Reward: -122.91\t Avg Reward: -112.17\t Noise: 1.00\n",
      "Episode 5\tLast length:    81\t Reward: -116.83\t Avg Reward: -112.94\t Noise: 0.99\n",
      "Episode 6\tLast length:    61\t Reward: -113.38\t Avg Reward: -113.01\t Noise: 0.99\n",
      "Episode 7\tLast length:    35\t Reward: -109.67\t Avg Reward: -112.59\t Noise: 0.99\n",
      "Episode 8\tLast length:  1599\t Reward: -132.44\t Avg Reward: -114.79\t Noise: 0.99\n",
      "Episode 9\tLast length:  1599\t Reward: -147.43\t Avg Reward: -118.06\t Noise: 0.99\n",
      "Episode 10\tLast length:  1599\t Reward: -146.98\t Avg Reward: -120.69\t Noise: 0.99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import namedtuple\n",
    "\n",
    "from TD3_keras.td3 import TD3\n",
    "\n",
    "args = {\n",
    "    'render': True,\n",
    "    'log_interval': 1\n",
    "}\n",
    "\n",
    "env = gym.make('BipedalWalker-v2')\n",
    "episodes = 100000\n",
    "reward_history = []\n",
    "\n",
    "task = {\n",
    "        'state_size': 24,\n",
    "        'action_size': 4,\n",
    "        'action_high': 1,\n",
    "        'action_low': -1\n",
    "    }\n",
    "agent = TD3(task)    \n",
    "\n",
    "\n",
    "def main(agent):   \n",
    "    \n",
    "    \n",
    "    for i_episode in range(episodes):\n",
    "        running_reward = 0        \n",
    "        state = env.reset()\n",
    "        for t in range(10000):  # Don't infinite loop while learning\n",
    "            action, noise_coeff = agent.act(state, i_episode)                \n",
    "            state, reward, done, _ = env.step(action)  \n",
    "            agent.step(action, reward, state, done, t)\n",
    "            if args['render']:\n",
    "                env.render()                   \n",
    "            running_reward += reward            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        reward_history.append(running_reward)\n",
    "        \n",
    "        if i_episode % args['log_interval'] == 0:\n",
    "            avg_reward = np.mean(reward_history[-100:])            \n",
    "            print('Episode {}\\tLast length: {:5d}\\t Reward: {:7.2f}\\t Avg Reward: {:7.2f}\\t Noise: {:.2f}'.format(\n",
    "                i_episode, t, running_reward, avg_reward, noise_coeff))\n",
    "        if avg_reward > env.spec.reward_threshold and i_episode > 100:\n",
    "            print(\"Solved! Average 100-episode reward is now {}!\".format(avg_reward))\n",
    "            break\n",
    "            \n",
    "print(\"action_space={}\".format(env.action_space))\n",
    "print(\"obs_space={}\".format(env.observation_space))\n",
    "print(\"threshold={} \\n\".format(env.spec.reward_threshold))\n",
    "main(agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def test(agent):   \n",
    "    random_seed = 0\n",
    "    episodes = 3\n",
    "    max_timesteps = 2000\n",
    "    render = True\n",
    "    save_gif = True\n",
    "     \n",
    "    for i_episode in range(1, episodes):\n",
    "        running_reward = 0        \n",
    "        state = env.reset()\n",
    "        for t in range(10000):  # Don't infinite loop while learning\n",
    "            action, noise_coeff = agent.act(state, i_episode)                \n",
    "            state, reward, done, _ = env.step(action)  \n",
    "            agent.step(action, reward, state, done, t)\n",
    "            if args['render']:\n",
    "                env.render()  \n",
    "                if save_gif:\n",
    "                    dirname = './gif/td3_keras/{}'.format(i_episode)\n",
    "                    if not os.path.isdir(dirname):\n",
    "                        os.mkdir(dirname)\n",
    "                    img = env.render(mode = 'rgb_array')\n",
    "                    img = Image.fromarray(img)\n",
    "                    img.save('./gif/td3_keras/{}/{}.jpg'.format(i_episode,t))\n",
    "            running_reward += reward            \n",
    "            if done:\n",
    "                break    \n",
    "   \n",
    "            \n",
    "        print('Episode: {}\\tReward: {}'.format(i_episode, int(running_reward)))\n",
    "        running_reward = 0\n",
    "        env.close()        \n",
    "                \n",
    "test(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
