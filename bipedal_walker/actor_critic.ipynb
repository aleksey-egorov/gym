{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "action_space=Box(4,)\n",
      "obs_space=Box(24,)\n",
      "threshold=300 \n",
      "\n",
      "Episode 0   Last length:   710   Reward: -152.80   Avg Reward: -152.80   Noise: 1.00   \n",
      "Probs: 0.0622 0.0233 0.3269 0.1225\n",
      "Episode 1   Last length:    93   Reward: -110.13   Avg Reward: -131.47   Noise: 1.00   \n",
      "Probs: 0.6036 0.7784 0.5920 0.4002\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import namedtuple\n",
    "\n",
    "from TD3.td3 import TD3\n",
    "\n",
    "args = {    \n",
    "    'render': True,\n",
    "    'log_interval': 1\n",
    "}\n",
    "\n",
    "env = gym.make('BipedalWalker-v2')\n",
    "episodes = 100000\n",
    "reward_history = []\n",
    "\n",
    "def main():   \n",
    "    task = {\n",
    "        'state_size': 24,\n",
    "        'action_size': 4,\n",
    "        'action_high': 1,\n",
    "        'action_low': -1\n",
    "    }\n",
    "    agent = TD3(task)\n",
    "    sum_reward = 0   \n",
    "    for i_episode in range(episodes):\n",
    "        probs_history = [[],[],[],[]]\n",
    "        running_reward = 0        \n",
    "        state = env.reset()\n",
    "        for t in range(10000):  # Don't infinite loop while learning\n",
    "            action, noise_coeff = agent.act(state, i_episode)                \n",
    "            state, reward, done, _ = env.step(action) \n",
    "            agent.step(action, reward, state, done, t)\n",
    "            for k in range(4):\n",
    "                probs_history[k].append(action[k])\n",
    "            if args['render']:\n",
    "                env.render()                   \n",
    "            running_reward += reward            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        reward_history.append(running_reward)\n",
    "        \n",
    "        if i_episode % args['log_interval'] == 0:\n",
    "            avg_reward = np.mean(reward_history[-100:])   \n",
    "            print('Episode {}   Last length: {:5d}   Reward: {:7.2f}   Avg Reward: {:7.2f}   Noise: {:.2f}   \\nProbs: {:.4f} {:.4f} {:.4f} {:.4f}'.format(\n",
    "                i_episode, t, running_reward, avg_reward, noise_coeff, np.mean(probs_history[0]), np.mean(probs_history[1]), np.mean(probs_history[2]), np.mean(probs_history[3])))\n",
    "        if running_reward > env.spec.reward_threshold:\n",
    "            print(\"Solved! Running reward is now {} and \"\n",
    "                  \"the last episode runs to {} time steps!\".format(running_reward, t))\n",
    "            break\n",
    "\n",
    "print(\"action_space={}\".format(env.action_space))\n",
    "print(\"obs_space={}\".format(env.observation_space))\n",
    "print(\"threshold={} \\n\".format(env.spec.reward_threshold))\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
