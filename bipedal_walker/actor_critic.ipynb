{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "action_space=Box(4,)\n",
      "obs_space=Box(24,)\n",
      "threshold=300 \n",
      "\n",
      "Episode: 1\tReward: -117.38364837284166\tAverage Reward: -117.38364837284166\n",
      "Episode: 2\tReward: -126.15036346807246\tAverage Reward: -121.76700592045705\n",
      "Episode: 3\tReward: -159.2917101232462\tAverage Reward: -134.27524065472008\n",
      "Episode: 4\tReward: -134.5799279937211\tAverage Reward: -134.35141248947033\n",
      "Episode: 5\tReward: -107.80148504645553\tAverage Reward: -129.04142700086737\n",
      "Episode: 6\tReward: -106.55710944241395\tAverage Reward: -125.29404074112513\n",
      "Episode: 7\tReward: -123.92387453411007\tAverage Reward: -125.09830271155155\n",
      "Episode: 8\tReward: -107.63605870294455\tAverage Reward: -122.9155222104757\n",
      "Episode: 9\tReward: -121.90678385961833\tAverage Reward: -122.80344017149156\n",
      "Episode: 10\tReward: -100.34347067362197\tAverage Reward: -120.5574432217046\n",
      "Episode: 11\tReward: -100.96442373494699\tAverage Reward: -118.77625963199935\n",
      "Episode: 12\tReward: -100.7301917016423\tAverage Reward: -117.27242063780294\n",
      "Episode: 13\tReward: -101.44108730273146\tAverage Reward: -116.05462576587435\n",
      "Episode: 14\tReward: -101.85018600543013\tAverage Reward: -115.04002292584262\n",
      "Episode: 15\tReward: -101.04542655511932\tAverage Reward: -114.10704983446107\n",
      "Episode: 16\tReward: -100.6952461240141\tAverage Reward: -113.26881210255813\n",
      "Episode: 17\tReward: -135.8600294914454\tAverage Reward: -114.5977072430809\n",
      "Episode: 18\tReward: -105.56195379797981\tAverage Reward: -114.09572094057529\n",
      "Episode: 19\tReward: -131.04487792734656\tAverage Reward: -114.98778183461589\n",
      "Episode: 20\tReward: -129.31704329876732\tAverage Reward: -115.70424490782345\n",
      "Episode: 21\tReward: -104.79319707701418\tAverage Reward: -115.18467120159444\n",
      "Episode: 22\tReward: -102.3370168046475\tAverage Reward: -114.60068691082414\n",
      "Episode: 23\tReward: -99.83214706546978\tAverage Reward: -113.95857648276524\n",
      "Episode: 24\tReward: -101.42420466422296\tAverage Reward: -113.43631099032598\n",
      "Episode: 25\tReward: -100.93671154807485\tAverage Reward: -112.93632701263594\n",
      "Episode: 26\tReward: -104.15571667325605\tAverage Reward: -112.59861123035209\n",
      "Episode: 27\tReward: -100.95723131849135\tAverage Reward: -112.16744901139428\n",
      "Episode: 28\tReward: -101.76496518116078\tAverage Reward: -111.79593173174308\n",
      "Episode: 29\tReward: -104.65126675813634\tAverage Reward: -111.54956397403251\n",
      "Episode: 30\tReward: -101.41665994288545\tAverage Reward: -111.2118005063276\n",
      "Episode: 31\tReward: -103.3414710459995\tAverage Reward: -110.95791891083316\n",
      "Episode: 32\tReward: -101.03117025548343\tAverage Reward: -110.64770801535349\n",
      "Episode: 33\tReward: -102.09702702374075\tAverage Reward: -110.3885964701531\n",
      "Episode: 34\tReward: -104.04874305815318\tAverage Reward: -110.20213019332958\n",
      "Episode: 35\tReward: -100.74895423793194\tAverage Reward: -109.9320394517468\n",
      "Episode: 36\tReward: -102.83921907410954\tAverage Reward: -109.7350166634791\n",
      "Episode: 37\tReward: -101.89714632140738\tAverage Reward: -109.5231823299096\n",
      "Episode: 38\tReward: -130.18288147053212\tAverage Reward: -110.06685862308387\n",
      "Episode: 39\tReward: -100.69140835765123\tAverage Reward: -109.82646246243176\n",
      "Episode: 40\tReward: -101.49172130777187\tAverage Reward: -109.61809393356523\n",
      "Episode: 41\tReward: -133.4451100903943\tAverage Reward: -110.19924066909765\n",
      "Episode: 42\tReward: -102.00829769248377\tAverage Reward: -110.00421821727352\n",
      "Episode: 43\tReward: -103.33193314274222\tAverage Reward: -109.84904879693558\n",
      "Episode: 44\tReward: -130.7749530597735\tAverage Reward: -110.3246375301819\n",
      "Episode: 45\tReward: -104.08003321976688\tAverage Reward: -110.18586854550601\n",
      "Episode: 46\tReward: -103.34517989091158\tAverage Reward: -110.03715792258005\n",
      "Episode: 47\tReward: -130.21919658340784\tAverage Reward: -110.46656300047\n",
      "Episode: 48\tReward: -131.16665242478817\tAverage Reward: -110.89781486347663\n",
      "Episode: 49\tReward: -131.03912897182352\tAverage Reward: -111.30886209017758\n",
      "Episode: 50\tReward: -129.03623187080987\tAverage Reward: -111.66340948579024\n",
      "Episode: 51\tReward: -103.47457969779528\tAverage Reward: -111.50284419582954\n",
      "Episode: 52\tReward: -127.40573731093349\tAverage Reward: -111.8086690634277\n",
      "Episode: 53\tReward: -123.43670710571297\tAverage Reward: -112.02806600762176\n",
      "Episode: 54\tReward: -134.49648863066284\tAverage Reward: -112.44414790804844\n",
      "Episode: 55\tReward: -133.8458901006823\tAverage Reward: -112.83327049336906\n",
      "Episode: 56\tReward: -132.1432981009592\tAverage Reward: -113.17809241493316\n",
      "Episode: 57\tReward: -101.07310942171185\tAverage Reward: -112.96572429224506\n",
      "Episode: 58\tReward: -126.83935118952516\tAverage Reward: -113.20492475599127\n",
      "Episode: 59\tReward: -99.38793591900962\tAverage Reward: -112.97073850451702\n",
      "Episode: 60\tReward: -105.35884835026388\tAverage Reward: -112.84387366861279\n",
      "Episode: 61\tReward: -124.53281349471496\tAverage Reward: -113.03549563297511\n",
      "Episode: 62\tReward: -127.93928731341666\tAverage Reward: -113.27587936975642\n",
      "Episode: 63\tReward: -122.96674622754954\tAverage Reward: -113.42970265321345\n",
      "Episode: 64\tReward: -125.48790708517642\tAverage Reward: -113.61811209746288\n",
      "Episode: 65\tReward: -98.89800708931922\tAverage Reward: -113.39164894349145\n",
      "Episode: 66\tReward: -127.49153861509913\tAverage Reward: -113.60528363548549\n",
      "Episode: 67\tReward: -105.57823473838906\tAverage Reward: -113.48547693552884\n",
      "Episode: 68\tReward: -127.37573007388346\tAverage Reward: -113.68974536403405\n",
      "Episode: 69\tReward: -123.63483647234702\tAverage Reward: -113.833877119227\n",
      "Episode: 70\tReward: -128.66561320687208\tAverage Reward: -114.0457590633362\n",
      "Episode: 71\tReward: -132.44774477390425\tAverage Reward: -114.30494196066816\n",
      "Episode: 72\tReward: -103.21469618545277\tAverage Reward: -114.15091076934573\n",
      "Episode: 73\tReward: -125.86345817648707\tAverage Reward: -114.31135662423807\n",
      "Episode: 74\tReward: -129.78010624952344\tAverage Reward: -114.52039378133654\n",
      "Episode: 75\tReward: -173.6388501852253\tAverage Reward: -115.30863986672172\n",
      "Episode: 76\tReward: -103.79969737006776\tAverage Reward: -115.15720641281838\n",
      "Episode: 77\tReward: -110.42182664602329\tAverage Reward: -115.09570797428857\n",
      "Episode: 78\tReward: -104.81037439329936\tAverage Reward: -114.96384472325023\n",
      "Episode: 79\tReward: -148.51701070955406\tAverage Reward: -115.38856834333004\n",
      "Episode: 80\tReward: -108.46982623389759\tAverage Reward: -115.30208406696211\n",
      "Episode: 81\tReward: -116.77898330915251\tAverage Reward: -115.32031739093976\n",
      "Episode: 82\tReward: -120.68162287173494\tAverage Reward: -115.38569916509579\n",
      "Episode: 83\tReward: -112.09556984128797\tAverage Reward: -115.34605905276075\n",
      "Episode: 84\tReward: -115.19511214163732\tAverage Reward: -115.34426206572356\n",
      "Episode: 85\tReward: -114.05610029217476\tAverage Reward: -115.32910722132887\n",
      "Episode: 86\tReward: -109.02257915937743\tAverage Reward: -115.25577549967826\n",
      "Episode: 87\tReward: -110.5873182744207\tAverage Reward: -115.20211507180173\n",
      "Episode: 88\tReward: -111.47979658712227\tAverage Reward: -115.15981599811225\n",
      "Episode: 89\tReward: -109.55496997633755\tAverage Reward: -115.09684020011478\n",
      "Episode: 90\tReward: -111.12009148270538\tAverage Reward: -115.05265410325468\n",
      "Episode: 91\tReward: -110.7984322792728\tAverage Reward: -115.00590441288125\n",
      "Episode: 92\tReward: -125.66161765391182\tAverage Reward: -115.12172738289246\n",
      "Episode: 93\tReward: -114.82723541248286\tAverage Reward: -115.11856080256547\n",
      "Episode: 94\tReward: -115.90632458636699\tAverage Reward: -115.12694126835059\n",
      "Episode: 95\tReward: -109.6823518252326\tAverage Reward: -115.0696298005283\n",
      "Episode: 96\tReward: -111.32191010412338\tAverage Reward: -115.03059105369074\n",
      "Episode: 97\tReward: -108.79791753487726\tAverage Reward: -114.96633668751741\n",
      "Episode: 98\tReward: -109.80102445949781\tAverage Reward: -114.91362941988456\n",
      "Episode: 99\tReward: -118.06297899349266\tAverage Reward: -114.94544103173916\n",
      "Episode: 100\tReward: -112.29753168778046\tAverage Reward: -114.91896193829957\n",
      "Episode: 101\tReward: -111.68757661749194\tAverage Reward: -114.86200122074608\n",
      "Episode: 102\tReward: -110.04515451122819\tAverage Reward: -114.70094913117764\n",
      "Episode: 103\tReward: -106.53575373545806\tAverage Reward: -114.17338956729978\n",
      "Episode: 104\tReward: -109.05329188669317\tAverage Reward: -113.9181232062295\n",
      "Episode: 105\tReward: -106.39730574285076\tAverage Reward: -113.90408141319344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 106\tReward: -108.7059167199559\tAverage Reward: -113.92556948596885\n",
      "Episode: 107\tReward: -110.17181592048047\tAverage Reward: -113.78804889983259\n",
      "Episode: 108\tReward: -107.56271374501422\tAverage Reward: -113.78731545025329\n",
      "Episode: 109\tReward: -91.26323039170036\tAverage Reward: -113.48087991557408\n",
      "Episode: 110\tReward: -130.6876588873643\tAverage Reward: -113.78432179771148\n",
      "Episode: 111\tReward: -92.8741092530532\tAverage Reward: -113.70341865289257\n",
      "Episode: 112\tReward: -125.7380270756353\tAverage Reward: -113.95349700663247\n",
      "Episode: 113\tReward: -119.74557199535198\tAverage Reward: -114.13654185355868\n",
      "Episode: 114\tReward: -123.74916249418882\tAverage Reward: -114.35553161844629\n",
      "Episode: 115\tReward: -112.146923895015\tAverage Reward: -114.46654659184526\n",
      "Episode: 116\tReward: -147.0620669034024\tAverage Reward: -114.93021479963915\n",
      "Episode: 117\tReward: -133.24938323745044\tAverage Reward: -114.90410833709919\n",
      "Episode: 118\tReward: -141.46073135089046\tAverage Reward: -115.26309611262833\n",
      "Episode: 119\tReward: -108.72575953058741\tAverage Reward: -115.0399049286607\n",
      "Episode: 120\tReward: -142.73194247333083\tAverage Reward: -115.17405392040634\n",
      "Episode: 121\tReward: -107.17809032399467\tAverage Reward: -115.19790285287613\n",
      "Episode: 122\tReward: -97.41216685845998\tAverage Reward: -115.14865435341426\n",
      "Episode: 123\tReward: -96.4314450702752\tAverage Reward: -115.11464733346229\n",
      "Episode: 124\tReward: -107.57179569668392\tAverage Reward: -115.17612324378692\n",
      "Episode: 125\tReward: -106.58591216559172\tAverage Reward: -115.2326152499621\n",
      "Episode: 126\tReward: -103.44054791783716\tAverage Reward: -115.2254635624079\n",
      "Episode: 127\tReward: -99.17702212725757\tAverage Reward: -115.20766147049557\n",
      "Episode: 128\tReward: -101.85401801137849\tAverage Reward: -115.20855199879774\n",
      "Episode: 129\tReward: -84.37931741923488\tAverage Reward: -115.00583250540872\n",
      "Episode: 130\tReward: -99.05713387542568\tAverage Reward: -114.98223724473411\n",
      "Episode: 131\tReward: -95.7967687094038\tAverage Reward: -114.90679022136815\n",
      "Episode: 132\tReward: -118.38394410205744\tAverage Reward: -115.0803179598339\n",
      "Episode: 133\tReward: -115.10112896222536\tAverage Reward: -115.21035897921877\n",
      "Episode: 134\tReward: -129.18952117393428\tAverage Reward: -115.46176676037658\n",
      "Episode: 135\tReward: -111.05795202376372\tAverage Reward: -115.56485673823488\n",
      "Episode: 136\tReward: -114.29000451133629\tAverage Reward: -115.67936459260716\n",
      "Episode: 137\tReward: -118.34998330430132\tAverage Reward: -115.84389296243607\n",
      "Episode: 138\tReward: -118.02228315194711\tAverage Reward: -115.72228697925024\n",
      "Episode: 139\tReward: -98.72347344404339\tAverage Reward: -115.70260763011416\n",
      "Episode: 140\tReward: -130.78301471333918\tAverage Reward: -115.99552056416982\n",
      "Episode: 141\tReward: -114.0697421826974\tAverage Reward: -115.80176688509287\n",
      "Episode: 142\tReward: -150.70430173850394\tAverage Reward: -116.28872692555305\n",
      "Episode: 143\tReward: -114.51418761279187\tAverage Reward: -116.4005494702536\n",
      "Episode: 144\tReward: -111.15122743314268\tAverage Reward: -116.20431221398727\n",
      "Episode: 145\tReward: -111.01133521148856\tAverage Reward: -116.2736252339045\n",
      "Episode: 146\tReward: -106.79713862402856\tAverage Reward: -116.30814482123564\n",
      "Episode: 147\tReward: -134.73918015763095\tAverage Reward: -116.35334465697788\n",
      "Episode: 148\tReward: -107.49925182240786\tAverage Reward: -116.11667065095406\n",
      "Episode: 149\tReward: -107.65457432387763\tAverage Reward: -115.88282510447462\n",
      "Episode: 150\tReward: -104.59364035103363\tAverage Reward: -115.63839918927687\n",
      "Episode: 151\tReward: -105.78077997388108\tAverage Reward: -115.66146119203772\n",
      "Episode: 152\tReward: -131.9084356524147\tAverage Reward: -115.70648817545252\n",
      "Episode: 153\tReward: -136.58804013898333\tAverage Reward: -115.83800150578521\n",
      "Episode: 154\tReward: -131.0639392893062\tAverage Reward: -115.80367601237165\n",
      "Episode: 155\tReward: -101.45868210219571\tAverage Reward: -115.47980393238679\n",
      "Episode: 156\tReward: -124.0677476671947\tAverage Reward: -115.39904842804916\n",
      "Episode: 157\tReward: -105.50366204895744\tAverage Reward: -115.44335395432161\n",
      "Episode: 158\tReward: -102.53990851250799\tAverage Reward: -115.20035952755144\n",
      "Episode: 159\tReward: -101.34208051660711\tAverage Reward: -115.21990097352742\n",
      "Episode: 160\tReward: -105.69613565271789\tAverage Reward: -115.22327384655195\n",
      "Episode: 161\tReward: -132.0201111023025\tAverage Reward: -115.29814682262783\n",
      "Episode: 162\tReward: -117.10992977155472\tAverage Reward: -115.18985324720924\n",
      "Episode: 163\tReward: -112.88301060951383\tAverage Reward: -115.08901589102885\n",
      "Episode: 164\tReward: -117.96179095148209\tAverage Reward: -115.01375472969193\n",
      "Episode: 165\tReward: -104.95030202490341\tAverage Reward: -115.07427767904775\n",
      "Episode: 166\tReward: -101.31119879077796\tAverage Reward: -114.81247428080455\n",
      "Episode: 167\tReward: -114.5177348713355\tAverage Reward: -114.90186928213399\n",
      "Episode: 168\tReward: -112.87573622915411\tAverage Reward: -114.7568693436867\n",
      "Episode: 169\tReward: -106.66916857119509\tAverage Reward: -114.5872126646752\n",
      "Episode: 170\tReward: -107.93763983366688\tAverage Reward: -114.37993293094314\n",
      "Episode: 171\tReward: -104.96680383240924\tAverage Reward: -114.1051235215282\n",
      "Episode: 172\tReward: -114.64443981810544\tAverage Reward: -114.21942095785472\n",
      "Episode: 173\tReward: -130.41274387953408\tAverage Reward: -114.26491381488519\n",
      "Episode: 174\tReward: -135.58031963350243\tAverage Reward: -114.32291594872498\n",
      "Episode: 175\tReward: -156.22371833492835\tAverage Reward: -114.14876463022199\n",
      "Episode: 176\tReward: -139.85448510360175\tAverage Reward: -114.50931250755737\n",
      "Episode: 177\tReward: -134.63806528671364\tAverage Reward: -114.75147489396426\n",
      "Episode: 178\tReward: -147.6658340527516\tAverage Reward: -115.18002949055877\n",
      "Episode: 179\tReward: -110.25494200169207\tAverage Reward: -114.79740880348015\n",
      "Episode: 180\tReward: -85.36157650498399\tAverage Reward: -114.56632630619102\n",
      "Episode: 181\tReward: -140.3608700023154\tAverage Reward: -114.80214517312267\n",
      "Episode: 182\tReward: -110.26978013452086\tAverage Reward: -114.69802674575048\n",
      "Episode: 183\tReward: -79.81280465455632\tAverage Reward: -114.3751990938832\n",
      "Episode: 184\tReward: -84.90907439606417\tAverage Reward: -114.07233871642748\n",
      "Episode: 185\tReward: -103.98154429398615\tAverage Reward: -113.97159315644556\n",
      "Episode: 186\tReward: -127.87226200094449\tAverage Reward: -114.16008998486124\n",
      "Episode: 187\tReward: -100.5310386509687\tAverage Reward: -114.0595271886267\n",
      "Episode: 188\tReward: -146.73145591360688\tAverage Reward: -114.41204378189155\n",
      "Episode: 189\tReward: -132.71552092256394\tAverage Reward: -114.64364929135382\n",
      "Episode: 190\tReward: -94.98245742590241\tAverage Reward: -114.48227295078578\n",
      "Episode: 191\tReward: -69.55223469234326\tAverage Reward: -114.06981097491649\n",
      "Episode: 192\tReward: -120.52930602433315\tAverage Reward: -114.0184878586207\n",
      "Episode: 193\tReward: -31.332639037367713\tAverage Reward: -113.18354189486956\n",
      "Episode: 194\tReward: -9.411675259148007\tAverage Reward: -112.11859540159735\n",
      "Episode: 195\tReward: 3.3567308510878053\tAverage Reward: -110.98820457483414\n",
      "Episode: 196\tReward: -100.92649696620296\tAverage Reward: -110.88425044345495\n",
      "Episode: 197\tReward: -75.92433578827108\tAverage Reward: -110.5555146259889\n",
      "Episode: 198\tReward: -68.27747255030899\tAverage Reward: -110.14027910689701\n",
      "Episode: 199\tReward: -117.7522026556499\tAverage Reward: -110.1371713435186\n",
      "Episode: 200\tReward: -106.18827120250627\tAverage Reward: -110.07607873866587\n",
      "Episode: 201\tReward: -104.23499419244837\tAverage Reward: -110.00155291441543\n",
      "Episode: 202\tReward: -138.67595189902312\tAverage Reward: -110.28786088829338\n",
      "Episode: 203\tReward: -131.8097600256322\tAverage Reward: -110.54060095119512\n",
      "Episode: 204\tReward: -117.79433541696511\tAverage Reward: -110.62801138649782\n",
      "Episode: 205\tReward: -144.36051116862203\tAverage Reward: -111.00764344075554\n",
      "Episode: 206\tReward: -103.1676535558407\tAverage Reward: -110.95226080911438\n",
      "Episode: 207\tReward: -142.14433507319694\tAverage Reward: -111.27198600064156\n",
      "Episode: 208\tReward: -107.29581336353334\tAverage Reward: -111.26931699682675\n",
      "Episode: 209\tReward: -113.23517581678905\tAverage Reward: -111.48903645107762\n",
      "Episode: 210\tReward: -141.45786126331174\tAverage Reward: -111.59673847483711\n",
      "Episode: 211\tReward: -150.28338379228103\tAverage Reward: -112.17083122022937\n",
      "Episode: 212\tReward: -165.884415947758\tAverage Reward: -112.57229510895063\n",
      "Episode: 213\tReward: -118.47161820081378\tAverage Reward: -112.55955557100522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 214\tReward: -143.0680615006412\tAverage Reward: -112.75274456106972\n",
      "Episode: 215\tReward: -96.29601060889941\tAverage Reward: -112.59423542820858\n",
      "Episode: 216\tReward: -106.81813395882389\tAverage Reward: -112.19179609876281\n",
      "Episode: 217\tReward: -112.32354242590125\tAverage Reward: -111.98253769064733\n",
      "Episode: 218\tReward: -79.31342834594489\tAverage Reward: -111.36106466059788\n",
      "Episode: 219\tReward: -96.4996510107235\tAverage Reward: -111.23880357539922\n",
      "Episode: 220\tReward: -97.17802140467847\tAverage Reward: -110.78326436471271\n",
      "Episode: 221\tReward: -112.82714751141644\tAverage Reward: -110.8397549365869\n",
      "Episode: 222\tReward: -107.01563296387118\tAverage Reward: -110.93578959764102\n",
      "Episode: 223\tReward: -99.49317347766414\tAverage Reward: -110.96640688171489\n",
      "Episode: 224\tReward: -67.65176933771633\tAverage Reward: -110.5672066181252\n",
      "Episode: 225\tReward: -39.468847207414946\tAverage Reward: -109.89603596854347\n",
      "Episode: 226\tReward: -114.4823157763033\tAverage Reward: -110.00645364712813\n",
      "Episode: 227\tReward: 46.841880112131086\tAverage Reward: -108.54626462473426\n",
      "Episode: 228\tReward: -20.50012595926812\tAverage Reward: -107.73272570421315\n",
      "Episode: 229\tReward: -134.09913590833003\tAverage Reward: -108.2299238891041\n",
      "Episode: 230\tReward: -105.72022386206937\tAverage Reward: -108.29655478897054\n",
      "Episode: 231\tReward: -97.62910624577017\tAverage Reward: -108.3148781643342\n",
      "Episode: 232\tReward: -105.26408780148574\tAverage Reward: -108.18367960132849\n",
      "Episode: 233\tReward: -107.6135018479399\tAverage Reward: -108.10880333018564\n",
      "Episode: 234\tReward: -23.14340467372251\tAverage Reward: -107.04834216518351\n",
      "Episode: 235\tReward: -95.6726887002787\tAverage Reward: -106.89448953194868\n",
      "Episode: 236\tReward: 19.604555940302866\tAverage Reward: -105.55554392743228\n",
      "Episode: 237\tReward: 39.405697155631536\tAverage Reward: -103.97798712283294\n",
      "Episode: 238\tReward: 58.39930399147386\tAverage Reward: -102.21377125139873\n",
      "Episode: 239\tReward: -101.67273308105229\tAverage Reward: -102.24326384776882\n",
      "Episode: 240\tReward: -112.23223474667951\tAverage Reward: -102.05775604810223\n",
      "Episode: 241\tReward: -19.921933311175547\tAverage Reward: -101.116277959387\n",
      "Episode: 242\tReward: -73.35220365498381\tAverage Reward: -100.34275697855179\n",
      "Episode: 243\tReward: -70.54581151112704\tAverage Reward: -99.90307321753515\n",
      "Episode: 244\tReward: -46.86123956113316\tAverage Reward: -99.26017333881504\n",
      "Episode: 245\tReward: 3.237413683557405\tAverage Reward: -98.11768584986457\n",
      "Episode: 246\tReward: -102.35992810108111\tAverage Reward: -98.0733137446351\n",
      "Episode: 247\tReward: -5.927727146424305\tAverage Reward: -96.78519921452303\n",
      "Episode: 248\tReward: -101.74637080531683\tAverage Reward: -96.72767040435214\n",
      "Episode: 249\tReward: 52.17554224172705\tAverage Reward: -95.12936923869609\n",
      "Episode: 250\tReward: 38.059178189525845\tAverage Reward: -93.7028410532905\n",
      "Episode: 251\tReward: 48.390306667433244\tAverage Reward: -92.16113018687736\n",
      "Episode: 252\tReward: 23.652069274849428\tAverage Reward: -90.60552513760473\n",
      "Episode: 253\tReward: 51.85040267879586\tAverage Reward: -88.72114070942693\n",
      "Episode: 254\tReward: 70.07751023214574\tAverage Reward: -86.70972621421241\n",
      "Episode: 255\tReward: 91.18145772113064\tAverage Reward: -84.78332481597914\n",
      "Episode: 256\tReward: 109.22417002077037\tAverage Reward: -82.4504056390995\n",
      "Episode: 257\tReward: 109.30783025501279\tAverage Reward: -80.3022907160598\n",
      "Episode: 258\tReward: 148.14899852304387\tAverage Reward: -77.79540164570427\n",
      "Episode: 259\tReward: 112.58645623327044\tAverage Reward: -75.65611627820549\n",
      "Episode: 260\tReward: 141.26823914564582\tAverage Reward: -73.18647253022186\n",
      "Episode: 261\tReward: 143.09447371523368\tAverage Reward: -70.4353266820465\n",
      "Episode: 262\tReward: 117.42086953508623\tAverage Reward: -68.09001868898008\n",
      "Episode: 263\tReward: 126.5315654836889\tAverage Reward: -65.69587292804806\n",
      "Episode: 264\tReward: 104.17263284790833\tAverage Reward: -63.47452869005416\n",
      "Episode: 265\tReward: 130.62238901300807\tAverage Reward: -61.11880177967505\n",
      "Episode: 266\tReward: 166.44332082903796\tAverage Reward: -58.441256583476886\n",
      "Episode: 267\tReward: -33.148516175753485\tAverage Reward: -57.627564396521066\n",
      "Episode: 268\tReward: 142.72149157436158\tAverage Reward: -55.07159211848592\n",
      "Episode: 269\tReward: -108.96445946602064\tAverage Reward: -55.09454502743416\n",
      "Episode: 270\tReward: 77.59506283578096\tAverage Reward: -53.239218000739676\n",
      "Episode: 271\tReward: 85.79729267682691\tAverage Reward: -51.331577035647314\n",
      "Episode: 272\tReward: 12.704794883868972\tAverage Reward: -50.05808468862757\n",
      "Episode: 273\tReward: 119.80657000633056\tAverage Reward: -47.55589154976893\n",
      "Episode: 274\tReward: 195.5653276769234\tAverage Reward: -44.244435076664665\n",
      "Episode: 275\tReward: 162.49349324215424\tAverage Reward: -41.05726296089385\n",
      "Episode: 276\tReward: 110.7840166058671\tAverage Reward: -38.55087794379916\n",
      "Episode: 277\tReward: 146.26795782817584\tAverage Reward: -35.74181771265026\n",
      "Episode: 278\tReward: 169.77718130021717\tAverage Reward: -32.567387559120576\n",
      "Episode: 279\tReward: -108.14163672641473\tAverage Reward: -32.5462545063678\n",
      "Episode: 280\tReward: -116.93358400774608\tAverage Reward: -32.86197458139542\n",
      "Episode: 281\tReward: 176.1472139295469\tAverage Reward: -29.6968937420768\n",
      "Episode: 282\tReward: 157.39292450208168\tAverage Reward: -27.02026669571077\n",
      "Episode: 283\tReward: 162.20741341727103\tAverage Reward: -24.6000645149925\n",
      "Episode: 284\tReward: 139.9747914396868\tAverage Reward: -22.351225856634994\n",
      "Episode: 285\tReward: 178.83253317966862\tAverage Reward: -19.523085081898444\n",
      "Episode: 286\tReward: 113.34160827099072\tAverage Reward: -17.110946379179094\n",
      "Episode: 287\tReward: 183.96912417241646\tAverage Reward: -14.26594475094524\n",
      "Episode: 288\tReward: 153.4322725478829\tAverage Reward: -11.264307466330342\n",
      "Episode: 289\tReward: 178.77131173049185\tAverage Reward: -8.149439139799783\n",
      "Episode: 290\tReward: 233.01406338327837\tAverage Reward: -4.869473931707976\n",
      "Episode: 291\tReward: 208.04320418564558\tAverage Reward: -2.0935195429280897\n",
      "Episode: 292\tReward: 204.62203042805407\tAverage Reward: 1.1579938215957808\n",
      "Episode: 293\tReward: 192.97627258095244\tAverage Reward: 3.401082937778981\n",
      "Episode: 294\tReward: -105.7862096854821\tAverage Reward: 2.4373375935156423\n",
      "Episode: 295\tReward: 231.98417978937553\tAverage Reward: 4.7236120828985175\n",
      "Episode: 296\tReward: 233.50928903350828\tAverage Reward: 8.06796994289563\n",
      "Episode: 297\tReward: 245.63408376602968\tAverage Reward: 11.283554138438637\n",
      "Episode: 298\tReward: 217.9028390305196\tAverage Reward: 14.145357254246926\n",
      "Episode: 299\tReward: 247.08247970004058\tAverage Reward: 17.79370407780383\n",
      "Episode: 300\tReward: 246.85747446724008\tAverage Reward: 21.32416153450129\n",
      "Episode: 301\tReward: 249.63062953919015\tAverage Reward: 24.862817771817678\n",
      "Episode: 302\tReward: 249.28511234732252\tAverage Reward: 28.742428414281136\n",
      "Episode: 303\tReward: 242.46938921062548\tAverage Reward: 32.485219906643714\n",
      "Episode: 304\tReward: 254.93349807685735\tAverage Reward: 36.21249824158193\n",
      "Episode: 305\tReward: 250.13784922823223\tAverage Reward: 40.15748184555048\n",
      "Episode: 306\tReward: 247.3350144628044\tAverage Reward: 43.66250852573693\n",
      "Episode: 307\tReward: 254.66797787435996\tAverage Reward: 47.630631655212504\n",
      "Episode: 308\tReward: 249.3102181546364\tAverage Reward: 51.1966919703942\n",
      "Episode: 309\tReward: -114.99744090742257\tAverage Reward: 51.179069319487866\n",
      "Episode: 310\tReward: 250.62336970134555\tAverage Reward: 55.09988162913444\n",
      "Episode: 311\tReward: 246.89943734042907\tAverage Reward: 59.07170984046154\n",
      "Episode: 312\tReward: 246.2557842185892\tAverage Reward: 63.193111842125\n",
      "Episode: 313\tReward: 248.50843197505418\tAverage Reward: 66.86291234388368\n",
      "Episode: 314\tReward: 241.65415339051827\tAverage Reward: 70.71013449279528\n",
      "Episode: 315\tReward: 251.35408272619975\tAverage Reward: 74.18663542614627\n",
      "Episode: 316\tReward: 250.88415674540025\tAverage Reward: 77.7636583331885\n",
      "Episode: 317\tReward: 248.4659107008388\tAverage Reward: 81.37155286445592\n",
      "Episode: 318\tReward: 225.42096457873717\tAverage Reward: 84.41889679370273\n",
      "Episode: 319\tReward: 243.9368310541205\tAverage Reward: 87.8232616143512\n",
      "Episode: 320\tReward: 240.95456276102777\tAverage Reward: 91.20458745600826\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "from TD3 import TD3\n",
    "from PIL import Image\n",
    "from utils import ReplayBuffer\n",
    "\n",
    "env_name = 'BipedalWalker-v2'\n",
    "episodes = 100000\n",
    "log_interval = 1           # print avg reward after interval\n",
    "random_seed = 0\n",
    "gamma = 0.99                # discount for future rewards\n",
    "batch_size = 100            # num of transitions sampled from replay buffer\n",
    "exploration_noise = 0.1 \n",
    "polyak = 0.995              # target policy update parameter (1-tau)\n",
    "policy_noise = 0.2          # target policy smoothing noise\n",
    "noise_clip = 0.5\n",
    "policy_delay = 2            # delayed policy updates parameter\n",
    "max_episodes = 1500         # max num of episodes\n",
    "max_timesteps = 2000        # max timesteps in one episode\n",
    "directory = \"./preTrained/{}\".format(env_name) # save trained models\n",
    "filename = \"TD3_{}_{}\".format(env_name, random_seed)\n",
    "reward_history = []\n",
    "\n",
    "\n",
    "def train():\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    \n",
    "    policy = TD3(state_dim, action_dim, max_action)\n",
    "    replay_buffer = ReplayBuffer()\n",
    "    \n",
    "    print(\"action_space={}\".format(env.action_space))\n",
    "    print(\"obs_space={}\".format(env.observation_space))\n",
    "    print(\"threshold={} \\n\".format(env.spec.reward_threshold))\n",
    "    \n",
    "    if random_seed:\n",
    "        print(\"Random Seed: {}\".format(random_seed))\n",
    "        env.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # logging variables:        \n",
    "    log_f = open(\"log.txt\",\"w+\")\n",
    "    \n",
    "    # training procedure:\n",
    "    for episode in range(1, max_episodes+1):\n",
    "        ep_reward = 0\n",
    "        state = env.reset()\n",
    "        for t in range(max_timesteps):\n",
    "            # select action and add exploration noise:\n",
    "            action = policy.select_action(state)\n",
    "            action = action + np.random.normal(0, exploration_noise, size=env.action_space.shape[0])\n",
    "            action = action.clip(env.action_space.low, env.action_space.high)\n",
    "            \n",
    "            # take action in env:\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            replay_buffer.add((state, action, reward, next_state, float(done)))\n",
    "            state = next_state\n",
    "            \n",
    "            ep_reward += reward\n",
    "            \n",
    "            # if episode is done then update policy:\n",
    "            if done or t==(max_timesteps-1):\n",
    "                policy.update(replay_buffer, t, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay)\n",
    "                break\n",
    "        \n",
    "        reward_history.append(ep_reward)\n",
    "        avg_reward = np.mean(reward_history[-100:]) \n",
    "        \n",
    "        # logging updates:        \n",
    "        log_f.write('{},{}\\n'.format(episode, ep_reward))\n",
    "        log_f.flush()\n",
    "       \n",
    "        \n",
    "        # if avg reward > 300 then save and stop traning:\n",
    "        if avg_reward >= 300:\n",
    "            print(\"########## Solved! ###########\")\n",
    "            name = filename + '_solved'\n",
    "            policy.save(directory, name)\n",
    "            log_f.close()\n",
    "            break\n",
    "        \n",
    "        if episode > 500:\n",
    "            policy.save(directory, filename)\n",
    "        \n",
    "        # print avg reward every log interval:\n",
    "        if episode % log_interval == 0:            \n",
    "            print(\"Episode: {}\\tReward: {}\\tAverage Reward: {}\".format(episode, ep_reward, avg_reward))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test():\n",
    "    env_name = \"BipedalWalker-v2\"\n",
    "    random_seed = 0\n",
    "    n_episodes = 3\n",
    "    max_timesteps = 2000\n",
    "    render = True\n",
    "    save_gif = False\n",
    "    \n",
    "    filename = \"TD3_{}_{}\".format(env_name, random_seed)\n",
    "    filename += '_solved'\n",
    "    directory = \"./preTrained/{}/ONE\".format(env_name)\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    \n",
    "    policy = TD3(state_dim, action_dim, max_action)\n",
    "    \n",
    "    policy.load_actor(directory, filename)\n",
    "    \n",
    "    for ep in range(1, n_episodes+1):\n",
    "        ep_reward = 0\n",
    "        state = env.reset()\n",
    "        for t in range(max_timesteps):\n",
    "            action = policy.select_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            ep_reward += reward\n",
    "            if render:\n",
    "                env.render()\n",
    "                if save_gif:\n",
    "                     img = env.render(mode = 'rgb_array')\n",
    "                     img = Image.fromarray(img)\n",
    "                     img.save('./gif/{}.jpg'.format(t))\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        print('Episode: {}\\tReward: {}'.format(ep, int(ep_reward)))\n",
    "        ep_reward = 0\n",
    "        env.close()        \n",
    "                \n",
    "test()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
